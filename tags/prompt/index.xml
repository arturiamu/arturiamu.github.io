<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Prompt on 木林彪的个人博客</title>
        <link>https://arturiamu.github.io/tags/prompt/</link>
        <description>Recent content in Prompt on 木林彪的个人博客</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Tue, 15 Oct 2024 20:02:17 +0800</lastBuildDate><atom:link href="https://arturiamu.github.io/tags/prompt/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>大模型提示工程（Prompt）</title>
        <link>https://arturiamu.github.io/post/prompt-tips/</link>
        <pubDate>Tue, 15 Oct 2024 20:02:17 +0800</pubDate>
        
        <guid>https://arturiamu.github.io/post/prompt-tips/</guid>
        <description>&lt;p&gt;现在的大模型，基本都是基于 transformer 的 GPT 模型。以 ChatGPT 为例，它是一种基于 GPT 模型的对话生成模型，它可以让计算机自动学习对话语料库中的模式，并生成连贯、自然的对话回复。 对于我们普通用户来说，无论是使用ChatGPT，还是文心一言、通义千问这些大模型，就是通过一轮一轮的对话来实现我们的诉求。&lt;/p&gt;
&lt;h2 id=&#34;简单提示&#34;&gt;简单提示&lt;/h2&gt;
&lt;p&gt;所谓提示词，就是如何让ChatGPT更精准的理解我们的意图，输出我们想要的答案。想要让AI生成更优质、更符合我们需求的内容，关键在于如何设计Prompt（提示词）。以下是一些改进Prompt的技巧，帮助我们更好地引导AI：&lt;/p&gt;
&lt;p&gt;1.明确目标，清晰表达：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;避免模糊不清： 不要使用过于笼统或模棱两可的词语。例如，将“写一篇关于人工智能的文章”改为“写一篇面向初学者的、介绍人工智能发展历史的文章，字数约1000字”。&lt;/li&gt;
&lt;li&gt;具体化需求： 明确我们希望AI生成的内容类型、风格、长度等。例如，将“写一首诗”改为“写一首关于春天、表达喜悦心情的五言绝句”。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.提供上下文，丰富信息：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;背景信息： 提供与主题相关的背景信息，帮助AI更好地理解我们的需求。例如，在要求AI生成一篇产品文案时，可以提供产品的目标用户、核心卖点等信息。&lt;/li&gt;
&lt;li&gt;示例参考： 提供我们希望AI模仿的风格或格式的示例，例如提供一篇你喜欢的文章作为参考。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3.分步骤引导，细化任务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将复杂任务拆解： 将复杂的任务拆解成多个简单的步骤，逐步引导AI生成内容。例如，将“写一篇小说”拆解为“设定故事背景”、“塑造人物形象”、“设计故事情节”等步骤。&lt;/li&gt;
&lt;li&gt;迭代优化： 不要期望AI一次就能生成完美的内容。可以根据初步生成的结果，不断调整和优化Prompt，逐步接近你的目标。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;4.尝试不同的Prompt风格：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指令式Prompt： 直接告诉AI我们希望它做什么，例如“翻译以下句子”、“总结这篇文章的主要观点”。&lt;/li&gt;
&lt;li&gt;问答式Prompt： 以问题的形式引导AI生成内容，例如“什么是机器学习？”、“如何提高写作效率？”。&lt;/li&gt;
&lt;li&gt;角色扮演Prompt： 让AI扮演特定角色来生成内容，例如“假设你是一位历史学家，请描述一下唐朝的繁荣景象”。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;5.利用工具和资源：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prompt库： 参考一些优秀的Prompt库，例如OpenAI的Prompt Library，学习如何设计有效的Prompt。&lt;/li&gt;
&lt;li&gt;在线工具： 使用一些在线工具，例如Prompt Generator，帮助你生成更结构化的Prompt。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;6.些额外的建议：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用自然语言： 尽量使用自然语言与AI沟通，就像与人交流一样。&lt;/li&gt;
&lt;li&gt;保持耐心和探索精神： 设计Prompt是一个不断尝试和优化的过程，需要耐心和探索精神。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;更进一步&#34;&gt;更进一步&lt;/h2&gt;
&lt;p&gt;我们可以通过&lt;strong&gt;提示工程（prompt engineering）&lt;/strong&gt; 和&lt;strong&gt;微调（fine-tuning）&lt;/strong&gt; 激发大型语言模型的涌现能力。 对于理解和应用LLM模型来说，这些知识都具有重要的参考价值。 作为非技术人员的日常应用，我们要关注的是：&lt;/p&gt;
&lt;h3 id=&#34;zero-shot-提示法&#34;&gt;Zero shot 提示法&lt;/h3&gt;
&lt;p&gt;Zero-shot(零样本) Prompt 提示词技术使得我们在无需做特定训练的情况下依然可以让大模型给我们完成一些简单的任务，我们无需提供给模型额外的数据或者做微调，在很多时候依然能得到不错的效果。Zero-shot(零样本) Prompt是一种很快速便捷的方式让我们对新任务做出尝试，很适合验证我们新的想法。 在一些简单的场景中，我们优先会考虑的就是Zero-shot(零样本) Prompt。&lt;/p&gt;
&lt;h3 id=&#34;one-shot--few-shot-提示法&#34;&gt;One-shot &amp;amp; Few-shot 提示法&lt;/h3&gt;
&lt;p&gt;Few-shot提示方法并不复杂，只需要将一些类似的问题的问题+答案作为prompt的一部分进行输入即可。&lt;/p&gt;
&lt;p&gt;Few-shot的编写格式：&lt;/p&gt;
&lt;p&gt;当需要输入多段问答作为提示词时，以Q作为问题的开头、A作为回答的开头（也可以换成“问题”、“答案”）， 并且不同的问答对话需要换行以便于更加清晰的展示，具体方法是通过转义符+换行来完成。&lt;/p&gt;
&lt;h3 id=&#34;code-prompting&#34;&gt;Code Prompting&lt;/h3&gt;
&lt;p&gt;代码提示工程是指通过设计特殊的代码提示来激发模型的涌现能力。这种方法不需要对模型进行额外的训练，只需要通过设计合适的代码提示来引导模型完成特定任务，代码提示工程通常用于解决那些无法通过语言提示工程解决的问题。这个不在这里描述，也是后续需要学习的一个重点专题。&lt;/p&gt;
&lt;h3 id=&#34;思维链提示法&#34;&gt;思维链提示法&lt;/h3&gt;
&lt;p&gt;思维链（Chain of Thought）是一种提示工具，用于帮助语言模型进行复杂的推理和思考过程。它通过引导模型逐步解决问题，以一系列连贯的步骤展示推理的思路和逻辑关系。&lt;/p&gt;
&lt;p&gt;思维链提示的基本思想是将推理过程分解为多个步骤，并在每个步骤中指导模型逐步进行推理。每个步骤都通过自然语言描述，使模型能够理解和执行每个推理阶段所需的操作。&lt;/p&gt;
&lt;p&gt;具体而言，思维链提示通常由多个中间步骤组成，每个中间步骤都解释了问题的一个方面或子问题。模型需要根据前一个步骤的结果和当前问题的要求来推断下一个步骤。通过这种逐步推理的方式，模型可以逐渐获得更多信息，并在整个推理过程中累积正确的推断。&lt;/p&gt;
&lt;h4 id=&#34;zero-shot-cot提示方法&#34;&gt;Zero-shot-CoT提示方法&lt;/h4&gt;
&lt;p&gt;Zero-shot-CoT是在Few-shot思想下，一种更好的提示方法。它借助思维链（也被称为思考链，Chain of Thought，CoT）提示法来解决这个问题。一种非常简单而有效的方式是：&lt;/p&gt;
&lt;p&gt;在提示词尾部追加一句“Let’s think step by step”，即可大幅提高模型推理能力。&lt;/p&gt;
&lt;p&gt;如果切换到中文语境下，对指令“Let’s think step by step”进行中文翻译，做了大量的测试后，得出结论： “请一步步进行推理并得出结论”要远远好于“请让我们一步步进行思考”等类似的提示词语句。&lt;/p&gt;
&lt;h4 id=&#34;few-shot-cot提示方法&#34;&gt;Few-shot-CoT提示方法&lt;/h4&gt;
&lt;p&gt;Zero-shot-CoT是零样本提示的情况下通过修改提示词后缀激发模型的思维链，而Few-shot-CoT则是通过编写思维链样本作为提示词，让模型学会思维链的推导方式，从而更好的完成推导任务。&lt;/p&gt;
&lt;h4 id=&#34;cot改良方法least-to-most-promptingltm提示法&#34;&gt;CoT改良方法：LEAST-TO-MOST PROMPTING（LtM提示法）&lt;/h4&gt;
&lt;p&gt;LtM提示方法提出的初衷是为了解决CoT提示方法泛化能力不足的问题——即通过人工编写的思维链提示样本可能并不能够很好的迁移到别的问题当中去，换而言之，就是解决问题的流程迁移能力不足，即泛化能力不够。而这种泛化能力不足则会导致“新的问题”无法使用“老的模板”进行解决。&lt;/p&gt;
&lt;p&gt;所以一个思想就是：让大模型自己找到解决当前问题的思维链。谷歌大脑基于这个思路开发了一种全新的提示流程，即先通过提示过程让模型找到解决该问题必须要分步解决哪几个问题，然后再通过依次解决这些问题来解决最原始的问题。&lt;/p&gt;
&lt;p&gt;整个提示过程会分为两个阶段进行：&lt;/p&gt;
&lt;p&gt;第一个阶段是自上而下的分解问题（Decompose Question into subquestion）；&lt;/p&gt;
&lt;p&gt;第二个阶段是自下而上的依次解决问题（Sequentially Solve Subquestion），整个依次回答问题的过程，其实就可以看成是CoT的过程，只不过LtM会要求模型根据每个不同的问题，单独生成解决问题的链路，从而能够更加精准的解决复杂推理问题。 而整个过程问题的由少变多，则是LEAST-TO-MOST一词的来源。&lt;/p&gt;
&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;
&lt;p&gt;通过改进Prompt，我们可以更有效地引导AI生成更优质、更符合我们需求的内容。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
