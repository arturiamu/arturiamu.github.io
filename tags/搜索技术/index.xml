<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>搜索技术 on 木林彪的个人博客</title>
        <link>http://localhost:1313/tags/%E6%90%9C%E7%B4%A2%E6%8A%80%E6%9C%AF/</link>
        <description>Recent content in 搜索技术 on 木林彪的个人博客</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Sat, 12 Oct 2024 19:22:39 +0800</lastBuildDate><atom:link href="http://localhost:1313/tags/%E6%90%9C%E7%B4%A2%E6%8A%80%E6%9C%AF/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>从信息检索到文本生成：RAG如何让AI更懂你？</title>
        <link>http://localhost:1313/post/retrieval-augmented-generation/</link>
        <pubDate>Sat, 12 Oct 2024 19:22:39 +0800</pubDate>
        
        <guid>http://localhost:1313/post/retrieval-augmented-generation/</guid>
        <description>&lt;p&gt;你是否曾经感叹，虽然AI模型能写出流畅的文字，但内容却空洞无物，甚至“一本正经地胡说八道”？这是因为传统语言模型仅依赖于训练数据中的统计规律，缺乏对真实世界知识的深入理解。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RAG（Retrieval-Augmented Generation，检索增强生成）&lt;/strong&gt; 的出现，为解决这一问题提供了新的思路。它将信息检索与文本生成相结合，让AI在动笔之前，先学会“查资料”。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RAG的工作原理：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;提出问题：&lt;/strong&gt; 当你向RAG模型提出一个问题或指令时，它首先会将其转化为一个可检索的查询。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;检索相关知识：&lt;/strong&gt; 模型会从海量的文档库（例如维基百科、专业数据库）中检索出与查询最相关的文档片段。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;生成最终答案：&lt;/strong&gt; 模型将检索到的文档片段与原始问题相结合，生成更准确、信息更丰富的回答。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;RAG的优势：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;更准确的回答：&lt;/strong&gt; RAG模型不再局限于训练数据，能够利用外部知识库提供更准确、可靠的答案。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;更强的可解释性：&lt;/strong&gt; 由于RAG模型的回答基于检索到的文档，我们可以追踪其信息来源，提高模型的可解释性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;更广泛的应用场景：&lt;/strong&gt; RAG可以应用于问答系统、对话系统、文本摘要等多个领域，为用户提供更智能的服务。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;RAG的应用实例：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;智能客服：&lt;/strong&gt; RAG可以帮助客服机器人快速检索产品信息、常见问题解答等，为用户提供更精准的解答。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;医疗诊断：&lt;/strong&gt; RAG可以辅助医生检索医学文献、病例数据等，为诊断和治疗提供参考。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;教育领域：&lt;/strong&gt; RAG可以为学生提供个性化的学习资料，并根据学生的学习情况推荐相关的学习资源。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;RAG的未来发展：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;RAG技术仍处于快速发展阶段，未来还有许多值得探索的方向，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;如何提高检索效率和精度？&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;如何更好地融合检索到的信息和生成的内容？&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;如何构建更高质量、更全面的知识库？&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;总结：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;RAG的出现为人工智能的发展带来了新的机遇，它让AI模型能够更好地理解和利用外部知识，从而提供更智能、更可靠的服务。相信随着技术的不断进步，RAG将在各个领域发挥越来越重要的作用，为我们的生活带来更多便利。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>搜索引擎原理入门</title>
        <link>http://localhost:1313/post/search-engine-principles/</link>
        <pubDate>Thu, 05 Sep 2024 13:25:17 +0800</pubDate>
        
        <guid>http://localhost:1313/post/search-engine-principles/</guid>
        <description>&lt;p&gt;搜索无处不在，作为信息化时代大多数人获取信息的最重要的路径，说搜索引擎是使用最为广泛和频繁的中间件之一，应该没有人会反驳。在实际的应用场景中， 小到个人博客， 大到电商平台，你在谷歌上搜索的每一个关键字， 在电商网站上搜索的每一件商品， 追剧听音乐的时候在搜索栏输入的每一个名字的背后都是搜索引擎的处理和输出。就像是你提问，然后搜索引擎告诉你一个答案，搜索不仅无处不在，无所不知，默默的主宰着网络世界的入口。&lt;/p&gt;
&lt;h2 id=&#34;什么是搜索引擎&#34;&gt;什么是搜索引擎&lt;/h2&gt;
&lt;p&gt;搜索引擎是一种在线搜索工具，旨在根据用户的搜索查询在网络上收集合适的网站存入自己的数据库中，然后使用独特的算法对它们进行排序。当用户在搜索框输入关键词时，搜索引擎就会将对应的内容展示给用户。&lt;/p&gt;
&lt;h2 id=&#34;搜索引擎的工作原理&#34;&gt;搜索引擎的工作原理&lt;/h2&gt;
&lt;p&gt;搜索引擎的工作原理可以简单概括为以下 4 个步骤：&lt;/p&gt;
&lt;h3 id=&#34;爬取网页&#34;&gt;爬取网页：&lt;/h3&gt;
&lt;p&gt;搜索引擎会派出名为“网络爬虫”的程序，像蜘蛛一样在互联网上爬行，访问各个网站，收集网页内容。 爬虫会从一个种子 URL 列表开始，然后沿着网页上的链接不断爬取新的页面并存储到搜索引擎的数据库中。
为了避免过度消耗网站资源，爬虫会遵守 robots.txt 协议，并控制爬取频率。&lt;/p&gt;
&lt;p&gt;爬虫发现新页面的主要跟踪方法是已知的网页中的链接。从A页面上的超链接可以发现 B 页面、C 页面等，搜索引擎蜘蛛会将这些网页存储起来，当做下次访问的对象。正是基于这点，所以我们要避免某个网页成为“孤岛页面”，也就是没有任何链接指向它。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;robots.txt&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;robots.txt 是一个纯文本文件，是网站管理者用来与网络爬虫进行沟通的工具。它遵循 Robots 排除协议 (Robots Exclusion Protocol)，通过简单的指令告诉爬虫哪些页面可以抓取，哪些页面应该避免。&lt;/p&gt;
&lt;p&gt;robots.txt 的作用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;控制爬虫访问： 网站管理者可以通过 robots.txt 文件限制某些爬虫访问网站的特定部分，例如后台管理页面、用户个人信息等，保护敏感数据和网站安全。&lt;/li&gt;
&lt;li&gt;优化爬虫效率： 通过引导爬虫抓取重要页面，避免爬虫浪费资源在无关紧要的内容上，可以提高爬虫效率，减轻网站服务器负担。&lt;/li&gt;
&lt;li&gt;避免重复内容： 网站管理者可以使用 robots.txt 文件阻止爬虫抓取重复内容的页面，例如打印友好页面、搜索结果页面等，有利于提升网站在搜索引擎中的排名。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;robots.txt 的语法： robots.txt 文件的语法非常简单，主要由以下两个指令构成：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;User-agent&lt;/code&gt;: 指定该规则适用于哪些爬虫。例如，User-agent: * 表示该规则适用于所有爬虫，User-agent: Googlebot 表示该规则仅适用于 Google 的爬虫。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Disallow&lt;/code&gt;: 指定不允许爬虫访问的路径。例如，Disallow: /admin/ 表示不允许爬虫访问 /admin/ 目录下的所有内容。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;需要注意：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;robots.txt 只是一个“君子协议”，它依赖于爬虫的自觉遵守。一些恶意的爬虫可能会无视 robots.txt 文件的限制。&lt;/p&gt;
&lt;p&gt;robots.txt 文件不能阻止网页被索引。即使爬虫不能抓取某个页面，如果该页面被其他页面链接，它仍然可能出现在搜索引擎结果中。&lt;/p&gt;
&lt;p&gt;如果需要更严格地控制页面索引，可以使用 noindex 元标签。&lt;/p&gt;
&lt;h3 id=&#34;建立索引&#34;&gt;建立索引：&lt;/h3&gt;
&lt;p&gt;将爬虫收集到的网页经过分析处理后，搜索引擎会将这些信息进行索引。索引的过程类似于图书馆的索引系统，目的是为快速查找内容而构建一个高效的数据结构。
在索引过程中，搜索引擎会分析页面中的文本内容、关键词、图片、视频等，并构建倒排索引（Inverted Index）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;倒排索引&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;倒排索引将每个单词或短语与它在各个页面中出现的位置进行关联，这样当用户输入查询时，搜索引擎可以迅速地查找到所有包含这些单词的页面。这个索引结构大大提高了搜索引擎的查询效率。&lt;/p&gt;
&lt;h3 id=&#34;处理搜索请求&#34;&gt;处理搜索请求：&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;理解用户意图：&lt;/strong&gt; 当你输入关键词进行搜索时，搜索引擎会首先尝试理解你的搜索意图。
搜索引擎会分析你的搜索关键词、搜索历史、地理位置等信息，来判断你真正想要查找的内容。
例如，你搜索“苹果”，搜索引擎需要判断你是想了解水果“苹果”，还是科技公司“苹果”。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;匹配关键词：&lt;/strong&gt; 搜索引擎会根据你的搜索关键词，在索引库中查找包含这些关键词的网页。
搜索引擎会使用各种算法来计算网页与搜索关键词的相关性。
例如，关键词出现的频率、位置、网页的权威性等因素都会影响相关性得分。&lt;/p&gt;
&lt;h3 id=&#34;排序和展示结果&#34;&gt;排序和展示结果：&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;相关性排序：&lt;/strong&gt; 搜索引擎会根据一系列复杂的算法，对找到的网页进行排序。相关性越高的网页，排名越靠前。
除了相关性，搜索引擎还会考虑其他因素，例如网页的权威性、新鲜度、用户的点击行为等。
例如，一个来自权威网站、内容新鲜、用户点击率高的网页，排名会相对靠前。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;展示搜索结果：&lt;/strong&gt; 最后，搜索引擎会将排序后的结果以列表的形式展示给你，通常包括网页标题、摘要、链接等信息。
搜索引擎会使用各种技术来优化搜索结果的展示，例如摘要生成、关键词高亮、相关搜索推荐等。
例如，搜索引擎会根据网页内容生成简洁明了的摘要，并将搜索关键词高亮显示，方便用户快速浏览。&lt;/p&gt;
&lt;h2 id=&#34;搜索引擎的关键技术&#34;&gt;搜索引擎的关键技术&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1.自然语言处理（NLP）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;自然语言处理是让计算机理解人类语言的技术。搜索引擎需要使用NLP来处理用户的查询，并将其与网页内容进行匹配。例如，NLP可以帮助搜索引擎识别同义词、理解多义词的不同含义、进行文本的情感分析等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.机器学习与人工智能（AI）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;机器学习和AI在搜索引擎中的应用越来越广泛，特别是在排序和个性化推荐方面。搜索引擎会使用机器学习算法对用户行为进行分析，以便预测用户的需求，并根据用户的历史搜索记录、位置、兴趣等信息提供个性化的搜索结果。&lt;/p&gt;
&lt;p&gt;例如，谷歌的RankBrain算法就是基于人工智能的一个搜索算法，它通过分析大量数据来判断搜索结果的相关性，并不断学习和改进。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.大数据与分布式计算&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;搜索引擎需要处理的网页数据量非常庞大，因此大数据和分布式计算技术在搜索引擎中起到了至关重要的作用。分布式计算通过将任务分配到多个服务器上，解决了海量数据处理的瓶颈问题，保证了搜索引擎的高效性和可扩展性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.信息检索技术&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;信息检索是搜索引擎的核心技术之一，它涉及如何从海量数据中快速找到相关信息。倒排索引、布尔检索、向量空间模型等都是经典的信息检索技术。现代搜索引擎还引入了深度学习等先进的技术，进一步提升了搜索精度。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;虽然看起来搜索引擎的原理非常简单，但是搜索引擎实际上是个非常之复杂的系统工程。分布式的海量数据存储、超高并发的读写、搜索的速度和精确度要求、不同类型结果的渲染展示等等，每一项都面临着对应技术领域天花板级别的挑战。本文只是尝试简单的来了解搜索引擎基本原理、工作流程、运行机制。&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
