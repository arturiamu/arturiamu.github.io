[{"content":"最近 deepseek 越来越火，官网已经近乎沦陷。由于家里有台 2060 闲置笔记本，尝试利用 deepseek 开源的模型，在本地搭建一个，将模型部署在本地使用。\n配置\n下载运行Ollama 打开官网网址：https://ollama.com\n点击 Download\n点击 Download for Windows\nexe 文件约 800MB，等待下载期间先配置相关环境变量（主要是配置 ollma 模型下载位置，避免 C 盘空间不足），可以使用以下脚本快速完成，将 path=D:/Ollama 修改为目标位置即可，注意 = 左右不能有空格！！！\n1 2 3 4 5 6 7 8 9 10 @echo off chcp 65001 \u0026gt; nul set \u0026#34;SCRIPT_DIR=%~dp0\u0026#34; set path=D:/Ollama setx OLLAMA_MODELS \u0026#34;%path%/models\u0026#34; \u0026gt; nul setx OLLAMA_HOST \u0026#34;0.0.0.0\u0026#34; \u0026gt; nul setx OLLAMA_ORIGINS \u0026#34;*\u0026#34; \u0026gt; nul echo 环境变量已设置成功,下面将进行安装程序，安装页面弹出后，直接点install即可，程序将被安装到%path% %SCRIPT_DIR%OllamaSetup.exe /DIR=\u0026#34;%path%\u0026#34; pause 将以上脚本保存到 exe 文件同级目录\n待 ollama 下载完毕后，右键单机脚本，点击“以管理员身份运行”，会弹出以下界面，该界面可以直接关闭\n同时会弹出以下界面，点击 Install 即可开始安装\n安装完成后，系统会自动运行 ollama，在电脑右下角有个小图标，将ollama重启一下。\n下载 deepseek 模型 ollama 安装好之后，就能下载模型了，这里我使用的是deepseek-r1的模型。\n模型官方地址：https://ollama.com/library/deepseek-r1\n在电脑上重新打开一个cmd窗口或者windows powershell窗口。\n输入命令 ollama help，如果能输出以下提示信息，说明目前设置正确。\nollama 命令，我们目前只要记住这三个就可以了：\n查看模型列表： ollama list\n安装模型： ollama run xxxx\n卸载模型： ollama rm xxxx\n下载模型，直接输入命令就可以了。\n这里我使用的是 8 b的模型，就在cmd里面直接输入 ollama run deepseek-r1:8b。模型下载完毕之后会直接运行。\n提示：下载过程中如果下载速度降的很低，直接 ctrl+c 中断任务后重新下载即可。\n可视化 打开 chatbox 官网：https://chatboxai.app/zh\n点击 “免费下载”\n点击 “手动下载 for Windows（PC）”\n选择位置安装\n安装完毕后设置相关参数\n开始使用\n完结撒花！！！！！！！\n","date":"2025-02-01T22:05:14+08:00","permalink":"http://localhost:1313/post/local-deepseek-model/","title":"deepseek模型本地部署"},{"content":"本文转载自 科技爱好者周刊（第 333 期）：一切都要支付两次\n有一句古语\u0026quot;书非借不能读也\u0026quot;，大家可能都听过。\n它的意思是，很多人买了书却不读，觉得不着急，拥有书就相当于已经开始学了，后面就慢慢来吧，反而是借来的书有急迫感会抓紧读完。\n这种事情很多。网址保存成书签，就扔在那里了，再也不去看它了。\n我最近看到一篇老外的文章，他给这种现象起了一个全新的名字，让人觉得很贴切。老外的概念化能力真是强。\n他提出，人们买书却不读，是因为没有意识到每样东西都需要两次支付。\n第一次是货币支付，你付出货币，得到自己想要的东西，比如一本书，一个 App，一辆自行车，一颗卷心菜等等。\n但是，你还必须支付第二次，才能真正消费这个东西。这次你付出的是你的时间和努力，来获得它的收益。\n第二次支付可能比第一次支付贵得多。假设一本书的第一次支付是20元，第二次支付可能就是10小时的阅读时间。只有支付第二次，你才算真正消费了这本书。如果没有第二次支付，第一次支付就意义不大了，跟把钱扔进垃圾箱差不多。\n生活中，到处都是两次支付的例子。购买 App 后，你必须学习如何使用，并且经常使用，才能得到它的价值。购买自行车后，你必须忍受痛苦的初学者阶段，然后才能上街骑行。购买蔬菜后，必须切碎、蒸熟并咀嚼，然后才能为你提供营养。\n我们经常犯的一个错误，就是只完成了第一次支付，没有第二次支付， 比如未使用的会员资格，未读的书籍，未玩的游戏，未编织的毛线。由于没有第二次支付，所以你并没有真正使用，第一次支付的钱实际上扔进了垃圾桶。\n这种行为方式的深层次原因，就是现代社会太强调消费， 过于看重第一次支付的经济价值，而忽视第二次支付的实际结果。人们受到消费主义的影响，以为支付了商品价格，就完成了一次消费。\n合理的消费方式应该是，只有当你确定会有第二次支付，才进行第一次支付。 这样就可以避免许许多多的浪费。\n新的一年，大家购买商品时，可以先问问自己，你会不会第二次支付，即会不会为它付出时间和努力？只有确信自己会，再掏钱购买它。\n有一种商品，天然支持先进行第二次支付，再进行第一次支付，那就是软件。\n软件不同于实体商品，边际成本接近零，又是长期消费，完全可以先让用户免费用（试用版或者试用期），等他用习惯了，再向他收费。\n很多软件就是这样做的，这大概就是为什么，软件的不理性消费行为，要比实体商品少得多的原因。\n","date":"2025-01-15T22:03:45+08:00","permalink":"http://localhost:1313/post/pay-for-everything-twice/","title":"一切都要支付两次"},{"content":"文件完整性校验是确保文件在传输、存储或处理过程中未被篡改或损坏的重要技术手段。它在信息安全、数据管理和系统维护中扮演着关键角色。\nMD5算法简介 MD5 算法（Message Digest Algorithm 5，消息摘要算法第5版）是一种广泛使用的哈希函数，由 Ronald Rivest 于 1991 年设计。它可以将任意长度的数据（如文件、字符串）转换为固定长度的 128 位（16 字节）哈希值，通常以 32 个十六进制字符表示。MD5 最初被设计用于数据完整性校验和密码存储，但由于其安全性问题，现已不推荐用于高安全性场景。\nMD5 算法的特点:\n输出长度：128 位（16 字节），通常表示为 32 个十六进制字符。 输入长度：支持任意长度的输入数据。 计算速度：MD5 计算速度较快，适合处理大量数据。 确定性：相同的输入始终生成相同的哈希值。 雪崩效应：输入数据的微小变化会导致哈希值的显著变化。 尽管在理论上，MD5存在着潜在的安全漏洞，但对于文件完整性校验来说，它仍然是足够安全的。\n校验和 校验和（Checksum）是一种用于验证数据完整性的简单技术。它通过对数据（如文件、消息或数据包）进行数学计算，生成一个固定长度的值（即校验和），然后将该值与接收方计算的校验和进行比对。如果两者一致，则说明数据在传输或存储过程中未被篡改或损坏；如果不一致，则说明数据可能存在问题。\nMD5算法和SHA-512算法都可以用于生成文件的校验和。MD5算法生成的校验和长度为128位，而SHA-512算法生成的校验和长度为512位，后者因此提供了更高级别的安全性。\n使用MD5算法和sha512sum校验和检验文件完整性 假如存在一个文件 file.txt，我把文件发送给其他人，怎么证明文件在传输的途中没有被恶意修改？\n1 2 root@ubuntu:~# ls file.txt 先求出文件的md5值。\n1 2 root@ubuntu:~# md5sum file.txt 9cc4a633f4ba45f0fd723512ec60f330 file.txt 把文件传输给其他机器。\n1 root@ubuntu:~# scp file.txt 192.168.110.131:/root/test/ 其他机器收到文件之后，求文件的md5值。如果此时生成的md5值和原来的md5值一致，则文件是完整的，没有被修改过。\n数字签名也是类似的：文件和文件生成的md5值一起传输，md5值使用私钥加密，接收方收到后使用公钥解密md5值，接收方使用收到的文件生成md5值，如果md5值和公钥解密之后的md5值一致，则文件没有被修改过。\n1 2 [root@etcd2 test]# md5sum file.txt 9cc4a633f4ba45f0fd723512ec60f330 file.txt 创建校验和目录。\n1 2 3 4 root@ubuntu:~# mkdir checksum root@ubuntu:~# cd checksum/ root@ubuntu:~/checksum# ls file.txt 求文件的校验和。\n1 2 root@ubuntu:~/checksum# sha512sum file.txt 94eece98db92232a42080e33f87e0659182e2ff9e347db38a494928c247289fcfa763a20e18ee63a84fe87f436b91e710927d138621640d6753083b8b339e8cf file.txt 把校验和写入到文件里。\n1 2 3 4 5 6 7 8 root@ubuntu:~/checksum# sha512sum file.txt \u0026gt;check.txt root@ubuntu:~/checksum# vim check.txt root@ubuntu:~/checksum# cat check.txt file.txt 94eece98db92232a42080e33f87e0659182e2ff9e347db38a494928c247289fcfa763a20e18ee63a84fe87f436b91e710927d138621640d6753083b8b339e8cf 94eece98db92232a42080e33f87e0659182e2ff9e347db38a494928c247289fcfa763a20e18ee63a84fe87f436b91e710927d138621640d6753083b8b339e8cf 如果两个校验和是一致的，则只剩一行(去重)。\n1 2 3 root@ubuntu:~/checksum# cat check.txt | uniq file.txt 94eece98db92232a42080e33f87e0659182e2ff9e347db38a494928c247289fcfa763a20e18ee63a84fe87f436b91e710927d138621640d6753083b8b339e8cf 生成校验和并写入文件。\n1 2 3 4 root@ubuntu:~/checksum# sha512sum file.txt \u0026gt;check.txt root@ubuntu:~/checksum# cat check.txt 94eece98db92232a42080e33f87e0659182e2ff9e347db38a494928c247289fcfa763a20e18ee63a84fe87f436b91e710927d138621640d6753083b8b339e8cf file.txt sha512sum -c 判断file.txt文件的校验和和check.txt 里的校验和是否一致，输出OK则校验和一致。\n1 2 root@ubuntu:~/checksum# sha512sum -c check.txt file.txt: OK 总结 MD5和sha512sum校验和是检查文件完整性的有效方法。它们能够帮助我们在下载、传输或备份文件的过程中确保数据的一致性，提高我们的数据安全性。\n尽管MD5和SHA-512广泛用于计算文件校验和，但它们并不能防止数据被篡改。如果你需要保护数据的机密性，建议使用更强大的加密技术，例如AES或RSA等。\n","date":"2025-01-03T10:35:48+08:00","permalink":"http://localhost:1313/post/file-integrity-check/","title":"文件完整性校验"},{"content":"问题描述 使用 vscode 调试 golang 项目时，发现部分代码不按顺序跳转，变量不可见。\nlaunch.json\n1 2 3 4 5 6 7 8 9 10 11 12 13 { \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;debug ae app\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;exec\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;${workspaceFolder}/ae-app-598\u0026#34;, \u0026#34;preLaunchTask\u0026#34;: \u0026#34;build.ae.app\u0026#34; } ] } task.json\n1 2 3 4 5 6 7 8 9 10 { \u0026#34;version\u0026#34;: \u0026#34;2.0.0\u0026#34;, \u0026#34;tasks\u0026#34;: [ { \u0026#34;label\u0026#34;: \u0026#34;build.ae.app\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;make generate \u0026amp;\u0026amp; make build\u0026#34; } ] } 排查 google 搜索相关词条后，初步定位是 gcflags 参数问题，在 launch.json 中添加 \u0026quot;buildFlags\u0026quot;: \u0026quot;-gcflags=all=-N -l\u0026quot; 参数后问题仍然复现，且 debug 会触发 vscode 提示。\n提示链接 https://github.com/golang/vscode-go/blob/master/docs/debugging.md#debugging\n根据 gcflags 关键词查找到相关内容\n必须使用 go build -gcflags=all=\u0026quot;-N -l\u0026quot; 构建二进制文件以禁用可能干扰调试的内联和优化。\n解决 排查makefile 文件，发现 include 子文件中 go build 命令没有带 -gcflags=all=\u0026quot;-N -l\u0026quot; 参数。\n添加参数后问题解决\n关于 buildFlags -gcflags=\u0026quot;all=-N -l\u0026quot; 是 Go 编译器的一个常见调试选项，用于控制 Go 编译器优化行为，主要目的是禁用优化和内联，从而使生成的代码更适合调试。\n参数解释 -gcflags 全称：Go Compiler Flags 作用：用于传递给 Go 编译器的标志，影响编译过程的行为。 格式：-gcflags='pattern=flags' pattern 指定应用这些标志的包（例如 main、./... 或 all）。 flags 是具体的编译器参数。 all 作用：表示这些编译标志将应用于所有包（包括标准库和项目代码）。 示例： -gcflags=all=-N -l：对所有包禁用优化和内联。 -gcflags=main=-N：只对 main 包禁用优化。 -N 作用：禁用优化。 详细说明： 在调试中，禁用优化有助于让生成的代码更接近于源代码。 优化关闭后，变量的值和执行路径更容易在调试器中被准确跟踪。 -l 作用：禁用函数内联（Inlining）。 详细说明： 函数内联是编译器将一个函数的调用替换为该函数的代码，从而提升运行时性能。 在调试中，内联可能导致函数调用栈不准确，变量信息丢失等问题。 禁用内联可以保留函数调用栈的完整性。 综合效果 当使用 -gcflags=\u0026quot;all=-N -l\u0026quot;：\n优化禁用：编译器不再优化代码，源代码与生成的机器码保持较高的一致性。 内联禁用：函数的调用关系在运行时完全保留，便于调试器追踪调用栈和变量信息。 使用场景 调试：\n开启调试器（如 dlv）时，为了能更准确地显示变量值和调用栈。 示例： 1 2 go build -gcflags=\u0026#34;all=-N -l\u0026#34; dlv exec ./your_program 定位问题：\n如果程序行为异常且难以调试，通过禁用优化和内联来简化调试过程。 性能分析对比：\n使用禁用优化的版本对比优化后的版本，分析优化对性能的影响。 注意事项 性能影响：\n禁用优化和内联后，生成的代码运行速度会变慢，特别是在大规模项目中。 不建议在生产环境中使用。 限制性：\n这些标志仅对编译的包有效，对预编译的标准库（如 fmt、net）无效，除非重新编译标准库。 重新编译标准库： 1 go install -a -gcflags=\u0026#34;all=-N -l\u0026#34; std 示例 1 2 3 4 5 6 7 8 # 对当前项目禁用优化和内联 go build -gcflags=\u0026#34;all=-N -l\u0026#34; # 对特定包禁用优化（如 `mypkg`） go build -gcflags=\u0026#34;mypkg=-N -l\u0026#34; ./mypkg # 使用 Makefile 构建时禁用优化 make build GCFLAGS=\u0026#34;all=-N -l\u0026#34; ","date":"2024-12-05T16:53:18+08:00","permalink":"http://localhost:1313/post/vscode-go-dlv-debugging/","title":"vscode debug golang 代码不按顺序跳转、变量不可见问题"},{"content":"现在的大模型，基本都是基于 transformer 的 GPT 模型。以 ChatGPT 为例，它是一种基于 GPT 模型的对话生成模型，它可以让计算机自动学习对话语料库中的模式，并生成连贯、自然的对话回复。 对于我们普通用户来说，无论是使用ChatGPT，还是文心一言、通义千问这些大模型，就是通过一轮一轮的对话来实现我们的诉求。\n简单提示 所谓提示词，就是如何让ChatGPT更精准的理解我们的意图，输出我们想要的答案。想要让AI生成更优质、更符合我们需求的内容，关键在于如何设计Prompt（提示词）。以下是一些改进Prompt的技巧，帮助我们更好地引导AI：\n1.明确目标，清晰表达：\n避免模糊不清： 不要使用过于笼统或模棱两可的词语。例如，将“写一篇关于人工智能的文章”改为“写一篇面向初学者的、介绍人工智能发展历史的文章，字数约1000字”。 具体化需求： 明确我们希望AI生成的内容类型、风格、长度等。例如，将“写一首诗”改为“写一首关于春天、表达喜悦心情的五言绝句”。 2.提供上下文，丰富信息：\n背景信息： 提供与主题相关的背景信息，帮助AI更好地理解我们的需求。例如，在要求AI生成一篇产品文案时，可以提供产品的目标用户、核心卖点等信息。 示例参考： 提供我们希望AI模仿的风格或格式的示例，例如提供一篇你喜欢的文章作为参考。 3.分步骤引导，细化任务：\n将复杂任务拆解： 将复杂的任务拆解成多个简单的步骤，逐步引导AI生成内容。例如，将“写一篇小说”拆解为“设定故事背景”、“塑造人物形象”、“设计故事情节”等步骤。 迭代优化： 不要期望AI一次就能生成完美的内容。可以根据初步生成的结果，不断调整和优化Prompt，逐步接近你的目标。 4.尝试不同的Prompt风格：\n指令式Prompt： 直接告诉AI我们希望它做什么，例如“翻译以下句子”、“总结这篇文章的主要观点”。 问答式Prompt： 以问题的形式引导AI生成内容，例如“什么是机器学习？”、“如何提高写作效率？”。 角色扮演Prompt： 让AI扮演特定角色来生成内容，例如“假设你是一位历史学家，请描述一下唐朝的繁荣景象”。 5.利用工具和资源：\nPrompt库： 参考一些优秀的Prompt库，例如OpenAI的Prompt Library，学习如何设计有效的Prompt。 在线工具： 使用一些在线工具，例如Prompt Generator，帮助你生成更结构化的Prompt。 6.些额外的建议：\n使用自然语言： 尽量使用自然语言与AI沟通，就像与人交流一样。 保持耐心和探索精神： 设计Prompt是一个不断尝试和优化的过程，需要耐心和探索精神。 更进一步 我们可以通过提示工程（prompt engineering） 和微调（fine-tuning） 激发大型语言模型的涌现能力。 对于理解和应用LLM模型来说，这些知识都具有重要的参考价值。 作为非技术人员的日常应用，我们要关注的是：\nZero shot 提示法 Zero-shot(零样本) Prompt 提示词技术使得我们在无需做特定训练的情况下依然可以让大模型给我们完成一些简单的任务，我们无需提供给模型额外的数据或者做微调，在很多时候依然能得到不错的效果。Zero-shot(零样本) Prompt是一种很快速便捷的方式让我们对新任务做出尝试，很适合验证我们新的想法。 在一些简单的场景中，我们优先会考虑的就是Zero-shot(零样本) Prompt。\nOne-shot \u0026amp; Few-shot 提示法 Few-shot提示方法并不复杂，只需要将一些类似的问题的问题+答案作为prompt的一部分进行输入即可。\nFew-shot的编写格式：\n当需要输入多段问答作为提示词时，以Q作为问题的开头、A作为回答的开头（也可以换成“问题”、“答案”）， 并且不同的问答对话需要换行以便于更加清晰的展示，具体方法是通过转义符+换行来完成。\nCode Prompting 代码提示工程是指通过设计特殊的代码提示来激发模型的涌现能力。这种方法不需要对模型进行额外的训练，只需要通过设计合适的代码提示来引导模型完成特定任务，代码提示工程通常用于解决那些无法通过语言提示工程解决的问题。这个不在这里描述，也是后续需要学习的一个重点专题。\n思维链提示法 思维链（Chain of Thought）是一种提示工具，用于帮助语言模型进行复杂的推理和思考过程。它通过引导模型逐步解决问题，以一系列连贯的步骤展示推理的思路和逻辑关系。\n思维链提示的基本思想是将推理过程分解为多个步骤，并在每个步骤中指导模型逐步进行推理。每个步骤都通过自然语言描述，使模型能够理解和执行每个推理阶段所需的操作。\n具体而言，思维链提示通常由多个中间步骤组成，每个中间步骤都解释了问题的一个方面或子问题。模型需要根据前一个步骤的结果和当前问题的要求来推断下一个步骤。通过这种逐步推理的方式，模型可以逐渐获得更多信息，并在整个推理过程中累积正确的推断。\nZero-shot-CoT提示方法 Zero-shot-CoT是在Few-shot思想下，一种更好的提示方法。它借助思维链（也被称为思考链，Chain of Thought，CoT）提示法来解决这个问题。一种非常简单而有效的方式是：\n在提示词尾部追加一句“Let’s think step by step”，即可大幅提高模型推理能力。\n如果切换到中文语境下，对指令“Let’s think step by step”进行中文翻译，做了大量的测试后，得出结论： “请一步步进行推理并得出结论”要远远好于“请让我们一步步进行思考”等类似的提示词语句。\nFew-shot-CoT提示方法 Zero-shot-CoT是零样本提示的情况下通过修改提示词后缀激发模型的思维链，而Few-shot-CoT则是通过编写思维链样本作为提示词，让模型学会思维链的推导方式，从而更好的完成推导任务。\nCoT改良方法：LEAST-TO-MOST PROMPTING（LtM提示法） LtM提示方法提出的初衷是为了解决CoT提示方法泛化能力不足的问题——即通过人工编写的思维链提示样本可能并不能够很好的迁移到别的问题当中去，换而言之，就是解决问题的流程迁移能力不足，即泛化能力不够。而这种泛化能力不足则会导致“新的问题”无法使用“老的模板”进行解决。\n所以一个思想就是：让大模型自己找到解决当前问题的思维链。谷歌大脑基于这个思路开发了一种全新的提示流程，即先通过提示过程让模型找到解决该问题必须要分步解决哪几个问题，然后再通过依次解决这些问题来解决最原始的问题。\n整个提示过程会分为两个阶段进行：\n第一个阶段是自上而下的分解问题（Decompose Question into subquestion）；\n第二个阶段是自下而上的依次解决问题（Sequentially Solve Subquestion），整个依次回答问题的过程，其实就可以看成是CoT的过程，只不过LtM会要求模型根据每个不同的问题，单独生成解决问题的链路，从而能够更加精准的解决复杂推理问题。 而整个过程问题的由少变多，则是LEAST-TO-MOST一词的来源。\n总结 通过改进Prompt，我们可以更有效地引导AI生成更优质、更符合我们需求的内容。\n","date":"2024-10-15T20:02:17+08:00","permalink":"http://localhost:1313/post/prompt-tips/","title":"大模型提示工程（Prompt）"},{"content":"你是否曾经感叹，虽然AI模型能写出流畅的文字，但内容却空洞无物，甚至“一本正经地胡说八道”？这是因为传统语言模型仅依赖于训练数据中的统计规律，缺乏对真实世界知识的深入理解。\nRAG（Retrieval-Augmented Generation，检索增强生成） 的出现，为解决这一问题提供了新的思路。它将信息检索与文本生成相结合，让AI在动笔之前，先学会“查资料”。\nRAG的工作原理：\n提出问题： 当你向RAG模型提出一个问题或指令时，它首先会将其转化为一个可检索的查询。\n检索相关知识： 模型会从海量的文档库（例如维基百科、专业数据库）中检索出与查询最相关的文档片段。\n生成最终答案： 模型将检索到的文档片段与原始问题相结合，生成更准确、信息更丰富的回答。\nRAG的优势：\n更准确的回答： RAG模型不再局限于训练数据，能够利用外部知识库提供更准确、可靠的答案。\n更强的可解释性： 由于RAG模型的回答基于检索到的文档，我们可以追踪其信息来源，提高模型的可解释性。\n更广泛的应用场景： RAG可以应用于问答系统、对话系统、文本摘要等多个领域，为用户提供更智能的服务。\nRAG的应用实例：\n智能客服： RAG可以帮助客服机器人快速检索产品信息、常见问题解答等，为用户提供更精准的解答。\n医疗诊断： RAG可以辅助医生检索医学文献、病例数据等，为诊断和治疗提供参考。\n教育领域： RAG可以为学生提供个性化的学习资料，并根据学生的学习情况推荐相关的学习资源。\nRAG的未来发展：\nRAG技术仍处于快速发展阶段，未来还有许多值得探索的方向，例如：\n如何提高检索效率和精度？\n如何更好地融合检索到的信息和生成的内容？\n如何构建更高质量、更全面的知识库？\n总结：\nRAG的出现为人工智能的发展带来了新的机遇，它让AI模型能够更好地理解和利用外部知识，从而提供更智能、更可靠的服务。相信随着技术的不断进步，RAG将在各个领域发挥越来越重要的作用，为我们的生活带来更多便利。\n","date":"2024-10-12T19:22:39+08:00","permalink":"http://localhost:1313/post/retrieval-augmented-generation/","title":"从信息检索到文本生成：RAG如何让AI更懂你？"},{"content":"搜索无处不在，作为信息化时代大多数人获取信息的最重要的路径，说搜索引擎是使用最为广泛和频繁的中间件之一，应该没有人会反驳。在实际的应用场景中， 小到个人博客， 大到电商平台，你在谷歌上搜索的每一个关键字， 在电商网站上搜索的每一件商品， 追剧听音乐的时候在搜索栏输入的每一个名字的背后都是搜索引擎的处理和输出。就像是你提问，然后搜索引擎告诉你一个答案，搜索不仅无处不在，无所不知，默默的主宰着网络世界的入口。\n什么是搜索引擎 搜索引擎是一种在线搜索工具，旨在根据用户的搜索查询在网络上收集合适的网站存入自己的数据库中，然后使用独特的算法对它们进行排序。当用户在搜索框输入关键词时，搜索引擎就会将对应的内容展示给用户。\n搜索引擎的工作原理 搜索引擎的工作原理可以简单概括为以下 4 个步骤：\n爬取网页： 搜索引擎会派出名为“网络爬虫”的程序，像蜘蛛一样在互联网上爬行，访问各个网站，收集网页内容。 爬虫会从一个种子 URL 列表开始，然后沿着网页上的链接不断爬取新的页面并存储到搜索引擎的数据库中。 为了避免过度消耗网站资源，爬虫会遵守 robots.txt 协议，并控制爬取频率。\n爬虫发现新页面的主要跟踪方法是已知的网页中的链接。从A页面上的超链接可以发现 B 页面、C 页面等，搜索引擎蜘蛛会将这些网页存储起来，当做下次访问的对象。正是基于这点，所以我们要避免某个网页成为“孤岛页面”，也就是没有任何链接指向它。\nrobots.txt\nrobots.txt 是一个纯文本文件，是网站管理者用来与网络爬虫进行沟通的工具。它遵循 Robots 排除协议 (Robots Exclusion Protocol)，通过简单的指令告诉爬虫哪些页面可以抓取，哪些页面应该避免。\nrobots.txt 的作用：\n控制爬虫访问： 网站管理者可以通过 robots.txt 文件限制某些爬虫访问网站的特定部分，例如后台管理页面、用户个人信息等，保护敏感数据和网站安全。 优化爬虫效率： 通过引导爬虫抓取重要页面，避免爬虫浪费资源在无关紧要的内容上，可以提高爬虫效率，减轻网站服务器负担。 避免重复内容： 网站管理者可以使用 robots.txt 文件阻止爬虫抓取重复内容的页面，例如打印友好页面、搜索结果页面等，有利于提升网站在搜索引擎中的排名。 robots.txt 的语法： robots.txt 文件的语法非常简单，主要由以下两个指令构成：\nUser-agent: 指定该规则适用于哪些爬虫。例如，User-agent: * 表示该规则适用于所有爬虫，User-agent: Googlebot 表示该规则仅适用于 Google 的爬虫。\nDisallow: 指定不允许爬虫访问的路径。例如，Disallow: /admin/ 表示不允许爬虫访问 /admin/ 目录下的所有内容。\n需要注意：\nrobots.txt 只是一个“君子协议”，它依赖于爬虫的自觉遵守。一些恶意的爬虫可能会无视 robots.txt 文件的限制。\nrobots.txt 文件不能阻止网页被索引。即使爬虫不能抓取某个页面，如果该页面被其他页面链接，它仍然可能出现在搜索引擎结果中。\n如果需要更严格地控制页面索引，可以使用 noindex 元标签。\n建立索引： 将爬虫收集到的网页经过分析处理后，搜索引擎会将这些信息进行索引。索引的过程类似于图书馆的索引系统，目的是为快速查找内容而构建一个高效的数据结构。 在索引过程中，搜索引擎会分析页面中的文本内容、关键词、图片、视频等，并构建倒排索引（Inverted Index）。\n倒排索引\n倒排索引将每个单词或短语与它在各个页面中出现的位置进行关联，这样当用户输入查询时，搜索引擎可以迅速地查找到所有包含这些单词的页面。这个索引结构大大提高了搜索引擎的查询效率。\n处理搜索请求： 理解用户意图： 当你输入关键词进行搜索时，搜索引擎会首先尝试理解你的搜索意图。 搜索引擎会分析你的搜索关键词、搜索历史、地理位置等信息，来判断你真正想要查找的内容。 例如，你搜索“苹果”，搜索引擎需要判断你是想了解水果“苹果”，还是科技公司“苹果”。\n匹配关键词： 搜索引擎会根据你的搜索关键词，在索引库中查找包含这些关键词的网页。 搜索引擎会使用各种算法来计算网页与搜索关键词的相关性。 例如，关键词出现的频率、位置、网页的权威性等因素都会影响相关性得分。\n排序和展示结果： 相关性排序： 搜索引擎会根据一系列复杂的算法，对找到的网页进行排序。相关性越高的网页，排名越靠前。 除了相关性，搜索引擎还会考虑其他因素，例如网页的权威性、新鲜度、用户的点击行为等。 例如，一个来自权威网站、内容新鲜、用户点击率高的网页，排名会相对靠前。\n展示搜索结果： 最后，搜索引擎会将排序后的结果以列表的形式展示给你，通常包括网页标题、摘要、链接等信息。 搜索引擎会使用各种技术来优化搜索结果的展示，例如摘要生成、关键词高亮、相关搜索推荐等。 例如，搜索引擎会根据网页内容生成简洁明了的摘要，并将搜索关键词高亮显示，方便用户快速浏览。\n搜索引擎的关键技术 1.自然语言处理（NLP）\n自然语言处理是让计算机理解人类语言的技术。搜索引擎需要使用NLP来处理用户的查询，并将其与网页内容进行匹配。例如，NLP可以帮助搜索引擎识别同义词、理解多义词的不同含义、进行文本的情感分析等。\n2.机器学习与人工智能（AI）\n机器学习和AI在搜索引擎中的应用越来越广泛，特别是在排序和个性化推荐方面。搜索引擎会使用机器学习算法对用户行为进行分析，以便预测用户的需求，并根据用户的历史搜索记录、位置、兴趣等信息提供个性化的搜索结果。\n例如，谷歌的RankBrain算法就是基于人工智能的一个搜索算法，它通过分析大量数据来判断搜索结果的相关性，并不断学习和改进。\n3.大数据与分布式计算\n搜索引擎需要处理的网页数据量非常庞大，因此大数据和分布式计算技术在搜索引擎中起到了至关重要的作用。分布式计算通过将任务分配到多个服务器上，解决了海量数据处理的瓶颈问题，保证了搜索引擎的高效性和可扩展性。\n4.信息检索技术\n信息检索是搜索引擎的核心技术之一，它涉及如何从海量数据中快速找到相关信息。倒排索引、布尔检索、向量空间模型等都是经典的信息检索技术。现代搜索引擎还引入了深度学习等先进的技术，进一步提升了搜索精度。\n总结 虽然看起来搜索引擎的原理非常简单，但是搜索引擎实际上是个非常之复杂的系统工程。分布式的海量数据存储、超高并发的读写、搜索的速度和精确度要求、不同类型结果的渲染展示等等，每一项都面临着对应技术领域天花板级别的挑战。本文只是尝试简单的来了解搜索引擎基本原理、工作流程、运行机制。\n","date":"2024-09-05T13:25:17+08:00","permalink":"http://localhost:1313/post/search-engine-principles/","title":"搜索引擎原理入门"},{"content":"很多程序员都会在 GitHub Pages 上搭建自己的个人博客用于分享和交流技术，对于个人博客，没有被搜索引擎收录的话，别人基本是是看不到的，再好的技术文无法被分享也是白搭。\n基于 GitHub Pages 的个人博客， Google 收录非常及时全面。然而，到目前为止，GitHub 还是拒绝百度爬虫的访问，直接返回 403。 官方给出原因是，百度爬虫爬得太狠，影响了 Github Pages 服务的正常使用。这就导致了，但凡在 Github Pages 搭建的个人博客，都无法被百度收录。\n注册登录 打开 https://vercel.com/，点击右上角的 Log In, 使用 GitHub 账号登录。授予 zeit repo 的 read 权限\n部署项目 导入 GitHub 博客 repo\n等待部署成功\n配置域名 点击 Domains 进入域名配置页面,添加域名\n添加好后到域名服务商处添加 CNAME 解析即可\n百度 在 百度搜索资源平台 添加个人网站就行。这里注意选择 https 协议，因为 zeit 默认都是 https 了。\n网站验证我采用的是文件验证，下载验证文件放在你博客本地 repo 的 source 目录下，部署到 GitHub，当然也会及时更新到 zeit。然后完成验证就好了，试一下链接诊断，看能不能正常抓取，失败的话，看看抓取的 ip 地址是不是还是之前的缓存，等待一段时间重新抓取下，时间取决于 dns 的 ttl。\n","date":"2024-04-08T18:20:39+08:00","permalink":"http://localhost:1313/post/baidu-include-github-pages-blog/","title":"如何使用 zeit.co 让百度收录 GitHub Pages 博客"},{"content":"本文译自 Building Blockchain in Go. Part 4: Transactions 1\n简介 交易是比特币的核心，区块链的唯一目的是以安全可靠的方式存储交易，因此在创建交易后没有人可以修改它们。 今天我们开始实施交易。 但因为这是一个相当大的主题，所以我将其分为两部分：在这一部分中，我们将实现交易的一般机制，在第二部分中我们将讨论细节。\n另外，由于代码更改很大，因此在这里描述所有更改是没有意义的。 您可以在这里看到所有更改。\n相较于传统支付 如果您曾经开发过 Web 应用程序，为了实现付款，您可能会在数据库中创建这些表：帐户和交易。 帐户将存储有关用户的信息，包括他们的个人信息和余额，而交易将存储有关从一个帐户转移到另一个帐户的资金的信息。 在比特币中，支付是以完全不同的方式实现的。 在这里：\n没有账户。 没有余额。 没有地址。 没有币。 没有发送者和接收者。 由于区块链是一个公共且开放的数据库，我们不想存储有关钱包所有者的敏感信息。 币不收集在帐户中。 交易不会将资金从一个地址转移到另一个地址。 没有保存帐户余额的字段或属性。 只有交易。 那么交易里面有什么？\n比特币交易 交易是输入和输出的组合：\n1 2 3 4 5 type Transaction struct { ID []byte Vin []TXInput Vout []TXOutput } 新交易的输入引用先前交易的输出（不过有一个例外，我们将在稍后讨论）。 输出是实际存储币的地方。 下图展示了交易的互连：\n请注意：\n有些输出未链接到输入。 在一笔交易中，输入可以引用多个交易的输出。 输入必须引用输出。 在整篇文章中，我们将使用“钱”、“币”、“花费”、“发送”、“账户”等词语。但比特币中没有这样的概念。 交易只是用脚本锁定值，该脚本只能由锁定它们的人解锁。\n交易输出 让我们首先从输出开始：\n1 2 3 4 type TXOutput struct { Value int ScriptPubKey string } 实际上，它是存储“币”的输出（注意上面的值字段）。 存储意味着用一个数学迷题锁定它们，该谜题存储在 ScriptPubKey 中。 在内部，比特币使用一种称为 Script 的脚本语言，用于定义输出锁定和解锁逻辑。 该语言非常原始（这是有意为之，以避免可能的黑客攻击和误用），但我们不会详细讨论它。 您可以在这里找到它的详细解释。\n在比特币中，value字段存储的是satoshis的数量，而不是BTC的数量。 聪是比特币的一亿分之一（0.00000001 BTC），因此这是比特币中最小的货币单位（如美分）。\n由于我们没有实现地址，因此我们现在将避免整个脚本相关逻辑。 ScriptPubKey 将存储任意字符串（用户定义的钱包地址）。\n顺便说一句，拥有这样的脚本语言意味着比特币也可以用作智能合约平台。\n关于输出的一个重要的事情是它们是不可分割的，这意味着您不能引用其值的一部分。 当新交易中引用输出时，它会作为一个整体被使用。 如果其值大于所需值，则会生成更改并将其发送回发送者。 这类似于现实世界的情况，例如，您用 5 美元的钞票购买 1 美元的商品，然后找回 4 美元。\n交易输入 这是输入：\n1 2 3 4 5 type TXInput struct { Txid []byte Vout int ScriptSig string } 如前所述，输入引用先前的输出：Txid 存储该交易的 ID，Vout 存储交易中输出的索引。 ScriptSig 是一个脚本，提供在输出的 ScriptPubKey 中使用的数据。 如果数据正确，则可以解锁输出，并且其值可以用于生成新的输出； 如果不正确，则无法在输入中引用输出。 这是保证用户不能花费属于其他人的币的机制。\n同样，由于我们还没有实现地址，ScriptSig 将仅存储任意用户定义的钱包地址。 我们将在下一篇文章中实现公钥和签名检查。\n让我们总结一下。 输出是存储“币”的地方。 每个输出都带有一个解锁脚本，它决定了解锁输出的逻辑。 每笔新交易必须至少有一个输入和输出。 输入引用先前交易的输出，并提供在输出的解锁脚本中使用的数据（ScriptSig 字段）来解锁它并使用其值创建新的输出。\n但先有什么：输入还是输出？\n先有鸡还是先有蛋 在比特币中，先有蛋，后有鸡。 输入-引用-输出逻辑是经典的“先有鸡还是先有蛋”的情况：输入产生输出，输出使输入成为可能。 在比特币中，输出先于输入。\n当矿工开始挖掘一个区块时，它会向其中添加一个 coinbase 交易。 coinbase 交易是一种特殊类型的交易，不需要先前存在的输出。 它凭空创造输出（即“币”）。 有蛋无鸡。 这是矿工开采新区块所获得的奖励。\n如您所知，区块链的开头有创世块。 正是这个区块生成了区块链中的第一个输出。 并且不需要先前的输出，因为没有先前的交易，也没有这样的输出。\n让我们创建一个 coinbase 交易：\n1 2 3 4 5 6 7 8 9 10 11 12 func NewCoinbaseTX(to, data string) *Transaction { if data == \u0026#34;\u0026#34; { data = fmt.Sprintf(\u0026#34;Reward to \u0026#39;%s\u0026#39;\u0026#34;, to) } txin := TXInput{[]byte{}, -1, data} txout := TXOutput{subsidy, to} tx := Transaction{nil, []TXInput{txin}, []TXOutput{txout}} tx.SetID() return \u0026amp;tx } 一笔 coinbase 交易只有一个输入。在我们的实现中，它的 Txid 为空，Vout 等于 -1。此外，coinbase 交易不会在 ScriptSig 中存储脚本。相反，任意数据都存储在那里。\n在比特币中，第一笔 Coinbase 交易包含以下消息：“泰晤士报 2009 年 1 月 3 日财政大臣即将对银行进行第二次救助”。你可以自己看看。\n补贴是奖励的金额。 在比特币中，这个数字不存储在任何地方，仅根据区块总数计算：区块数量除以210000。挖掘创世区块产生50 BTC，每210000个区块奖励减半。 在我们的实现中，我们将把奖励存储为常量（至少现在是这样😉）。\n在区块链中存储交易 从现在开始，每个区块必须存储至少一笔交易，并且不再可能在没有交易的情况下挖掘区块。这意味着我们应该删除块的数据字段并存储交易：\n1 2 3 4 5 6 7 type Block struct { Timestamp int64 Transactions []*Transaction PrevBlockHash []byte Hash []byte Nonce int } NewBlock 和 NewGenesisBlock 也必须相应更改：\n1 2 3 4 5 6 7 8 func NewBlock(transactions []*Transaction, prevBlockHash []byte) *Block { block := \u0026amp;Block{time.Now().Unix(), transactions, prevBlockHash, []byte{}, 0} ... } func NewGenesisBlock(coinbase *Transaction) *Block { return NewBlock([]*Transaction{coinbase}, []byte{}) } 接下来要改变的是创建一个新的区块链：\n1 2 3 4 5 6 7 8 9 10 11 12 func CreateBlockchain(address string) *Blockchain { ... err = db.Update(func(tx *bolt.Tx) error { cbtx := NewCoinbaseTX(address, genesisCoinbaseData) genesis := NewGenesisBlock(cbtx) b, err := tx.CreateBucket([]byte(blocksBucket)) err = b.Put(genesis.Hash, genesis.Serialize()) ... }) ... } 现在，该函数采用一个地址，该地址将获得挖掘创世块的奖励。\n工作量证明 工作量证明算法必须考虑存储在区块中的交易，以保证区块链作为交易存储的一致性和可靠性。所以现在我们必须修改 ProofOfWork.prepareData 方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func (pow *ProofOfWork) prepareData(nonce int) []byte { data := bytes.Join( [][]byte{ pow.block.PrevBlockHash, pow.block.HashTransactions(), // This line was changed IntToHex(pow.block.Timestamp), IntToHex(int64(targetBits)), IntToHex(int64(nonce)), }, []byte{}, ) return data } 我们现在使用 pow.block.HashTransactions() 代替 pow.block.Data，它是：\n1 2 3 4 5 6 7 8 9 10 11 func (b *Block) HashTransactions() []byte { var txHashes [][]byte var txHash [32]byte for _, tx := range b.Transactions { txHashes = append(txHashes, tx.ID) } txHash = sha256.Sum256(bytes.Join(txHashes, []byte{})) return txHash[:] } 同样，我们使用哈希作为提供唯一数据表示的机制。 我们希望块中的所有交易都由单个哈希值唯一标识。 为了实现这一点，我们获取每个交易的哈希值，将它们连接起来，并获得连接组合的哈希值。\n比特币使用了一种更复杂的技术：它将块中包含的所有交易表示为 Merkle 树，并在工作量证明系统中使用树的根哈希。 这种方法允许快速检查一个块是否包含特定交易，仅具有根哈希而无需下载所有交易。\n让我们检查一下到目前为止一切是否正确：\n1 2 3 4 $ blockchain_go createblockchain -address Ivan 00000093450837f8b52b78c25f8163bb6137caf43ff4d9a01d1b731fa8ddcc8a Done! 好的！我们收到了第一笔挖矿奖励。但我们如何查看余额呢？\n未花费的交易输出 我们需要找到所有未花费的交易输出（UTXO）。 未花费意味着这些输出没有在任何输入中引用。 在上图中，这些是：\ntx0，输出1； tx1，输出0； tx3，输出0； tx4，输出0。 当然，当我们检查余额时，我们不需要全部，而只需要那些可以用我们拥有的密钥解锁的（目前我们没有实现密钥，将使用用户定义的地址代替）。 首先，我们定义输入和输出的锁定/解锁方法：\n1 2 3 4 5 6 7 func (in *TXInput) CanUnlockOutputWith(unlockingData string) bool { return in.ScriptSig == unlockingData } func (out *TXOutput) CanBeUnlockedWith(unlockingData string) bool { return out.ScriptPubKey == unlockingData } 这里我们只是将脚本字段与unlockingData进行比较。在我们实现基于私钥的地址之后，这些部分将在以后的文章中得到改进。\n下一步 - 查找包含未使用输出的交易 - 非常困难：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 func (bc *Blockchain) FindUnspentTransactions(address string) []Transaction { var unspentTXs []Transaction spentTXOs := make(map[string][]int) bci := bc.Iterator() for { block := bci.Next() for _, tx := range block.Transactions { txID := hex.EncodeToString(tx.ID) Outputs: for outIdx, out := range tx.Vout { // Was the output spent? if spentTXOs[txID] != nil { for _, spentOut := range spentTXOs[txID] { if spentOut == outIdx { continue Outputs } } } if out.CanBeUnlockedWith(address) { unspentTXs = append(unspentTXs, *tx) } } if tx.IsCoinbase() == false { for _, in := range tx.Vin { if in.CanUnlockOutputWith(address) { inTxID := hex.EncodeToString(in.Txid) spentTXOs[inTxID] = append(spentTXOs[inTxID], in.Vout) } } } } if len(block.PrevBlockHash) == 0 { break } } return unspentTXs } 由于交易存储在区块中，因此我们必须检查区块链中的每个区块。我们从输出开始：\n1 2 3 if out.CanBeUnlockedWith(address) { unspentTXs = append(unspentTXs, tx) } 如果输出被我们正在搜索未使用交易输出的同一地址锁定，那么这就是我们想要的输出。但在获取之前，我们需要检查输入中是否已经引用了输出：\n1 2 3 4 5 6 7 if spentTXOs[txID] != nil { for _, spentOut := range spentTXOs[txID] { if spentOut == outIdx { continue Outputs } } } 我们跳过输入中引用的那些（它们的值已移至其他输出，因此我们无法对它们进行计数）。 检查输出后，我们收集所有可以解锁使用所提供的地址锁定的输出的输入（这不适用于 coinbase 交易，因为它们不解锁输出）：\n1 2 3 4 5 6 7 8 if tx.IsCoinbase() == false { for _, in := range tx.Vin { if in.CanUnlockOutputWith(address) { inTxID := hex.EncodeToString(in.Txid) spentTXOs[inTxID] = append(spentTXOs[inTxID], in.Vout) } } } 该函数返回包含未花费输出的交易列表。为了计算余额，我们还需要一个函数来接受交易并仅返回输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func (bc *Blockchain) FindUTXO(address string) []TXOutput { var UTXOs []TXOutput unspentTransactions := bc.FindUnspentTransactions(address) for _, tx := range unspentTransactions { for _, out := range tx.Vout { if out.CanBeUnlockedWith(address) { UTXOs = append(UTXOs, out) } } } return UTXOs } 就是这样！现在我们可以实现 getbalance 命令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 func (cli *CLI) getBalance(address string) { bc := NewBlockchain(address) defer bc.db.Close() balance := 0 UTXOs := bc.FindUTXO(address) for _, out := range UTXOs { balance += out.Value } fmt.Printf(\u0026#34;Balance of \u0026#39;%s\u0026#39;: %d\\n\u0026#34;, address, balance) } 账户余额是该账户地址锁定的所有未花费交易输出值的总和。\n让我们在挖掘创世块后检查一下我们的余额：\n1 2 $ blockchain_go getbalance -address Ivan Balance of \u0026#39;Ivan\u0026#39;: 10 这是我们的第一笔钱！\n发送币 现在，我们想发送一些币给其他人。 为此，我们需要创建一个新交易，将其放入一个区块中，然后挖掘该区块。 到目前为止，我们只实现了coinbase交易（这是一种特殊类型的交易），现在我们需要一个通用交易：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 func NewUTXOTransaction(from, to string, amount int, bc *Blockchain) *Transaction { var inputs []TXInput var outputs []TXOutput acc, validOutputs := bc.FindSpendableOutputs(from, amount) if acc \u0026lt; amount { log.Panic(\u0026#34;ERROR: Not enough funds\u0026#34;) } // Build a list of inputs for txid, outs := range validOutputs { txID, err := hex.DecodeString(txid) for _, out := range outs { input := TXInput{txID, out, from} inputs = append(inputs, input) } } // Build a list of outputs outputs = append(outputs, TXOutput{amount, to}) if acc \u0026gt; amount { outputs = append(outputs, TXOutput{acc - amount, from}) // a change } tx := Transaction{nil, inputs, outputs} tx.SetID() return \u0026amp;tx } 在创建新的输出之前，我们首先必须找到所有未使用的输出并确保它们存储足够的价值。 这就是 FindSpendableOutputs 方法的作用。 之后，为每个找到的输出创建引用它的输入。 接下来，我们创建两个输出：\n一个与接收者地址锁定的。 这是实际将币转移到其他地址。 与发件人地址锁定的一种。 这是一个改变。 仅当未花费的输出所具有的价值高于新交易所需的价值时，才会创建它。 请记住：输出是不可分割的。 FindSpendableOutputs 方法基于我们之前定义的\nFindUnspentTransactions 方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func (bc *Blockchain) FindSpendableOutputs(address string, amount int) (int, map[string][]int) { unspentOutputs := make(map[string][]int) unspentTXs := bc.FindUnspentTransactions(address) accumulated := 0 Work: for _, tx := range unspentTXs { txID := hex.EncodeToString(tx.ID) for outIdx, out := range tx.Vout { if out.CanBeUnlockedWith(address) \u0026amp;\u0026amp; accumulated \u0026lt; amount { accumulated += out.Value unspentOutputs[txID] = append(unspentOutputs[txID], outIdx) if accumulated \u0026gt;= amount { break Work } } } } return accumulated, unspentOutputs } 该方法迭代所有未花费的交易并累积它们的值。 当累计值大于或等于我们要转移的金额时，它会停止并返回按交易 ID 分组的累计值和输出索引。 我们不想拿的比我们花的多。\n现在我们可以修改Blockchain.MineBlock方法：\n1 2 3 4 5 func (bc *Blockchain) MineBlock(transactions []*Transaction) { ... newBlock := NewBlock(transactions, lastHash) ... } 最后，我们来实现发送命令：\n1 2 3 4 5 6 7 8 func (cli *CLI) send(from, to string, amount int) { bc := NewBlockchain(from) defer bc.db.Close() tx := NewUTXOTransaction(from, to, amount, bc) bc.MineBlock([]*Transaction{tx}) fmt.Println(\u0026#34;Success!\u0026#34;) } 发送币意味着创建交易并通过挖掘区块将其添加到区块链中。 但比特币并不会立即做到这一点（就像我们一样）。 相反，它将所有新交易放入内存池（或mempool）中，当矿工准备好挖掘一个块时，它会从mempool中取出所有交易并创建一个候选块。 仅当包含交易的区块被开采并添加到区块链时，交易才会被确认。\n让我们检查一下发送币是否有效：\n1 2 3 4 5 6 7 8 9 10 $ blockchain_go send -from Ivan -to Pedro -amount 6 00000001b56d60f86f72ab2a59fadb197d767b97d4873732be505e0a65cc1e37 Success! $ blockchain_go getbalance -address Ivan Balance of \u0026#39;Ivan\u0026#39;: 4 $ blockchain_go getbalance -address Pedro Balance of \u0026#39;Pedro\u0026#39;: 6 好的！现在，让我们创建更多交易并确保从多个输出发送工作正常：\n1 2 3 4 5 6 7 8 9 $ blockchain_go send -from Pedro -to Helen -amount 2 00000099938725eb2c7730844b3cd40209d46bce2c2af9d87c2b7611fe9d5bdf Success! $ blockchain_go send -from Ivan -to Helen -amount 2 000000a2edf94334b1d94f98d22d7e4c973261660397dc7340464f7959a7a9aa Success! 现在，海伦的币被锁定在两个输出中：一个来自佩德罗，一个来自伊万。让我们将它们发送给其他人：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 $ blockchain_go send -from Helen -to Rachel -amount 3 000000c58136cffa669e767b8f881d16e2ede3974d71df43058baaf8c069f1a0 Success! $ blockchain_go getbalance -address Ivan Balance of \u0026#39;Ivan\u0026#39;: 2 $ blockchain_go getbalance -address Pedro Balance of \u0026#39;Pedro\u0026#39;: 4 $ blockchain_go getbalance -address Helen Balance of \u0026#39;Helen\u0026#39;: 1 $ blockchain_go getbalance -address Rachel Balance of \u0026#39;Rachel\u0026#39;: 3 看起来不错！现在我们来测试一下失败情况：\n1 2 3 4 5 6 7 8 $ blockchain_go send -from Pedro -to Ivan -amount 5 panic: ERROR: Not enough funds $ blockchain_go getbalance -address Pedro Balance of \u0026#39;Pedro\u0026#39;: 4 $ blockchain_go getbalance -address Ivan Balance of \u0026#39;Ivan\u0026#39;: 2 结论 唷！ 这并不容易，但我们现在有交易了！ 尽管如此，类似比特币的加密货币缺少一些关键特征：\n地址。 我们还没有真正的、基于私钥的地址。 奖励。 开采区块绝对不赚钱！ UTXO 设置。 获得平衡需要扫描整个区块链，当区块数量很多时，这可能需要很长时间。 此外，如果我们想验证以后的交易，可能会花费很多时间。 UTXO集合旨在解决这些问题并使交易操作变得快速。 内存池。 这是交易在打包到区块之前存储的地方。 在我们当前的实现中，一个区块只包含一个交易，这是相当低效的。 ","date":"2023-12-13T10:54:23+08:00","permalink":"http://localhost:1313/post/building-blockchain-in-go-part-4/","title":"在Go中构建区块链-4-交易-1"},{"content":"本文译自 Building Blockchain in Go. Part 3: Persistence and CLI\n简介 到目前为止，我们已经构建了一个具有工作量证明系统的区块链，这使得挖矿成为可能。我们的实现越来越接近一个完全功能的区块链，但仍然缺少一些重要的功能。今天我们将开始将区块链存储在数据库中，之后我们将创建一个简单的命令行界面来执行与区块链相关的操作。在本质上，区块链是一个分布式数据库。我们将暂时省略“分布式”部分，专注于“数据库”部分。\n数据库选择 目前，我们的实现中没有数据库；相反，每次运行程序时，我们都会创建新的区块并将其存储在内存中。我们无法重复使用区块链，也无法与他人共享，因此我们需要将其存储在磁盘上。\n我们需要哪种数据库？实际上，任何数据库都可以。在原始的比特币论文中，并未提及使用特定的数据库，因此由开发人员决定使用哪个数据库。比特币核心（最初由中本聪发布，目前是比特币的参考实现）使用LevelDB（尽管它仅在2012年才引入到客户端）。而我们将使用\u0026hellip;\nBoltDB 因为：\n它简单而简约。 它是用Go语言实现的。 它不需要运行服务器。 它允许构建我们想要的数据结构。 从BoltDB在GitHub上的README中：\nBolt是一种纯Go键/值存储，灵感来自Howard Chu的LMDB项目。该项目的目标是为那些不需要像Postgres或MySQL这样的完整数据库服务器的项目提供一个简单、快速且可靠的数据库。\n由于Bolt旨在作为这样一个低级功能来使用，简单性至关重要。API 将很小，并且仅关注获取值和设置值。就是这样。\n听起来完全符合我们的需求！让我们花一分钟来了解一下。\nBoltDB是一种键/值存储，这意味着没有像 SQL 关系型数据库管理系统（MySQL、PostgreSQL等）中的表，也没有行、列。相反，数据存储为键-值对（类似于 Golang 中的映射）。键-值对存储在桶中，桶旨在组织类似的键-值对（这类似于关系型数据库管理系统中的表）。因此，为了获取一个值，您需要知道一个桶和一个键。\n关于BoltDB的一件重要的事情是它没有数据类型：键和值都是字节数组。由于我们将在其中存储Go结构体（特别是Block），我们需要对它们进行序列化，即实现一种将Go结构体转换为字节数组并从字节数组还原的机制。我们将使用 encoding/gob 进行此操作，但也可以使用 JSON、XML、Protocol Buffers 等。我们使用 encoding/gob 是因为它简单且是Go标准库的一部分。\n数据库结构 在开始实现持久性逻辑之前，我们首先需要决定如何在数据库中存储数据。为此，我们将参考比特币核心的存储方式。\n简单来说，比特币核心使用两个“buckets（桶）”来存储数据：\nblocks 存储描述链中所有区块的元数据。 chainstate 存储链的状态，即所有当前未花费的交易输出和一些元数据。 此外，区块以单独的文件形式存储在磁盘上。这是出于性能考虑：读取单个区块不需要将所有（或一些）区块加载到内存中。我们不会实现这一点。\n在 blocks 中，键值对如下：\n\u0026lsquo;b\u0026rsquo; + 32字节的区块哈希 -\u0026gt; 区块索引记录 \u0026lsquo;f\u0026rsquo; + 4字节的文件号 -\u0026gt; 文件信息记录 \u0026rsquo;l\u0026rsquo; -\u0026gt; 4字节的文件号：最后一个使用的区块文件号 \u0026lsquo;R\u0026rsquo; -\u0026gt; 1字节的布尔值：是否正在重新索引的过程中 \u0026lsquo;F\u0026rsquo; + 1字节的标志名长度 + 标志名字符串 -\u0026gt; 1字节的布尔值：各种可能打开或关闭的标志 \u0026rsquo;t\u0026rsquo; + 32字节的交易哈希 -\u0026gt; 交易索引记录 在 chainstate 中，键值对如下：\n\u0026lsquo;c\u0026rsquo; + 32字节的交易哈希 -\u0026gt; 该交易的未花费交易输出记录\n\u0026lsquo;B\u0026rsquo; -\u0026gt; 32字节的区块哈希：数据库表示未花费交易输出的区块哈希\n（详细的解释可以在这里找到）\n由于我们还没有交易，我们将只使用 blocks 桶。此外，如上所述，我们将整个数据库存储为单个文件，而不是将区块存储在单独的文件中。因此，我们将不需要与文件号相关的任何内容。因此，这些是我们将使用的键值对：\n32字节的区块哈希 -\u0026gt; 区块结构（序列化） \u0026rsquo;l\u0026rsquo; -\u0026gt; 链中最后一个区块的哈希 这就是我们开始实现持久性机制所需要知道的一切。\n序列化 如前所述，在BoltDB中，值只能是[]byte类型，而我们想要在数据库中存储Block结构体。我们将使用 encoding/gob 来序列化结构体。\n让我们实现Block的Serialize方法（为简洁起见，省略了错误处理）：\n1 2 3 4 5 6 7 8 func (b *Block) Serialize() []byte { var result bytes.Buffer encoder := gob.NewEncoder(\u0026amp;result) err := encoder.Encode(b) return result.Bytes() } 这一部分很简单：首先，我们声明一个缓冲区，用于存储序列化数据；然后，我们初始化一个gob编码器并对区块进行编码；最后，将结果作为字节数组返回。\n接下来，我们需要一个反序列化函数，它将接收一个字节数组作为输入，并返回一个Block。这不会是一个方法，而是一个独立的函数：\n1 2 3 4 5 6 7 8 func DeserializeBlock(d []byte) *Block { var block Block decoder := gob.NewDecoder(bytes.NewReader(d)) err := decoder.Decode(\u0026amp;block) return \u0026amp;block } 这就是系列化的内容！\n持久性 让我们从NewBlockchain函数开始。目前，它创建了一个Blockchain的新实例并将创世块添加到其中。我们希望它执行以下操作：\n打开一个DB文件。 检查是否有存储在其中的区块链。 如果存在区块链： 创建一个新的Blockchain实例。 将Blockchain实例的尖端设置为存储在DB中的最后一个区块哈希。 如果没有现有的区块链： 创建创世块。 存储在DB中。 将创世块的哈希保存为最后一个区块哈希。 创建一个新的Blockchain实例，其尖端指向创世块。 在代码中，它看起来像这样：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 func NewBlockchain() *Blockchain { var tip []byte db, err := bolt.Open(dbFile, 0600, nil) err = db.Update(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(blocksBucket)) if b == nil { genesis := NewGenesisBlock() b, err := tx.CreateBucket([]byte(blocksBucket)) err = b.Put(genesis.Hash, genesis.Serialize()) err = b.Put([]byte(\u0026#34;l\u0026#34;), genesis.Hash) tip = genesis.Hash } else { tip = b.Get([]byte(\u0026#34;l\u0026#34;)) } return nil }) bc := Blockchain{tip, db} return \u0026amp;bc } 让我们一块一块地回顾一下。\n1 db, err := bolt.Open(dbFile, 0600, nil) 这是打开 BoltDB 文件的标准方法。请注意，如果没有这样的文件，它不会返回错误。\n1 2 3 err = db.Update(func(tx *bolt.Tx) error { ... }) 在 BoltDB 中，数据库操作在事务内运行。事务有两种类型：只读和读写。在这里，我们打开一个读写事务（db.Update(\u0026hellip;)），因为我们希望将创世块放入数据库中。\n1 2 3 4 5 6 7 8 9 10 11 b := tx.Bucket([]byte(blocksBucket)) if b == nil { genesis := NewGenesisBlock() b, err := tx.CreateBucket([]byte(blocksBucket)) err = b.Put(genesis.Hash, genesis.Serialize()) err = b.Put([]byte(\u0026#34;l\u0026#34;), genesis.Hash) tip = genesis.Hash } else { tip = b.Get([]byte(\u0026#34;l\u0026#34;)) } 这是该函数的核心。 在这里，我们获取存储块的存储桶：如果存在，我们从中读取 l 键； 如果不存在，我们生成创世块，创建存储桶，将块保存到其中，并更新存储链的最后一个块哈希的 l 键。\n另外，请注意创建区块链的新方法：\n1 bc := Blockchain{tip, db} 我们不再将所有区块都存储在其中，而只存储链的尖端。此外，我们存储了一个数据库连接，因为我们希望在程序运行时只打开一次，并保持其打开状态。因此，Blockchain结构现在如下所示：\n1 2 3 4 type Blockchain struct { tip []byte db *bolt.DB } 接下来我们要更新的是AddBlock方法：现在添加区块到链上不再像在数组中添加元素那样简单。从现在开始，我们将在数据库中存储区块：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func (bc *Blockchain) AddBlock(data string) { var lastHash []byte err := bc.db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(blocksBucket)) lastHash = b.Get([]byte(\u0026#34;l\u0026#34;)) return nil }) newBlock := NewBlock(data, lastHash) err = bc.db.Update(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(blocksBucket)) err := b.Put(newBlock.Hash, newBlock.Serialize()) err = b.Put([]byte(\u0026#34;l\u0026#34;), newBlock.Hash) bc.tip = newBlock.Hash return nil }) } 让我们逐条回顾一下：\n1 2 3 4 5 6 err := bc.db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(blocksBucket)) lastHash = b.Get([]byte(\u0026#34;l\u0026#34;)) return nil }) 这是 BoltDB 事务的另一种（只读）类型。在这里，我们从数据库中获取最后一个块哈希，并用它来挖掘新的块哈希。\n1 2 3 4 5 newBlock := NewBlock(data, lastHash) b := tx.Bucket([]byte(blocksBucket)) err := b.Put(newBlock.Hash, newBlock.Serialize()) err = b.Put([]byte(\u0026#34;l\u0026#34;), newBlock.Hash) bc.tip = newBlock.Hash 挖掘新块后，我们将其序列化表示保存到数据库中并更新 l 键，该键现在存储新块的哈希值。\n完毕！这并不难，不是吗？\n检查区块链 所有新的区块现在都保存在数据库中，因此我们可以重新打开区块链并向其添加新的区块。但在实现这一点后，我们失去了一个很好的功能：我们不能再打印出区块链块，因为我们不再将块存储在数组中。让我们修复这个缺陷！\nBoltDB允许在一个桶中迭代所有键，但这些键是按字节排序的，而我们希望按照它们在区块链中的顺序打印出区块。此外，由于我们不想将所有区块加载到内存中（我们的区块链数据库可能非常庞大！..或者我们就假装它可能非常庞大），我们将逐个读取它们。为此，我们将需要一个区块链迭代器：\n1 2 3 4 type BlockchainIterator struct { currentHash []byte db *bolt.DB } 每当我们想要在区块链中迭代区块时，都将创建一个迭代器，它将存储当前迭代的区块哈希和到DB的连接。由于后者，迭代器在逻辑上与区块链相关联（它是一个存储DB连接的Blockchain实例），因此它是在Blockchain方法中创建的：\n1 2 3 4 5 func (bc *Blockchain) Iterator() *BlockchainIterator { bci := \u0026amp;BlockchainIterator{bc.tip, bc.db} return bci } 注意，迭代器最初指向区块链的尖端，因此区块将从顶部到底部获取，从最新到最旧。实际上，选择一个尖端意味着“投票”支持一个区块链。一个区块链可能有多个分支，其中最长的被认为是主分支。在获取到一个尖端（它可以是区块链中的任何一个块）之后，我们可以重建整个区块链，找到它的长度以及构建它所需的工作量。这也意味着尖端是区块链的一种标识符。\nBlockchainIterator 只会做一件事：从区块链返回下一个区块。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func (i *BlockchainIterator) Next() *Block { var block *Block err := i.db.View(func(tx *bolt.Tx) error { b := tx.Bucket([]byte(blocksBucket)) encodedBlock := b.Get(i.currentHash) block = DeserializeBlock(encodedBlock) return nil }) i.currentHash = block.PrevBlockHash return block } 这就是数据库部分！\nCLI 到目前为止，我们的实现还没有提供任何与程序交互的接口：我们只是在主函数中执行了NewBlockchain、bc.AddBlock。是时候改进一下了！我们希望有以下这些命令：\nblockchain_go addblock \u0026quot;为一杯咖啡支付 0.031337\u0026quot; blockchain_go printchain 所有与命令行相关的操作将由CLI结构处理：\n1 2 3 type CLI struct { bc *Blockchain } 它的“入口点”是 Run 函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 func (cli *CLI) Run() { cli.validateArgs() addBlockCmd := flag.NewFlagSet(\u0026#34;addblock\u0026#34;, flag.ExitOnError) printChainCmd := flag.NewFlagSet(\u0026#34;printchain\u0026#34;, flag.ExitOnError) addBlockData := addBlockCmd.String(\u0026#34;data\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;Block data\u0026#34;) switch os.Args[1] { case \u0026#34;addblock\u0026#34;: err := addBlockCmd.Parse(os.Args[2:]) case \u0026#34;printchain\u0026#34;: err := printChainCmd.Parse(os.Args[2:]) default: cli.printUsage() os.Exit(1) } if addBlockCmd.Parsed() { if *addBlockData == \u0026#34;\u0026#34; { addBlockCmd.Usage() os.Exit(1) } cli.addBlock(*addBlockData) } if printChainCmd.Parsed() { cli.printChain() } } 我们使用标准flag包来解析命令行参数。\n1 2 3 addBlockCmd := flag.NewFlagSet(\u0026#34;addblock\u0026#34;, flag.ExitOnError) printChainCmd := flag.NewFlagSet(\u0026#34;printchain\u0026#34;, flag.ExitOnError) addBlockData := addBlockCmd.String(\u0026#34;data\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;Block data\u0026#34;) 首先，我们创建两个子命令，addblock 和 printchain，然后为前者添加 -data 标志。 printchain 不会有任何标志。\n1 2 3 4 5 6 7 8 9 switch os.Args[1] { case \u0026#34;addblock\u0026#34;: err := addBlockCmd.Parse(os.Args[2:]) case \u0026#34;printchain\u0026#34;: err := printChainCmd.Parse(os.Args[2:]) default: cli.printUsage() os.Exit(1) } 接下来我们检查用户提供的命令并解析相关的flag子命令。\n1 2 3 4 5 6 7 8 9 10 11 if addBlockCmd.Parsed() { if *addBlockData == \u0026#34;\u0026#34; { addBlockCmd.Usage() os.Exit(1) } cli.addBlock(*addBlockData) } if printChainCmd.Parsed() { cli.printChain() } 接下来我们检查哪些子命令被解析并运行相关函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func (cli *CLI) addBlock(data string) { cli.bc.AddBlock(data) fmt.Println(\u0026#34;Success!\u0026#34;) } func (cli *CLI) printChain() { bci := cli.bc.Iterator() for { block := bci.Next() fmt.Printf(\u0026#34;Prev. hash: %x\\n\u0026#34;, block.PrevBlockHash) fmt.Printf(\u0026#34;Data: %s\\n\u0026#34;, block.Data) fmt.Printf(\u0026#34;Hash: %x\\n\u0026#34;, block.Hash) pow := NewProofOfWork(block) fmt.Printf(\u0026#34;PoW: %s\\n\u0026#34;, strconv.FormatBool(pow.Validate())) fmt.Println() if len(block.PrevBlockHash) == 0 { break } } } 这件作品与我们之前的作品非常相似。唯一的区别是我们现在使用 BlockchainIterator 来迭代区块链中的块。\n另外，我们不要忘记相应地修改 main 函数：\n1 2 3 4 5 6 7 func main() { bc := NewBlockchain() defer bc.db.Close() cli := CLI{bc} cli.Run() } 请注意，无论提供什么命令行参数，都会创建一个新的区块链。\n就是这样！让我们检查一切是否按预期工作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 $ blockchain_go printchain No existing blockchain found. Creating a new one... Mining the block containing \u0026#34;Genesis Block\u0026#34; 000000edc4a82659cebf087adee1ea353bd57fcd59927662cd5ff1c4f618109b Prev. hash: Data: Genesis Block Hash: 000000edc4a82659cebf087adee1ea353bd57fcd59927662cd5ff1c4f618109b PoW: true $ blockchain_go addblock -data \u0026#34;Send 1 BTC to Ivan\u0026#34; Mining the block containing \u0026#34;Send 1 BTC to Ivan\u0026#34; 000000d7b0c76e1001cdc1fc866b95a481d23f3027d86901eaeb77ae6d002b13 Success! $ blockchain_go addblock -data \u0026#34;Pay 0.31337 BTC for a coffee\u0026#34; Mining the block containing \u0026#34;Pay 0.31337 BTC for a coffee\u0026#34; 000000aa0748da7367dec6b9de5027f4fae0963df89ff39d8f20fd7299307148 Success! $ blockchain_go printchain Prev. hash: 000000d7b0c76e1001cdc1fc866b95a481d23f3027d86901eaeb77ae6d002b13 Data: Pay 0.31337 BTC for a coffee Hash: 000000aa0748da7367dec6b9de5027f4fae0963df89ff39d8f20fd7299307148 PoW: true Prev. hash: 000000edc4a82659cebf087adee1ea353bd57fcd59927662cd5ff1c4f618109b Data: Send 1 BTC to Ivan Hash: 000000d7b0c76e1001cdc1fc866b95a481d23f3027d86901eaeb77ae6d002b13 PoW: true Prev. hash: Data: Genesis Block Hash: 000000edc4a82659cebf087adee1ea353bd57fcd59927662cd5ff1c4f618109b PoW: true 下次我们将实现地址、钱包和（可能）交易。所以敬请期待！\n结论 我们的区块链离实际架构更近了一步：现在添加区块需要进行艰苦工作，因此挖矿成为可能。但它仍然缺少一些关键功能：区块链数据库不是持久化的，没有钱包、地址、交易，也没有共识机制。所有这些内容我们将在未来的文章中实现，目前祝您挖矿愉快！\n","date":"2023-12-12T19:41:34+08:00","permalink":"http://localhost:1313/post/building-blockchain-in-go-part-3/","title":"在Go中构建区块链-3-持久性和CLI"},{"content":"本文译自 Building Blockchain in Go. Part 2: Proof-of-Work\n简介 在前一篇文章中，我们构建了一个非常简单的数据结构，这就是区块链数据库的本质。我们使得可以通过它实现具有链状关系的区块添加：每个区块都与前一个区块相连接。然而，遗憾的是，我们的区块链实现有一个显著的缺陷：向链中添加区块变得轻松而廉价。区块链和比特币的关键之一是添加新区块是一项艰苦的工作。今天我们将修复这个缺陷。\n工作量证明 区块链的一个关键理念是，为了将数据放入其中，必须进行一些艰苦的工作。正是这种艰苦的工作使得区块链安全而一致。此外，为这项艰苦的工作支付一定的奖励（这就是人们通过挖矿获得硬币的方式）。\n这一机制与现实生活中的机制非常相似：人们必须努力工作以获得奖励，并维持他们的生活。在区块链中，网络的一些参与者（矿工）工作以维持网络，向其中添加新区块，并为他们的工作获得奖励。通过他们的工作，区块以一种安全的方式合并到区块链中，这维护了整个区块链数据库的稳定性。值得注意的是，完成工作的人必须证明这一点。\n整个“进行艰苦工作并证明”的机制被称为工作量证明。它之所以困难，是因为它需要大量的计算能力：即使是高性能计算机也无法迅速完成。此外，这项工作的难度会随时间而增加，以保持新区块的产生速率约为每小时6个区块。在比特币中，这项工作的目标是找到一个符合某些要求的区块哈希。而这个哈希就是作为证明的依据。因此，找到证明就是实际的工作。\n最后需要注意的一点是，工作量证明算法必须满足一个要求：做工作是困难的，但验证证明是容易的。通常，证明会交给其他人，因此对于他们来说，验证这个证明不应该花费太多时间。\n哈希 在这一段中，我们将讨论哈希。如果您对这个概念熟悉，可以跳过这部分内容。\n哈希是获取指定数据的哈希值的过程。哈希是对计算的数据的唯一表示。哈希函数是一个接受任意大小的数据并生成固定大小哈希值的函数。以下是哈希的一些关键特点：\n无法从哈希还原出原始数据。因此，哈希不是加密。 特定的数据只能有一个哈希值，且哈希是唯一的。 即使在输入数据中更改一个字节，也会导致完全不同的哈希值。 哈希函数广泛用于检查数据的一致性。一些软件提供商除了软件包之外，还会发布校验和。下载文件后，您可以将其输入到哈希函数中，并将生成的哈希与软件开发者提供的哈希进行比较。\n在区块链中，哈希用于保证区块的一致性。哈希算法的输入数据包含前一区块的哈希，因此几乎不可能（或至少相当困难）修改链中的一个区块：必须重新计算其哈希和其后所有区块的哈希。\nHashcash 比特币使用Hashcash，这是一种最初用于防止电子邮件垃圾的工作量证明算法。它可以分为以下步骤：\n获取一些公开已知的数据（在电子邮件的情况下，是接收方的电子邮件地址；在比特币的情况下，是区块头）。 向其添加一个计数器。计数器从0开始。 获取数据+计数器组合的哈希值。 检查哈希是否符合特定的要求。 如果符合要求，任务完成。 如果不符合要求，增加计数器，然后重复步骤3和4。 因此，这是一种穷举算法：更改计数器，计算新的哈希，检查它，增加计数器，计算哈希，依此类推。这就是为什么它在计算上是昂贵的原因。\n现在让我们更详细地看看哈希必须满足的要求。在原始的Hashcash实现中，要求是“哈希的前20位必须为零”。在比特币中，由于设计上每10分钟必须生成一个区块，因此要求会随时间调整，尽管计算能力随着时间的推移增加，越来越多的矿工加入网络。\n为了演示这个算法，我使用了前面例子中的数据(“I like donuts”)并找到了一个以3个零字节开头的哈希值：\nca07ca是计数器的十六进制值，十进制为13240266。\n执行 好了，理论讲完了，让我们来写代码吧！首先我们定义一下挖矿难度：\n1 const targetBits = 24 在比特币中，“targetBits”是存储区块挖掘难度的区块头。目前我们不会实现一个自动调整目标的算法，所以我们可以将难度定义为一个全局常量。\n24是一个任意的数字，我们的目标是拥有一个在内存中占用少于256位的目标。我们希望差异足够显著，但不要太大，因为差异越大，找到合适的哈希就越困难。\n1 2 3 4 5 6 7 8 9 10 11 12 13 type ProofOfWork struct { block *Block target *big.Int } func NewProofOfWork(b *Block) *ProofOfWork { target := big.NewInt(1) target.Lsh(target, uint(256-targetBits)) pow := \u0026amp;ProofOfWork{b, target} return pow } 在这里创建ProofOfWork结构，它包含对一个block和一个target的指针。在这里，“target”是前面段落中描述的要求的另一个名称。我们使用大整数是因为我们将如何将哈希与目标进行比较：我们将哈希转换为大整数并检查它是否小于目标。\n在NewProofOfWork函数中，我们使用值为1的big.Int，并将其左移256 - targetBits位。256是SHA-256哈希的位长度，而我们将使用SHA-256哈希算法。目标的十六进制表示是：\n0x10000000000000000000000000000000000000000000000000000000000 它在内存中占用29字节。以下是它与前面示例中的哈希的视觉比较：\n1 2 3 0fac49161af82ed938add1d8725835cc123a1a87b1b196488360e58d4bfb51e3 0000010000000000000000000000000000000000000000000000000000000000 0000008b0f41ec78bab747864db66bcb9fb89920ee75f43fdaaeb5544f7f76ca 第一个哈希（对“I like donuts”进行计算）大于目标，因此它不是有效的工作证明。第二个哈希（对“I like donutsca07ca”进行计算）小于目标，因此它是有效的证明。\n您可以将目标看作是范围的上限：如果一个数字（一个哈希）小于这个上限，它就是有效的，反之亦然。降低上限将导致更少的有效数字，因此需要更多的工作来找到一个有效数字。\n现在，我们需要准备要进行哈希的数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func (pow *ProofOfWork) prepareData(nonce int) []byte { data := bytes.Join( [][]byte{ pow.block.PrevBlockHash, pow.block.Data, IntToHex(pow.block.Timestamp), IntToHex(int64(targetBits)), IntToHex(int64(nonce)), }, []byte{}, ) return data } 这一部分很简单：我们只需将区块字段与目标和nonce合并。这里的nonce是上面Hashcash描述中的计数器，这是一个密码学术语。\n好的，所有准备工作都已完成，让我们来实现PoW算法的核心部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 func (pow *ProofOfWork) Run() (int, []byte) { var hashInt big.Int var hash [32]byte nonce := 0 fmt.Printf(\u0026#34;Mining the block containing \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, pow.block.Data) for nonce \u0026lt; maxNonce { data := pow.prepareData(nonce) hash = sha256.Sum256(data) fmt.Printf(\u0026#34;\\r%x\u0026#34;, hash) hashInt.SetBytes(hash[:]) if hashInt.Cmp(pow.target) == -1 { break } else { nonce++ } } fmt.Print(\u0026#34;\\n\\n\u0026#34;) return nonce, hash[:] } 首先，我们初始化变量：hashInt是哈希的整数表示；nonce是计数器。接下来，我们运行一个“无限”循环：它受maxNonce的限制，maxNonce等于math.MaxInt64；这样做是为了避免nonce可能发生的溢出。尽管我们的PoW实现的难度对于计数器溢出来说太低了，但仍然最好进行这个检查，以防万一。\n在循环中，我们：\n准备数据。 使用SHA-256对其进行哈希。 将哈希转换为大整数。 将整数与目标进行比较。 正如之前解释的那样简单。现在我们可以删除Block的SetHash方法并修改NewBlock函数：\n1 2 3 4 5 6 7 8 9 10 func NewBlock(data string, prevBlockHash []byte) *Block { block := \u0026amp;Block{time.Now().Unix(), []byte(data), prevBlockHash, []byte{}, 0} pow := NewProofOfWork(block) nonce, hash := pow.Run() block.Hash = hash[:] block.Nonce = nonce return block } 在这里您可以看到随机数被保存为块属性。这是必要的，因为需要随机数来验证证明。块结构现在看起来像这样：\n1 2 3 4 5 6 7 type Block struct { Timestamp int64 Data []byte PrevBlockHash []byte Hash []byte Nonce int } 好吧！让我们运行该程序看看一切是否正常：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Mining the block containing \u0026#34;Genesis Block\u0026#34; 00000041662c5fc2883535dc19ba8a33ac993b535da9899e593ff98e1eda56a1 Mining the block containing \u0026#34;Send 1 BTC to Ivan\u0026#34; 00000077a856e697c69833d9effb6bdad54c730a98d674f73c0b30020cc82804 Mining the block containing \u0026#34;Send 2 more BTC to Ivan\u0026#34; 000000b33185e927c9a989cc7d5aaaed739c56dad9fd9361dea558b9bfaf5fbe Prev. hash: Data: Genesis Block Hash: 00000041662c5fc2883535dc19ba8a33ac993b535da9899e593ff98e1eda56a1 Prev. hash: 00000041662c5fc2883535dc19ba8a33ac993b535da9899e593ff98e1eda56a1 Data: Send 1 BTC to Ivan Hash: 00000077a856e697c69833d9effb6bdad54c730a98d674f73c0b30020cc82804 Prev. hash: 00000077a856e697c69833d9effb6bdad54c730a98d674f73c0b30020cc82804 Data: Send 2 more BTC to Ivan Hash: 000000b33185e927c9a989cc7d5aaaed739c56dad9fd9361dea558b9bfaf5fbe 耶！您可以看到现在每个哈希值都以三个零字节开头，并且需要一些时间才能获取这些哈希值。\n还有一件事要做：让我们能够验证工作量证明。\n1 2 3 4 5 6 7 8 9 10 11 func (pow *ProofOfWork) Validate() bool { var hashInt big.Int data := pow.prepareData(pow.block.Nonce) hash := sha256.Sum256(data) hashInt.SetBytes(hash[:]) isValid := hashInt.Cmp(pow.target) == -1 return isValid } 这就是我们需要保存的随机数的地方。\n让我们再检查一次是否一切正常：\n输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Prev. hash: Data: Genesis Block Hash: 00000093253acb814afb942e652a84a8f245069a67b5eaa709df8ac612075038 PoW: true Prev. hash: 00000093253acb814afb942e652a84a8f245069a67b5eaa709df8ac612075038 Data: Send 1 BTC to Ivan Hash: 0000003eeb3743ee42020e4a15262fd110a72823d804ce8e49643b5fd9d1062b PoW: true Prev. hash: 0000003eeb3743ee42020e4a15262fd110a72823d804ce8e49643b5fd9d1062b Data: Send 2 more BTC to Ivan Hash: 000000e42afddf57a3daa11b43b2e0923f23e894f96d1f24bfd9b8d2d494c57a PoW: true 结论 我们的区块链离实际架构更近了一步：现在添加区块需要进行艰苦工作，因此挖矿成为可能。但它仍然缺少一些关键功能：区块链数据库不是持久化的，没有钱包、地址、交易，也没有共识机制。所有这些内容我们将在未来的文章中实现，目前祝您挖矿愉快！\n","date":"2023-12-12T18:05:25+08:00","permalink":"http://localhost:1313/post/building-blockchain-in-go-part-2/","title":"在Go中构建区块链-2-工作量证明PoW"},{"content":"本文译自 Building Blockchain in Go. Part 1: Basic Prototype\n简介 区块链是21世纪最革命性的技术之一，仍然在不断发展，其潜力尚未充分实现。本质上，区块链只是一种分布式记录数据库。但使其独特的是，它不是私有数据库，而是公共数据库，即每个使用它的人都拥有其全部或部分副本。新的记录只能在数据库的其他维护者同意的情况下添加。此外，正是区块链使加密货币和智能合约成为可能。\n在这一系列的文章中，我们将构建一个基于简单区块链实现的简化加密货币。\n区块 让我们从“区块链”中的“区块”部分开始。在区块链中，存储有价值信息的是区块。例如，比特币区块存储交易，这是任何加密货币的本质。除此之外，一个区块还包含一些技术信息，如其版本、当前时间戳和前一区块的哈希值。 在本文中，我们不打算按照区块链或比特币规范实现区块，而是使用其简化版本，仅包含重要信息。以下是其结构：\n1 2 3 4 5 6 type Block struct { Timestamp int64 Data []byte PrevBlockHash []byte Hash []byte } Timestamp是当前时间戳（区块创建时的时间），Data是包含在区块中的实际有价值的信息，PrevBlockHash存储前一区块的哈希值，而Hash是区块的哈希值。在比特币规范中，Timestamp、PrevBlockHash和Hash构成区块头，形成一个独立的数据结构，而交易（在我们的情况中是Data）是另一个独立的数据结构。出于简化考虑，我们在这里将它们混合在一起。\n那么我们如何计算哈希值呢？哈希值的计算方式是区块链的一个非常重要的特性，正是这个特性使得区块链具有安全性。问题在于计算哈希是一项计算上困难的操作，即使在高速计算机上也需要一些时间（这就是为什么人们购买强大的GPU来挖掘比特币的原因）。这是一种有意的架构设计，使得添加新区块变得困难，从而防止它们在添加后被修改。我们将在未来的文章中讨论并实现这一机制。\n目前，我们将简单地取区块字段，连接它们，然后对连接的组合计算SHA-256哈希值。让我们在SetHash方法中完成这个操作：\n1 2 3 4 5 6 7 func (b *Block) SetHash() { timestamp := []byte(strconv.FormatInt(b.Timestamp, 10)) headers := bytes.Join([][]byte{b.PrevBlockHash, b.Data, timestamp}, []byte{}) hash := sha256.Sum256(headers) b.Hash = hash[:] } 接下来，遵循Golang的约定，我们将实现一个简化区块创建过程的函数：\n1 2 3 4 5 func NewBlock(data string, prevBlockHash []byte) *Block { block := \u0026amp;Block{time.Now().Unix(), []byte(data), prevBlockHash, []byte{}} block.SetHash() return block } 区块链 现在让我们来实现一个区块链。在其本质上，区块链只是一种具有特定结构的数据库：它是一个有序的、反向链接的列表。这意味着区块按照插入顺序存储，并且每个区块链接到前一个区块。这种结构允许快速获取链中的最新区块，并（高效地）通过其哈希获取区块。\n在Golang中，可以通过使用数组和哈希表（map）来实现这种结构：数组将保持有序的哈希值（在Go中数组是有序的），而map（哈希表）将保持哈希值到区块的映射（map是无序的）。但对于我们的区块链原型，我们将只使用数组，因为目前我们不需要通过哈希值获取区块。\n1 2 3 type Blockchain struct { blocks []*Block } 这是我们的第一个区块链！我从没想过会这么容易😉\n现在让我们可以向其中添加块：\n1 2 3 4 5 func (bc *Blockchain) AddBlock(data string) { prevBlock := bc.blocks[len(bc.blocks)-1] newBlock := NewBlock(data, prevBlock.Hash) bc.blocks = append(bc.blocks, newBlock) } 就是这样！还是有点不够。。\n要添加一个新区块，我们需要一个已经存在的区块，但是在我们的区块链中还没有区块！在任何区块链中，必须至少有一个区块（被称为创世块）。让我们实现一个创建这样一个区块的方法：\n1 2 3 func NewGenesisBlock() *Block { return NewBlock(\u0026#34;Genesis Block\u0026#34;, []byte{}) } 现在，我们可以实现一个使用创世块创建区块链的函数：\n1 2 3 func NewBlockchain() *Blockchain { return \u0026amp;Blockchain{[]*Block{NewGenesisBlock()}} } 让我们检查一下区块链是否正常工作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 func main() { bc := NewBlockchain() bc.AddBlock(\u0026#34;Send 1 BTC to Ivan\u0026#34;) bc.AddBlock(\u0026#34;Send 2 more BTC to Ivan\u0026#34;) for _, block := range bc.blocks { fmt.Printf(\u0026#34;Prev. hash: %x\\n\u0026#34;, block.PrevBlockHash) fmt.Printf(\u0026#34;Data: %s\\n\u0026#34;, block.Data) fmt.Printf(\u0026#34;Hash: %x\\n\u0026#34;, block.Hash) fmt.Println() } } 输出：\n1 2 3 4 5 6 7 8 9 10 11 Prev. hash: Data: Genesis Block Hash: aff955a50dc6cd2abfe81b8849eab15f99ed1dc333d38487024223b5fe0f1168 Prev. hash: aff955a50dc6cd2abfe81b8849eab15f99ed1dc333d38487024223b5fe0f1168 Data: Send 1 BTC to Ivan Hash: d75ce22a840abb9b4e8fc3b60767c4ba3f46a0432d3ea15b71aef9fde6a314e1 Prev. hash: d75ce22a840abb9b4e8fc3b60767c4ba3f46a0432d3ea15b71aef9fde6a314e1 Data: Send 2 more BTC to Ivan Hash: 561237522bb7fcfbccbc6fe0e98bbbde7427ffe01c6fb223f7562288ca2295d1 就是这样！\n结论 我们构建了一个非常简单的区块链原型：它只是一个区块数组，每个区块都与前一个区块相连接。然而，实际的区块链要复杂得多。在我们的区块链中，添加新区块是轻松而快速的，但在真实的区块链中，添加新区块需要一些工作：在获得添加区块权限之前，必须执行一些繁重的计算（这个机制被称为工作量证明 Proof-of-Work PoW）。此外，区块链是一个分布式数据库，没有单一的决策者。因此，新区块必须得到网络其他参与者的确认和批准（这个机制被称为共识）。而且，在我们的区块链中还没有交易！\n在未来的文章中，我们将涵盖这些特性中的每一个。\n","date":"2023-12-12T15:27:07+08:00","permalink":"http://localhost:1313/post/building-blockchain-in-go-part-1/","title":"在Go中构建区块链-1-基本原型"},{"content":"","date":"2023-11-01T16:47:36+08:00","permalink":"http://localhost:1313/post/about-repost/","title":"关于转载"},{"content":"本文转载自 docker \u0026ndash;link容器互联\n系统环境 docker容器互联概述 docker容器互联的三种方式 同一个宿主机上的多个docker容器之间如果想进行通信有三种方式：\n通过使用容器的ip地址来通信【这样会导致ip地址的硬编码，不方便迁移，并且容器重启后ip地址会改变，除非使用固定的ip】 通过宿主机的ip加上容器暴露出的端口号来通信【这样的通信方式比较单一，只能依靠监听在暴露出的端口的进程来进行有限的通信】 通过docker的link机制可以通过一个name来和另一个容器通信，link机制方便了容器去发现其它的容器并且可以安全的传递一些连接信息给其它的容器。 docker \u0026ndash;link使用注意事项 使用docker \u0026ndash;link需要注意以下几点：\n使用link选项建立的容器所链接的主机需要在运行状态 使用link选项建立的容器运行时需要所链接的容器也必须是运行状态 使用link选项链接的主机ip不需要固定，因为每次新建容器都会检查所链接容器的ip，在/etc/hosts里生成新的alias 名称对应的ip docker \u0026ndash;link原理 docker \u0026ndash;link 使用了link机制后，可以通过指定的名字来和目标容器通信，这其实是通过给/etc/hosts中加入名称和IP的解析关系来实现的。\ndocker容器互联 通过容器IP地址进行通信 创建一个MySQL容器\n1 2 [root@k8smaster ~]# docker run -dit --restart=always --name=mysql5 -e MYSQL_ROOT_PASSWORD=123456 -p 3306:3306 hub.c.163.com/library/mysql:latest 03982d14608971f6af6783ad0eb6611516c8b19e449dc05e899a802cabfe99f0 查看MySQL容器IP\n1 2 3 4 [root@k8smaster ~]# docker inspect mysql5 | grep -i ipaddr \u0026#34;SecondaryIPAddresses\u0026#34;: null, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.17.0.4\u0026#34;, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.17.0.4\u0026#34;, 创建一个centos容器，并测试容器的连通性\n1 2 3 4 5 6 7 8 9 10 11 #ping MySQL容器IP，可以看到成功ping通 [root@k8smaster ~]# docker run -it --restart=always --name=centos7 hub.c.163.com/library/centos:latest ping 172.17.0.4 PING 172.17.0.4 (172.17.0.4) 56(84) bytes of data. 64 bytes from 172.17.0.4: icmp_seq=1 ttl=64 time=0.168 ms 64 bytes from 172.17.0.4: icmp_seq=2 ttl=64 time=0.064 ms 64 bytes from 172.17.0.4: icmp_seq=3 ttl=64 time=0.063 ms 64 bytes from 172.17.0.4: icmp_seq=4 ttl=64 time=0.185 ms ^C --- 172.17.0.4 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 2999ms rtt min/avg/max/mdev = 0.063/0.120/0.185/0.056 ms 通过\u0026ndash;link 参数进行通信 注意：docker 默认是允许容器互联互通的，可以通过-icc=false 关闭互通。一旦关闭了互通，只能通过-link name:alias 命令连接指定容器\n创建centos容器，使用\u0026ndash;link mysql5:mysql 链接mysql5容器，并给mysql5容器起别名为mysql，直接ping mysql，可以看到成功ping通\n1 2 3 4 5 6 7 8 9 [root@k8smaster ~]# docker run -it --restart=always --name=c7 --link mysql5:mysql hub.c.163.com/library/centos:latest ping mysql PING mysql (172.17.0.4) 56(84) bytes of data. 64 bytes from mysql (172.17.0.4): icmp_seq=1 ttl=64 time=0.099 ms 64 bytes from mysql (172.17.0.4): icmp_seq=2 ttl=64 time=0.086 ms 64 bytes from mysql (172.17.0.4): icmp_seq=3 ttl=64 time=0.126 ms ^C --- mysql ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 1999ms rtt min/avg/max/mdev = 0.086/0.103/0.126/0.020 ms 进入容器ping mysql\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 [root@k8smaster ~]# docker exec -it c7 /bin/bash [root@0eea8b40d874 /]# ping mysql PING mysql (172.17.0.4) 56(84) bytes of data. 64 bytes from mysql (172.17.0.4): icmp_seq=1 ttl=64 time=0.108 ms 64 bytes from mysql (172.17.0.4): icmp_seq=2 ttl=64 time=0.107 ms 64 bytes from mysql (172.17.0.4): icmp_seq=3 ttl=64 time=0.064 ms 64 bytes from mysql (172.17.0.4): icmp_seq=4 ttl=64 time=0.080 ms ^C --- mysql ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 2999ms rtt min/avg/max/mdev = 0.064/0.089/0.108/0.021 ms #没有MySQL客户端 [root@0eea8b40d874 /]# mysql -uroot -p123456 -h 172.17.0.4 bash: mysql: command not found #安装MySQL客户端，mariadb客户端和MySQL客户端通用 [root@0eea8b40d874 /]# yum -y install mariadb Loaded plugins: fastestmirror, ovl ..... Installed: mariadb.x86_64 1:5.5.68-1.el7 ...... Complete! 在centos7容器里连接mysql\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 [root@0eea8b40d874 /]# mysql -uroot -p123456 -h 172.17.0.4 Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MySQL connection id is 3 Server version: 5.7.18 MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. MySQL [(none)]\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) MySQL [(none)]\u0026gt; exit Bye [root@0eea8b40d874 /]# [root@0eea8b40d874 /]# exit exit [root@k8smaster ~]# ","date":"2023-10-31T11:14:05+08:00","permalink":"http://localhost:1313/post/docker-container-link/","title":"docker --link容器互联"},{"content":"本文转载自 docker网络管理\n系统环境 docker网络 Docker 网络概述 Docker 容器和服务如此强大的原因之一是您可以将它们连接在一起，或者将它们连接到非 Docker 工作负载。 Docker 容器和服务甚至不需要知道它们部署在 Docker 上，或者它们的对等点是否也是 Docker 工作负载。 无论您的 Docker 主机运行 Linux、Windows 还是两者的混合，您都可以使用 Docker 以与平台无关的方式管理它们。\ndocker 网络类型 Docker 的网络子系统是可插拔的，使用驱动程序。默认情况下存在几个驱动程序，并提供核心网络功能：\nbridge：默认网络驱动程序。如果您未指定驱动程序，则这是您正在创建的网络类型。当您的应用程序在需要通信的独立容器中运行时，通常会使用桥接网络。\nhost：对于独立容器，去掉容器与 Docker 主机之间的网络隔离，直接使用主机的网络。\noverlay: Overlay 网络将多个 Docker 守护进程连接在一起，使 swarm 服务能够相互通信。您还可以使用覆盖网络来促进 swarm 服务和独立容器之间的通信，或者不同 Docker 守护程序上的两个独立容器之间的通信。这种策略消除了在这些容器之间进行操作系统级路由的需要。\nipvlan：IPvlan 网络使用户可以完全控制 IPv4 和 IPv6 寻址。VLAN 驱动程序建立在此之上，为对底层网络集成感兴趣的用户提供了对第 2 层 VLAN 标记甚至 IPvlan L3 路由的完全控制。\nmacvlan：Macvlan 网络允许您将 MAC 地址分配给容器，使其在您的网络上显示为物理设备。Docker 守护进程通过它们的 MAC 地址将流量路由到容器。macvlan 在处理期望直接连接到物理网络而不是通过 Docker 主机的网络堆栈路由的遗留应用程序时，使用驱动程序有时是最佳选择。\nnone：对于这个容器，禁用所有网络。通常与自定义网络驱动程序一起使用。none不适用于 swarm 服务。请参阅 禁用容器网络。\n网络插件：您可以通过 Docker 安装和使用第三方网络插件。这些插件可从 Docker Hub 或第三方供应商处获得。\n网络驱动总结：\n当您需要多个容器在同一个 Docker 主机上进行通信时，用户定义的桥接网络是最佳选择。 当网络堆栈不应该与 Docker 主机隔离时，主机网络是最好的，但您希望容器的其他方面被隔离。 当您需要在不同 Docker 主机上运行的容器进行通信时，或者当多个应用程序使用 swarm 服务一起工作时，覆盖网络是最佳选择。 当您从 VM 设置迁移或需要容器看起来像网络上的物理主机时，Macvlan 网络是最佳选择，每个主机都有唯一的 MAC 地址。 第三方网络插件允许您将 Docker 与专门的网络堆栈集成。 docker网络管理常用命令 docker network connect 将某个容器连接到一个docker网络\ndocker network create 创建一个docker局域网络\ndocker network disconnect 将某个容器退出某个局域网络\ndocker network inspect 显示某个局域网络信息\ndocker network ls 显示所有docker局域网络\ndocker network prune 删除所有未引用的docker局域网络\ndocker network rm 删除docker网络\n查看docker支持的网络\n1 2 3 4 5 [root@k8smaster ~]# docker network list NETWORK ID NAME DRIVER SCOPE 7e5d5c751c19 bridge bridge local d6114fdf8604 host host local d37b373ceadd none null local 查看bridge（桥接）网络的属性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 [root@k8smaster ~]# docker network inspect bridge [ { \u0026#34;Name\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;7e5d5c751c19179bd28704782956624fb6e1e51bbf1dec148a6a2857361c999f\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2021-12-28T14:43:30.751950569+08:00\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: null, \u0026#34;Config\u0026#34;: [ { \u0026#34;Subnet\u0026#34;: \u0026#34;172.17.0.0/16\u0026#34;, \u0026#34;Gateway\u0026#34;: \u0026#34;172.17.0.1\u0026#34; } ] }, \u0026#34;Internal\u0026#34;: false, \u0026#34;Attachable\u0026#34;: false, \u0026#34;Ingress\u0026#34;: false, \u0026#34;ConfigFrom\u0026#34;: { \u0026#34;Network\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;ConfigOnly\u0026#34;: false, \u0026#34;Containers\u0026#34;: { \u0026#34;1edbf56b01ee2f851bfb3dce9e955df18077e889c5254a8ac1dc24c4c343e5c5\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;redhat7.2\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;138e81107ffaca48a84d46c99a379245d02f031884567a214111f21833914a4e\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:11:00:03\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.17.0.3/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;c2d01513585bca0ceb67841e8307119e51ab9d6001cca76c147cc0f7ec441c63\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;redhat\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;9f0368fb571e73565af237a2d259f513063f83a7c18611b23ec4f11fe64e7bd5\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:11:00:02\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.17.0.2/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; } }, \u0026#34;Options\u0026#34;: { \u0026#34;com.docker.network.bridge.default_bridge\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;com.docker.network.bridge.enable_icc\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;com.docker.network.bridge.enable_ip_masquerade\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;com.docker.network.bridge.host_binding_ipv4\u0026#34;: \u0026#34;0.0.0.0\u0026#34;, \u0026#34;com.docker.network.bridge.name\u0026#34;: \u0026#34;docker0\u0026#34;, \u0026#34;com.docker.network.driver.mtu\u0026#34;: \u0026#34;1500\u0026#34; }, \u0026#34;Labels\u0026#34;: {} } ] 使用docker创建不同的网络类型 创建一个bridge桥接网络并使用 创建一张网卡brnet：类型为bridge，子网IP为：172.28.0.0/16\n1 2 [root@k8smaster ~]# docker network create --driver=bridge --subnet=172.28.0.0/16 brnet 50007eb84ee90f225233b873bfc395a0f0da680bd22b8ac1d45add39d45f527b 查看brnet网卡属性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 [root@k8smaster ~]# docker network inspect brnet [ { \u0026#34;Name\u0026#34;: \u0026#34;brnet\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;50007eb84ee90f225233b873bfc395a0f0da680bd22b8ac1d45add39d45f527b\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2021-12-29T15:53:20.641824413+08:00\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Config\u0026#34;: [ { \u0026#34;Subnet\u0026#34;: \u0026#34;172.28.0.0/16\u0026#34; } ] }, \u0026#34;Internal\u0026#34;: false, \u0026#34;Attachable\u0026#34;: false, \u0026#34;Ingress\u0026#34;: false, \u0026#34;ConfigFrom\u0026#34;: { \u0026#34;Network\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;ConfigOnly\u0026#34;: false, \u0026#34;Containers\u0026#34;: {}, \u0026#34;Options\u0026#34;: {}, \u0026#34;Labels\u0026#34;: {} } ] 查看docker网络，发现多了brnet\n1 2 3 4 5 6 [root@k8smaster ~]# docker network list NETWORK ID NAME DRIVER SCOPE 7e5d5c751c19 bridge bridge local 50007eb84ee9 brnet bridge local d6114fdf8604 host host local d37b373ceadd none null local 使用centos镜像创建一个容器centos7，网卡绑定为brnet\n1 2 3 4 5 6 7 8 [root@k8smaster ~]# docker run -dit --restart=always --name=centos7 --network=brnet hub.c.163.com/library/centos:latest 2de5574af1c392524a9476bd76e96e90a0035a789e02f102a47e464ea53ac502 #centos7容器的地址为：172.28.0.2 [root@k8smaster ~]# docker inspect centos7 | grep -i ipaddress \u0026#34;SecondaryIPAddresses\u0026#34;: null, \u0026#34;IPAddress\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.28.0.2\u0026#34;, 查看brnet网络的属性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 [root@k8smaster ~]# docker network inspect brnet [ { \u0026#34;Name\u0026#34;: \u0026#34;brnet\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;50007eb84ee90f225233b873bfc395a0f0da680bd22b8ac1d45add39d45f527b\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2021-12-29T15:53:20.641824413+08:00\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Config\u0026#34;: [ { \u0026#34;Subnet\u0026#34;: \u0026#34;172.28.0.0/16\u0026#34; } ] }, \u0026#34;Internal\u0026#34;: false, \u0026#34;Attachable\u0026#34;: false, \u0026#34;Ingress\u0026#34;: false, \u0026#34;ConfigFrom\u0026#34;: { \u0026#34;Network\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;ConfigOnly\u0026#34;: false, \u0026#34;Containers\u0026#34;: { \u0026#34;2de5574af1c392524a9476bd76e96e90a0035a789e02f102a47e464ea53ac502\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;centos7\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;27a8ff58525ec91f956a4f2aa0bdeaf2c042080efc3b2f443d0f2f8fd34084b9\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:1c:00:02\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.28.0.2/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; } }, \u0026#34;Options\u0026#34;: {}, \u0026#34;Labels\u0026#34;: {} } ] busybox容器使用host网络 拉取busybox镜像\n1 2 3 4 5 6 [root@k8smaster ~]# docker pull hub.c.163.com/library/busybox:latest latest: Pulling from library/busybox aab39f0bc16d: Pull complete Digest: sha256:662af1d642674367b721645652de96f9c147417c2efb708eee4e9b7212697762 Status: Downloaded newer image for hub.c.163.com/library/busybox:latest hub.c.163.com/library/busybox:latest 创建一个busybox容器，网络类型为host类型\n1 2 [root@k8smaster ~]# docker run -dit --restart=always --name=busybox --network=host hub.c.163.com/library/busybox:latest 0a02f83b685c2bf120f9b6de5be9f0c3fe3fb5730134b00995aaa8cc849613e3 进入busybox容器，发现容器里的网络就是物理机的网络\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 [root@k8smaster ~]# docker attach busybox / # ifconfig br-50007eb84ee9 Link encap:Ethernet HWaddr 02:42:1E:A8:31:1C inet addr:172.28.0.1 Bcast:172.28.255.255 Mask:255.255.0.0 inet6 addr: fe80::42:1eff:fea8:311c/64 Scope:Link UP BROADCAST MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:5 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 B) TX bytes:438 (438.0 B) ...... ens32 Link encap:Ethernet HWaddr 00:0C:29:BF:50:D8 inet addr:192.168.110.137 Bcast:192.168.110.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:febf:50d8/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:604560 errors:0 dropped:0 overruns:0 frame:0 TX packets:424501 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:460937108 (439.5 MiB) TX bytes:212554025 (202.7 MiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:7464831 errors:0 dropped:0 overruns:0 frame:0 TX packets:7464831 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:1397878730 (1.3 GiB) TX bytes:1397878730 (1.3 GiB) ...... / # exit [root@k8smaster ~]# 查看host网络属性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 [root@k8smaster ~]# docker network inspect host [ { \u0026#34;Name\u0026#34;: \u0026#34;host\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;d6114fdf860416d813aa5b250fb03b6be128dd90ad873a08179c6138ba15dee6\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2021-06-30T17:50:40.360664894+08:00\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;host\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: null, \u0026#34;Config\u0026#34;: [] }, \u0026#34;Internal\u0026#34;: false, \u0026#34;Attachable\u0026#34;: false, \u0026#34;Ingress\u0026#34;: false, \u0026#34;ConfigFrom\u0026#34;: { \u0026#34;Network\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;ConfigOnly\u0026#34;: false, \u0026#34;Containers\u0026#34;: { \u0026#34;0a02f83b685c2bf120f9b6de5be9f0c3fe3fb5730134b00995aaa8cc849613e3\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;busybox\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;864e7899e2bae367c7fbc60d423c09efe84da7afe43004e783785589ff40588f\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;6eb6f15dfc84b118f9da5d6294c857c169378dc2668f660ebb3a769cbabab7f3\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;k8s_POD_etcd-k8smaster_kube-system_1dcb59df47c677756cdf25f28d920325_16\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;f8bb0f0e910e8fc1888087270946f659bbb85c3391ded29c706644134f02ad8f\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; }, ....... \u0026#34;fc4069583b9570defd3e486e7eb56d241561f926cc1ce79fde8db43770038d99\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;k8s_POD_kube-proxy-7sxwx_kube-system_8e5ffc39-9f10-4fd0-ac80-61779b806d6a_16\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;85f62759a1916873b333aadfb8b7a6aa782f3245a966ed2da448287a70eda18f\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; } }, \u0026#34;Options\u0026#34;: {}, \u0026#34;Labels\u0026#34;: {} } ] nginx容器使用host网络 nginx容器的网络类型为host\n1 2 [root@k8smaster ~]# docker run -dit --restart=always --name=nginx --network=host hub.c.163.com/library/nginx:latest 2972a5284ef43036f6eaf288ee6c2bb361f24ab99368ceda877077e6d9b8334b 直接访问物理机的ip即可访问容器里的nginx\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 [root@k8smaster ~]# curl 192.168.110.137 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; busybox容器使用none网络 none类型的网络一般用来做测试，none类型创建的容器，里面的的网络只有127.0.0.1\n1 2 3 4 5 6 7 8 9 10 11 [root@k8smaster ~]# docker run -it --restart=always --name=busybox-test --network=none hub.c.163.com/library/busybox:latest / # ifconfig lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) / # exit ","date":"2023-10-27T14:14:04+08:00","permalink":"http://localhost:1313/post/docker-network-management/","title":"docker网络管理"},{"content":"本文转载自 一文搞懂docker容器基础：docker镜像管理，docker容器管理\n系统环境 docker Docker 概述 Docker 是一个用于开发、发布和运行应用程序的开放平台。Docker 使您能够将应用程序与基础架构分离，以便您可以快速交付软件。 使用 Docker，您可以像管理应用程序一样管理基础设施。通过利用 Docker 快速交付、测试和部署代码的方法，您可以显著减少编写代码和在生产环境中运行之间的延迟。\nDocker 平台 Docker 提供了在称为容器的松散隔离环境中打包和运行应用程序的能力。隔离和安全性允许您在给定主机上同时运行多个容器。 容器是轻量级的，包含运行应用程序所需的一切，因此您无需依赖主机上当前安装的内容。您可以在工作时轻松共享容器，并确保与您共享的每个人都获得以相同方式工作的同一个容器。\nDocker 提供工具和平台来管理容器的生命周期：\n使用容器开发您的应用程序及其支持组件。 容器成为分发和测试应用程序的单元。 准备就绪后，将应用程序部署到生产环境中，作为容器或编排的服务。无论您的生产环境是本地数据中心、云提供商还是两者的混合，这都是一样的。 我可以使用 Docker 做什么？ 快速、一致地交付您的应用程序 Docker 通过允许开发人员使用提供应用程序和服务的本地容器在标准化环境中工作来简化开发生命周期。容器非常适合持续集成和持续交付 (CI/CD) 工作流程。\n考虑以下示例场景：\n您的开发人员在本地编写代码并使用 Docker 容器与同事分享他们的工作。 他们使用 Docker 将他们的应用程序推送到测试环境中并执行自动化和手动测试。 当开发者发现bug时，可以在开发环境中修复，重新部署到测试环境中进行测试和验证。 测试完成后，将修复程序提供给客户就像将更新的映像推送到生产环境一样简单。 响应式部署和扩展 Docker 基于容器的平台允许高度可移植的工作负载。Docker 容器可以在开发人员的本地笔记本电脑、数据中心的物理或虚拟机、云提供商或混合环境中运行。\nDocker 的可移植性和轻量级特性还使得动态管理工作负载、根据业务需求近乎实时地扩展或拆除应用程序和服务变得容易。\n在相同硬件上运行更多工作负载 Docker 是轻量级和快速的。它为基于管理程序的虚拟机提供了一种可行且经济高效的替代方案，因此您可以使用更多计算容量来实现业务目标。 Docker 非常适合高密度环境以及需要用更少资源完成更多工作的中小型部署。\nDocker 架构 Docker 使用客户端-服务器架构。Docker客户端与 Docker守护进程对话，后者负责构建、运行和分发 Docker 容器的繁重工作。 Docker 客户端和守护程序可以 在同一系统上运行，或者您可以将 Docker 客户端连接到远程 Docker 守护程序。 Docker 客户端和守护程序使用 REST API，通过 UNIX 套接字或网络接口进行通信。 另一个 Docker 客户端是 Docker Compose，它允许您使用由一组容器组成的应用程序。\nThe Docker daemon(Docker 守护进程) Docker 守护程序 ( dockerd) 侦听 Docker API 请求并管理 Docker 对象，例如镜像、容器、网络和卷。守护进程还可以与其他守护进程通信以管理 Docker 服务。\nThe Docker client(Docker 客户端) Docker 客户端 ( docker) 是许多 Docker 用户与 Docker 交互的主要方式。当您使用诸如docker run之类的命令时，客户端会将这些命令发送到dockerd执行它们。 该docker命令使用 Docker API。Docker 客户端可以与多个守护进程通信。\nDocker Desktop(Docker 桌面) Docker Desktop 是一个易于安装的应用程序，适用于您的 Mac、Windows 或 Linux 环境，使您能够构建和共享容器化应用程序和微服务。 Docker Desktop 包括 Docker 守护程序 ( dockerd)、Docker 客户端 ( docker)、Docker Compose、Docker Content Trust、Kubernetes 和 Credential Helper\nDocker registries(Docker 镜像仓库) Docker镜像仓库存储 Docker 镜像。Docker Hub 是一个任何人都可以使用的公共镜像仓库，并且 Docker 默认配置为在 Docker Hub 上查找镜像。您甚至可以运行自己的私有镜像仓库。\n当您使用docker pull或者docker run命令时，将从您配置的镜像仓库中拉取所需的镜像。当您使用该docker push命令时，您的镜像会被推送到您配置的镜像仓库中。\nDocker objects(Docker 对象) 当您使用 Docker 时，您正在创建和使用镜像、容器、网络、卷、插件和其他对象。\nImages(镜像) 镜像是一个只读模板，其中包含创建 Docker 容器的说明。通常，一个镜像基于另一个镜像，并带有一些额外的自定义。 例如，您可以基于该镜像构建一个镜像ubuntu ，但安装 Apache Web 服务器和您的应用程序，以及使您的应用程序运行所需的配置详细信息。\n您可以创建自己的镜像，也可以只使用其他人创建并在镜像仓库中发布的镜像。要构建您自己的镜像，您需要使用简单的语法创建一个Dockerfile ， 用于定义创建和运行镜像所需的步骤。Dockerfile 中的每条指令都会在镜像中创建一个层。当您更改 Dockerfile 并重建镜像时，仅重建那些已更改的层。 与其他虚拟化技术相比，这是使镜像如此轻量、小巧和快速的部分原因。\n运行容器时，它使用隔离的文件系统。此自定义文件系统由容器镜像提供。由于镜像包含容器的文件系统， 它必须包含运行应用程序所需的一切（所有依赖项、配置、脚本、二进制文件等）。镜像还包含容器的其他配置，例如环境变量、要运行的默认命令、和其他元数据。\nContainers(容器) 容器是镜像的可运行实例。您可以使用 Docker API 或 CLI 创建、启动、停止、移动或删除容器。您可以将容器连接到一个或多个网络，将存储附加到它，甚至可以根据其当前状态创建新镜像。\n默认情况下，一个容器与其他容器及其主机的隔离相对较好。您可以控制容器的网络、存储或其他底层子系统与其他容器或主机的隔离程度。\n容器由其镜像以及您在创建或启动它时提供给它的任何配置选项定义。当容器被移除时，任何未存储在持久存储中的状态更改都会消失。\n容器是您机器上的沙盒进程，与主机上的所有其他进程隔离。这种隔离利用了内核命名空间和 cgroups，这些特性在 Linux 中已经存在了很长时间。Docker 致力于使这些功能变得平易近人且易于使用。总而言之，一个容器：\n是镜像的可运行实例。您可以使用 DockerAPI 或 CLI 创建、启动、停止、移动或删除容器。 可以在本地机器、虚拟机上运行或部署到云端。 是可移植的（可以在任何操作系统上运行）。 与其他容器隔离并运行自己的软件、二进制文件和配置。 docker的安装部署 安装docker 1.安装docker\n1 2 3 4 5 6 7 8 [root@k8scloude1 ~]# yum -y install docker-ce 已加载插件：fastestmirror base | 3.6 kB 00:00:00 ...... 已安装: docker-ce.x86_64 3:20.10.12-3.el7 ...... 完毕！ 2.设置docker开机自启动并现在启动docker\n1 2 3 4 5 6 7 8 9 10 11 12 [root@k8scloude1 ~]# systemctl enable docker --now Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service. [root@k8scloude1 ~]# systemctl status docker ● docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled) Active: active (running) since 六 2022-01-08 22:10:38 CST; 18s ago Docs: https://docs.docker.com Main PID: 1377 (dockerd) Memory: 30.8M CGroup: /system.slice/docker.service └─1377 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock 3.查看docker版本\n1 2 [root@k8scloude1 ~]# docker --version Docker version 20.10.12, build e91ed57 4.docker info : 显示 Docker 系统信息，包括镜像和容器数等等\n配置阿里云docker镜像加速器 1.配置docker镜像加速器\n1 2 3 4 5 6 7 8 9 10 [root@k8scloude1 ~]# cat \u0026gt; /etc/docker/daemon.json \u0026lt;\u0026lt;EOF \u0026gt; { \u0026gt; \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://frz7i079.mirror.aliyuncs.com\u0026#34;] \u0026gt; } \u0026gt; EOF [root@k8scloude1 ~]# cat /etc/docker/daemon.json { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://frz7i079.mirror.aliyuncs.com\u0026#34;] } 2.重启docker\n1 2 3 4 5 6 7 8 9 10 11 [root@k8scloude1 ~]# systemctl restart docker [root@k8scloude1 ~]# systemctl status docker ● docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled) Active: active (running) since 六 2022-01-08 22:17:45 CST; 8s ago Docs: https://docs.docker.com Main PID: 1529 (dockerd) Memory: 32.4M CGroup: /system.slice/docker.service └─1529 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock docker的管理 docker镜像的管理 1.docker镜像命名规范\n给镜像打标签(tag)时需要注意命名的规范，一般为:系统名称+系统版本+服务名+服务版本:代码版本如:centos7.6-nginx-1.47:2.0。\n2.docker镜像管理命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #搜索镜像：docker search 镜像 #拉取镜像：docker pull [选项] [Docker Registey 地址[:端口号]/] 镜像名[:标签] #在镜像列表中，可能会存在一种特殊的镜像，该镜像既没有仓库名/镜像名称，也没有标签/版本号，这两个位置均显示\u0026lt;none\u0026gt;，这种镜像通常被称为虚悬镜像，一般来说，虚悬镜像已经失去了存在的价值，是可以随意删除的，使用下面的命令删除：docker image prune #给镜像打标签:docker tag 镜像 #删除本地镜像：docker rmi 镜像 #导出镜像为tar包：docker save 镜像名 \u0026gt; filename.tar #导入镜像：docker load -i filename.tar #把容器导出为镜像tar包： docker export 容器名 \u0026gt; filename.tar #导入镜像tar包： cat filename.tar | docker import - 镜像名 列出镜像：docker images\n1 2 3 [root@k8smaster ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hub.c.163.com/library/centos latest 328edcd84f1b 4 years ago 193MB 查看指定镜像的创建历史：docker history xxxx \u0026ndash;no-trunc 可以显示完整的内容\n1 2 3 4 5 6 7 8 9 10 11 [root@k8smaster ~]# docker history hub.c.163.com/library/centos IMAGE CREATED CREATED BY SIZE COMMENT 328edcd84f1b 4 years ago /bin/sh -c #(nop) CMD [\u0026#34;/bin/bash\u0026#34;] 0B \u0026lt;missing\u0026gt; 4 years ago /bin/sh -c #(nop) LABEL name=CentOS Base Im… 0B \u0026lt;missing\u0026gt; 4 years ago /bin/sh -c #(nop) ADD file:63492ba809361c51e… 193MB [root@k8smaster ~]# docker history hub.c.163.com/library/centos --no-trunc IMAGE CREATED CREATED BY SIZE COMMENT sha256:328edcd84f1bbf868bc88e4ae37afe421ef19be71890f59b4b2d8ba48414b84d 4 years ago /bin/sh -c #(nop) CMD [\u0026#34;/bin/bash\u0026#34;] 0B \u0026lt;missing\u0026gt; 4 years ago /bin/sh -c #(nop) LABEL name=CentOS Base Image vendor=CentOS license=GPLv2 build-date=20170801 0B \u0026lt;missing\u0026gt; 4 years ago /bin/sh -c #(nop) ADD file:63492ba809361c51e75605d70390b549ff1187076b6d00485a1a0bb175daa40e in / 193MB docker容器的管理 docker容器管理命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #运行容器:docker run 镜像 #删除容器：docker rm 容器名 #显示容器:docker ps #列出指定容器的端口映射：docker port 容器名 [root@etcd2 ~]# docker port harbor-log 10514/tcp -\u0026gt; 127.0.0.1:1514 #在运行的容器中执行命令：docker exec xxxx 命令 #启动容器：docker start xxxx #停止容器：docker stop xxxxx #重启容器：docker restart xxxxx #杀掉一个运行中的容器：docker kill 容器名 #进入运行中的容器(连接到正在运行中的容器使用exit退出后容器自动关闭，不推荐使用)：docker attach CONTAINER #查看容器中运行的进程信息：docker top xxxxx #查看所有容器运行的进程：for i in `docker ps |grep Up|awk \u0026#39;{print $1}\u0026#39;`;do echo \\ \u0026amp;\u0026amp;docker top $i; done #获取容器的日志：docker logs -f node #获取容器的详细信息：docker inspect 容器名 #容器与主机之间的数据拷贝: #从容器里复制数据到主机：docker cp CONTAINER:SRC_PATH DEST_PATH #从主机里复制数据到容器：docker cp SRC_PATH| CONTAINER:DEST_PATH [root@etcd2 ~]# docker cp /opt/ 7c677fb67522:/home 运行容器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #运行容器:docker run 镜像 #docker run 镜像 ---最简单的一个容器 #docker run -it --rm hub.c.163.com/library/centos /bin/bash #docker run -dit -h node --name=c1 镜像名 命令 #docker run -dit --restart=always 镜像名 命令 #docker run -dit --restart=always -e 变量1=值1 -e 变量2=值2 镜像 常见参数 -a stdin: 指定标准输入输出内容类型，可选 STDIN/STDOUT/STDERR 三项； -d: 后台运行容器，并返回容器ID； -i: 以交互模式运行容器，通常与 -t 同时使用； -P: 随机端口映射，容器内部端口随机映射到主机的端口 -p: 指定端口映射，格式为：主机(宿主)端口:容器端口 -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用； --name=\u0026#34;nginx-lb\u0026#34;: 为容器指定一个名称； --dns 8.8.8.8: 指定容器使用的DNS服务器，默认和宿主一致； --dns-search example.com: 指定容器DNS搜索域名，默认和宿主一致； -h \u0026#34;mars\u0026#34;: 指定容器的hostname； -e username=\u0026#34;ritchie\u0026#34;: 设置环境变量； --env-file=[]: 从指定文件读入环境变量； --cpuset=\u0026#34;0-2\u0026#34; or --cpuset=\u0026#34;0,1,2\u0026#34;: 绑定容器到指定CPU运行； -m :设置容器使用内存最大值； --net=\u0026#34;bridge\u0026#34;: 指定容器的网络连接类型，支持 bridge/host/none/container: 四种类型； --link=[]: 添加链接到另一个容器； --expose=[]: 开放一个端口或一组端口； --volume , -v: 绑定一个卷 容器管理示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #运行一个容器并进入到里面 [root@k8smaster ~]# docker run -it --restart=always --name=centos hub.c.163.com/library/centos:latest [root@3c6f6cc36259 /]# ps | grep bash 1 pts/0 00:00:00 bash [root@3c6f6cc36259 /]# cat /etc/redhat-release CentOS Linux release 7.3.1611 (Core) #退出容器 [root@3c6f6cc36259 /]# exit exit #退出之后，查看发现容器进程还在 [root@k8smaster ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3c6f6cc36259 hub.c.163.com/library/centos:latest \u0026#34;/bin/bash\u0026#34; About a minute ago Up 3 seconds centos #再次进入容器 [root@k8smaster ~]# docker attach centos [root@3c6f6cc36259 /]# #删除容器，-f强制删除 [root@k8smaster ~]# docker rm -f centos centos [root@k8smaster ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES #运行一个容器但是不进入到里面，-d dettach [root@k8smaster ~]# docker run -dit --restart=always --name=centos hub.c.163.com/library/centos:latest 0f683a6c33868fee306b26b9d84fbf1ddbe1522f5c6d49944324ec57e1eb5990 [root@k8smaster ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 0f683a6c3386 hub.c.163.com/library/centos:latest \u0026#34;/bin/bash\u0026#34; 8 seconds ago Up 6 seconds centos #运行容器，运行命令：sleep 100 [root@k8smaster ~]# docker run -dit --restart=always --name=centos hub.c.163.com/library/centos:latest sleep 100 ae064dd568d9b489329d8c6e7f7c0795fb40efec1f4424a9137ce1f076946502 #进入容器什么也做不了，因为没有/bin/bash接待你 [root@k8smaster ~]# docker attach centos 运行nginx容器示例，容器端口映射 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 #运行nginx容器，容器端口为80,物理机端口随机生成 [root@k8smaster ~]# docker run -dit --name=web --restart=always -p 80 hub.c.163.com/library/nginx:latest bee79324ce9bfbef6bfaf7bdf671ff74007e12e2ffac5e0662fb8522442e275f #物理机端口为49153 [root@k8smaster ~]# docker ps | grep web bee79324ce9b hub.c.163.com/library/nginx:latest \u0026#34;nginx -g \u0026#39;daemon of…\u0026#34; 39 seconds ago Up 37 seconds 0.0.0.0:49153-\u0026gt;80/tcp, :::49153-\u0026gt;80/tcp web #访问nginx [root@k8smaster ~]# curl 192.168.110.137:49153 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Welcome to nginx!\u0026lt;/title\u0026gt; \u0026lt;style\u0026gt; body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to nginx!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;If you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;For online documentation and support please refer to \u0026lt;a href=\u0026#34;http://nginx.org/\u0026#34;\u0026gt;nginx.org\u0026lt;/a\u0026gt;.\u0026lt;br/\u0026gt; Commercial support is available at \u0026lt;a href=\u0026#34;http://nginx.com/\u0026#34;\u0026gt;nginx.com\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;em\u0026gt;Thank you for using nginx.\u0026lt;/em\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; #-p 80:80表示物理机端口：容器端口 [root@k8smaster ~]# docker run -dit --name=web --restart=always -p 80:80 hub.c.163.com/library/nginx:latest c027df65a8894f1b82cd38bc15a016a6b5b2c9e3ba36487a7692363fce9ee91b [root@k8smaster ~]# docker ps | grep web c027df65a889 hub.c.163.com/library/nginx:latest \u0026#34;nginx -g \u0026#39;daemon of…\u0026#34; 7 seconds ago Up 3 seconds 0.0.0.0:80-\u0026gt;80/tcp, :::80-\u0026gt;80/tcp web #执行容器变量，-e指定容器的变量 [root@k8smaster ~]# docker run -dit --restart=always --name=centos -e xx=12 -e yy=13 hub.c.163.com/library/centos:latest 8b9c2042ffe2e7bc1e7b263128b8fe903b9b3fa403030c23024b0a8c055b0b3c [root@k8smaster ~]# docker attach centos [root@8b9c2042ffe2 /]# echo $xx 12 [root@8b9c2042ffe2 /]# echo $yy 13 [root@8b9exit exit #--rm创建临时容器 [root@k8smaster ~]# docker run -it --rm --name=test -e xx=12 -e yy=13 hub.c.163.com/library/centos:latest [root@328ca3ac967f /]# echo $xx 12 [root@328ca3ac967f /]# exit exit 运行mysql容器示例，练习容器基本操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 #拉取mysql镜像 [root@k8smaster ~]# docker pull hub.c.163.com/library/mysql:latest [root@k8smaster ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hub.c.163.com/library/mysql latest 9e64176cd8a2 4 years ago 407MB [root@k8smaster ~]# docker run -dit --restart=always --name=db hub.c.163.com/library/mysql a0d580fc15c6487b2d639c92c0024ad6125af649067fee55eebcd8f9fa58bdb8 #发现mysql容器的状态是Restarting [root@k8smaster ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES a0d580fc15c6 hub.c.163.com/library/mysql \u0026#34;docker-entrypoint.s…\u0026#34; 8 seconds ago Restarting (1) 2 seconds ago db #查看mysql容器的日志，发现是没有指定mysql的密码 [root@k8smaster ~]# docker logs db error: database is uninitialized and password option is not specified You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD error: database is uninitialized and password option is not specified You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD error: database is uninitialized and password option is not specified You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD error: database is uninitialized and password option is not specified You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD error: database is uninitialized and password option is not specified You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD error: database is uninitialized and password option is not specified You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD error: database is uninitialized and password option is not specified You need to specify one of MYSQL_ROOT_PASSWORD, MYSQL_ALLOW_EMPTY_PASSWORD and MYSQL_RANDOM_ROOT_PASSWORD [root@k8smaster ~]# docker rm -f db db [root@k8smaster ~]# docker run -dit --restart=always --name=db -e MYSQL_ROOT_PASSWORD=qwerty hub.c.163.com/library/mysql 01d83d13eb32e25c72cd39290ab12d5f69b994cec3e48dd9c8608e719cd2181c [root@k8smaster ~]# docker ps | grep hub.c.163.com/library/mysql 01d83d13eb32 hub.c.163.com/library/mysql \u0026#34;docker-entrypoint.s…\u0026#34; 19 seconds ago Up 15 seconds 3306/tcp db #查看容器里运行的进程 [root@k8smaster ~]# docker top db UID PID PPID C STIME TTY TIME CMD polkitd 93764 93742 7 16:40 pts/0 00:00:02 mysqld #因为运行的是mysqld进程，没有bash进程，所以attach进不去 [root@k8smaster ~]# docker attach db #在容器外面执行shell命令 [root@k8smaster ~]# docker exec db ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 2: tunl0@NONE: \u0026lt;NOARP\u0026gt; mtu 1480 qdisc noop state DOWN group default qlen 1 link/ipip 0.0.0.0 brd 0.0.0.0 62: eth0@if63: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:04 brd ff:ff:ff:ff:ff:ff inet 172.17.0.4/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever #可以自带bash，进入容器 [root@k8smaster ~]# docker exec -it db /bin/bash root@01d83d13eb32:/# root@01d83d13eb32:/# exit exit #停止/启动/重启容器 [root@k8smaster ~]# docker stop db db [root@k8smaster ~]# docker start db db [root@k8smaster ~]# docker restart db db [root@k8smaster ~]# docker exec db ls /tmp #复制文件 [root@k8smaster ~]# docker cp /etc/docker/daemon.json db:/tmp [root@k8smaster ~]# docker exec db ls /tmp daemon.json [root@k8smaster ~]# docker cp db:/tmp/daemon.json ./ [root@k8smaster ~]# ls daemon.json daemon.json #查看容器日志 [root@k8smaster ~]# docker logs -f db #查看容器的属性(容器详细信息) [root@k8smaster ~]# docker inspect db [ { \u0026#34;Id\u0026#34;: \u0026#34;01d83d13eb32e25c72cd39290ab12d5f69b994cec3e48dd9c8608e719cd2181c\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2021-12-28T08:40:56.781434728Z\u0026#34;, \u0026#34;Path\u0026#34;: \u0026#34;docker-entrypoint.sh\u0026#34;, \u0026#34;Args\u0026#34;: [ \u0026#34;mysqld\u0026#34; ], ...... \u0026#34;DriverOpts\u0026#34;: null } } } } ] #查看容器IP地址 [root@k8smaster ~]# docker inspect db | grep IPAddress \u0026#34;SecondaryIPAddresses\u0026#34;: null, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.17.0.4\u0026#34;, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.17.0.4\u0026#34;, 容器数据卷volumes(容器目录映射) 数据卷是保存由 Docker 容器生成和使用的数据的首选机制。虽然绑定挂载依赖于主机的目录结构和操作系统，但数据卷完全由 Docker 管理。 与绑定挂载相比，数据卷有几个优点：\n数据卷比绑定挂载更容易备份或迁移。 您可以使用 Docker CLI 命令或 Docker API 管理数据卷。 数据卷适用于 Linux 和 Windows 容器。 数据卷可以在多个容器之间更安全地共享。 数据卷驱动程序允许您将数据卷存储在远程主机或云提供商上，以加密数据卷的内容或添加其他功能。 新数据卷的内容可以由容器预先填充。 Docker Desktop 上的数据卷比来自 Mac 和 Windows 主机的绑定挂载具有更高的性能。 此外，与在容器的可写层中持久化数据相比，数据卷通常是更好的选择，因为数据卷不会增加使用它的容器的大小，并且数据卷的内容存在于给定容器的生命周期之外。\n如果您的容器生成非持久状态数据，请考虑使用 tmpfs 挂载以避免将数据永久存储在任何地方，并通过避免写入容器的可写层来提高容器的性能。\n数据卷挂载可以使用-v 参数或者 \u0026ndash;mount参数，本文使用-v参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 #挂载数据卷：-v 本地目录：容器目录 -v /centos-test:/tmp [root@k8smaster ~]# docker run -it --restart=always --name=centos-test -v /centos-test:/tmp hub.c.163.com/library/centos:latest [root@38702e15b0d4 /]# ls /tmp/ [root@38702e15b0d4 /]# touch /tmp/aa.txt [root@38702e15b0d4 /]# ls /tmp/ aa.txt bb.txt [root@38702e15b0d4 /]# exit exit [root@k8smaster ~]# docker inspect centos-test [ { \u0026#34;Id\u0026#34;: \u0026#34;38702e15b0d49e1b7dcd8ddaa0e98dc050c520e323e6fe45ce773072e8bd2d9b\u0026#34;, ...... \u0026#34;Mounts\u0026#34;: [ { \u0026#34;Type\u0026#34;: \u0026#34;bind\u0026#34;, \u0026#34;Source\u0026#34;: \u0026#34;/centos-test\u0026#34;, \u0026#34;Destination\u0026#34;: \u0026#34;/tmp\u0026#34;, \u0026#34;Mode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;RW\u0026#34;: true, \u0026#34;Propagation\u0026#34;: \u0026#34;rprivate\u0026#34; } ], ...... } } } } ] [root@k8smaster ~]# docker rm -f centos-test centos-test #-v /centos-test:/tmp:ro容器目录只读挂载 [root@k8smaster ~]# docker run -it --restart=always --name=centos-test -v /centos-test:/tmp:ro hub.c.163.com/library/centos:latest [root@0c2793968ab4 /]# touch /tmp/cc.txt touch: cannot touch \u0026#39;/tmp/cc.txt\u0026#39;: Read-only file system [root@0c2793968ab4 /]# exit exit #另外一种挂载数据卷的方法： [root@k8smaster ~]# docker volume create v1 v1 [root@k8smaster ~]# docker volume list DRIVER VOLUME NAME local 3512441fd63342a92e4642d4332c2e8c9603b4b536b45173bb77802d1f3db52f local e58e312c1517081a8508838d8fcda74b895ac034d53740af478c6a18b6552f34 local f80a9bd35412905392fad18903053e122e3d3066239751e0ceca6a5b5fb8884e local v1 [root@k8smaster ~]# docker volume inspect v1 [ { \u0026#34;CreatedAt\u0026#34;: \u0026#34;2021-12-28T21:57:33+08:00\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Labels\u0026#34;: {}, \u0026#34;Mountpoint\u0026#34;: \u0026#34;/var/lib/docker/volumes/v1/_data\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;v1\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34; } ] [root@k8smaster ~]# docker run -it --restart=always --name=centos-test1 -v v1:/opt:ro hub.c.163.com/library/centos:latest [root@4f48281dfc07 /]# ls /opt/ [root@4f48281dfc07 /]# exit exit [root@k8smaster ~]# docker run -dit --restart=always --name=db -e MYSQL_ROOT_PASSWORD=qwerty hub.c.163.com/library/mysql eedcd260e5758013bde97205bea0a3c7c4c04bfab8dce308bc41b1b6cac262f4 [root@k8smaster ~]# docker inspect db | grep -i ipaddr \u0026#34;SecondaryIPAddresses\u0026#34;: null, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.17.0.6\u0026#34;, \u0026#34;IPAddress\u0026#34;: \u0026#34;172.17.0.6\u0026#34;, [root@k8smaster ~]# mysql -uroot -pqwerty -h 172.17.0.6 MySQL [(none)]\u0026gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) MySQL [(none)]\u0026gt; exit Bye [root@k8smaster ~]# docker rm -f db db [root@k8smaster ~]# docker run -dit --restart=always --name=db -e MYSQL_ROOT_PASSWORD=qwerty -v /mysqldir:/var/lib/mysql hub.c.163.com/library/mysql 09973a94e99861fd5f19e63bf3947d95a3e14fd0de40c1aa0af605af1fad3ab7 [root@k8smaster ~]# ls /mysqldir/ ","date":"2023-10-27T10:49:41+08:00","permalink":"http://localhost:1313/post/docker-container-base/","title":"一文搞懂docker容器基础：docker镜像管理，docker容器管理"},{"content":"关于mysql general_log MySQL General Log（一般日志）是MySQL数据库的一种日志记录功能，用于记录数据库服务器上发生的所有操作。它可以记录包括连接、查询、事务等在内的所有操作。\nGeneral Log记录的内容包括：\n客户端连接和断开连接的信息，包括连接的用户、IP地址、端口等。 执行的SQL查询语句，包括SELECT、INSERT、UPDATE、DELETE等。 事务的开始和提交信息。 错误和警告信息。 General Log的作用是用于调试和审计。通过查看General Log，您可以了解数据库服务器上发生的所有操作，包括哪些查询被执行、哪些连接被建立和断开、是否发生了错误等。这对于调试应用程序问题、分析慢查询、检查数据库安全性等非常有用。\n但是需要注意的是，启用General Log会对数据库服务器的性能产生一定的影响，因为它会记录大量的操作信息。因此，在生产环境中，一般不建议一直启用General Log，而是根据需要进行临时开启或者只记录特定的操作。\n使用方法 在数据库启动前开启 在启动mysqld服务时指定相应参数\n1 2 3 4 # --general_log 开启或关闭日志 # --log_output=[FILE,TABLE,NONE] 指定日志输出类型 # --general_log_file=file_name 指定日志输出位置 /usr/local/mysql/bin/mysqld --general_log=on --log_output=\u0026#39;FILE\u0026#39; --general_log_file=\u0026#39;/data/mysql/log_output/slt.log\u0026#39; 在数据库运行时开启 1 2 3 4 set global general_log_file=\u0026#39;/data/mysql/log_output/slt.log\u0026#39;; # 指定日志输出位置 SET GLOBAL log_output=\u0026#39;FILE\u0026#39;; # 指定日志输出类型 set global general_log=on; # 开启日志 # 此外，可以通过设置sql_log_off的值为ON或OFF来禁用或启用当前连接的General query log。 ","date":"2023-10-12T19:38:23+08:00","permalink":"http://localhost:1313/post/mysql-general-log/","title":"mysql general_log"},{"content":"ssh SSH（Secure Shell）是一种网络协议，用于在不安全的网络上安全地进行远程登录和执行命令。SSH提供了加密的连接，以防止敏感信息（如密码）被窃听。\nSSH包括二个部分，服务端的SSHD（Secure Shell Daemon）和SSH客户端。我们通常所说的用SSH登录到某某主机，指的是用SSH客户端远程登录到某台主机（该主机运行了SSHD服务端程序）。\n使用方法 1 2 3 4 5 6 7 8 9 10 ssh [选项] [用户名@]主机名 [命令] # 选项：常见的选项包括-p（指定端口号）、-i（指定私钥文件）等。 # 用户名：远程主机上的用户名。 # 主机名：远程主机的IP地址或域名。 # 命令：可选参数，用于在登录后执行特定的命令。 ssh root@192.168.0.1 # -p 指定端口 ssh -p 2222 user@example.com scp SCP（Secure Copy）是基于SSH协议的文件传输工具，用于在本地和远程主机之间安全地复制文件。\n使用方法 1 2 3 4 5 6 7 8 9 scp [选项] [源文件] [目标路径] # 选项：-v 显示进度，-C 启用压缩功能，-P 指定端口 # -4 强行使用 IPV4 地址，-6 强行使用 IPV6 地址，-r 递归复制整个目录 # 从远程服务器下载文件 scp 服务器地址:服务器文件路径 本地保存路径 # 上传文件到远程服务器 scp 本地文件地址 服务器地址:/远程保存路径 ftp FTP（File Transfer Protocol）是一种用于在网络上传输文件的标准协议。它使用明文传输，不提供加密功能。\n使用方法 1 2 3 4 5 6 ftp [选项] [主机名] # 选项：常见选项包括-p（指定端口号）、-u（指定用户名）等。 # 主机名：远程主机的IP地址或域名。 ftp example.com ftp -p 2222 user@example.com sftp SFTP（SSH File Transfer Protocol）是基于SSH协议的安全文件传输协议，提供了加密和身份验证功能。\n使用方法 登录\n1 2 3 4 sftp [选项] [用户名@]主机名 # 选项：常见选项包括-P（指定端口号）、-i（指定私钥文件）等。 # 用户名：远程主机上的用户名。 # 主机名：远程主机的IP地址或域名。 登录到远程主机后，可以如下运行交互式的 sFTP 命令：\n1 2 3 4 sftp\u0026gt; ls #list directory sftp\u0026gt; pwd #print working directory on remote host sftp\u0026gt; lpwd #print working directory on local host sftp\u0026gt; mkdir uploads #create a new directory 上传文件\n1 2 3 4 5 6 7 8 # put [本地文件的地址] [服务器上文件存储的位置] sftp\u0026gt; put text.md # put -r 将整个目录上传到服务器，但是，如果目录名称不存在于服务器中，会报错。 sftp\u0026gt; put -r dirname # 使用-p参数保留修改时间、访问时间以及被传输的文件的模式 sftp\u0026gt; put -pr dirname 下载文件\n1 2 3 4 # get [服务器上文件存储的位置] [本地要存储的位置] sftp\u0026gt; get filename # get -r 将整个目录下载到本地 sftp\u0026gt; get -r dirname ","date":"2023-09-28T16:05:04+08:00","permalink":"http://localhost:1313/post/ssh-scp-ftp-sftp/","title":"ssh、scp、ftp、sftp命令详解"},{"content":"本文内容来自 Shell：Shell 系列文章\nBash 数值运算 Bash 内置数值运算 使用 $(())、$[] 或内置命令 let 或 declare -i(以及等价的 typeset 命令) 可以进行数值运算，它们都只能进行整数运算。\nlet 命令只能单独作为一个命令行运算 declare -i 声明整数类型的变量，声明后就能直接参与数值运算 $(()) 和 $[] 可以在命令内部进行运算，运算完成后会进行算术替换：即将运算结果替换到命令行中 例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # 使用let n=1 let n=n+1 echo $n # 2 let n=$n+1 echo $n # 3 # 使用declare -i declare -i a b c a=10 b=100 c=a+b echo $c # 110 # 使用$(())和$[] x=10 y=20 echo $(( (x+y)*2 )) echo $[ (x+y)*2 ] 小数运算 Bash 自身语法不支持小数运算。但如果真的需要进行精确到小数的运算，是可以借助其它命令工具，比如 bc、awk、perl 等等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 使用awk $ echo 1.2 2.3 | awk \u0026#39;{print $1+$2}\u0026#39; 3.5 $ awk \u0026#39;BEGIN{print 1.2+2.3}\u0026#39; 3.5 # 使用bc $ echo 1.2+2.3 | bc 3.5 # 使用perl $ perl -E \u0026#39;say 1.2+2.3\u0026#39; 3.5 $ echo 1.2 2.3 | perl -anE \u0026#39;say $F[0]+$F[1]\u0026#39; 3.5 Bash 支持的运算操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 id++ id-- ++id --id 自增、自减 - + 一元运算符，即正负号 ! ~ 逻辑取反、位取反 ** 幂运算 * / % 乘法、除法、取模 + - 加法、减法 \u0026lt;\u0026lt; \u0026gt;\u0026gt; 位左移、位右移 \u0026amp; 按位与运算 ^ 按位异或运算 | 按位或运算 \u0026lt;= \u0026gt;= \u0026lt; \u0026gt; 大小比较 == != 等值比较 \u0026amp;\u0026amp; 逻辑与 || 逻辑或 expr ? expr : expr 三目条件运算 = *= /= %= += -= \u0026lt;\u0026lt;= \u0026gt;\u0026gt;= \u0026amp;= ^= |= 各种赋值语句 expr1 , expr2 多个表达式，例如$((x+=1,y+=3,z+=4)) 几个注意事项：\n空变量或未定义变量或字符串变量参与数值运算时，都当作数值0 变量替换先于算术运算，所以既可以使用变量名var，也可使用变量引用$var，例如$[a+1]和$[$a+1]在结果上是等价的 算术表达式可以进行嵌套，先计算最内层。如$(( (6+4)/$[2+3] )) 0开头的表示八进制，0x或0X开头的表示十六进制，可使用base#N的方式指定N是多少进制的数。例如echo $[ 010 + 10 ]得到18、echo $[ 0x10 + 10 ]得到26，echo $[ 2#100 + 10 ]得到14。参见下面一个实际案例 由上面的运算符可看出，$[]、$(())以及let命令，既支持算术运算，还支持赋值、大小比较、等值比较。如a=3;echo $[a==3] 有时候从字符串中截取得到的数值是以0开头的，如果要让它参与运算，需要指定为十进制，否则会当作八进制。例如：\n1 2 3 4 5 6 7 datetime1=`date +\u0026#34;%s.%N\u0026#34;` nano_seconds1=${datetime1#*.} sleep 1 datetime2=`date +\u0026#34;%s.%N\u0026#34;` nano_seconds2=${datetime2#*.} echo $[ 10#$nano_seconds2 - 10#$nano_seconds1 ] ","date":"2023-09-28T15:27:00+08:00","permalink":"http://localhost:1313/post/shell-operation/","title":"shell 运算"},{"content":"本文转载自 Shell 脚本深入教程：Bash 变量\n变量赋值 等号 = 左右两边必须不能出现空白。当包含了特殊符号时，需要使用引号包围。使用单引号还是双引号，后面再详细解释。\n1 2 3 var1=22 # 数值 var2=\u0026#34;hello world\u0026#34; # 字符串 var3=hello world # 错误 问题：var3=hello world 为什么报错的是没有 world 命令，而不是赋值错误？为什么 echo = 3 不是赋值？\nvar=value CMD 是shell的一种用法，在命令最前面赋值的变量var只在当前所执行的命令CMD中有效，其他任何地方都无法使用var变量，CMD退出后，var也消失。\n其实经常会看到这种用法，比如下面的命令模式，表示 cmd 命令执行时设置 locale 环境为 C，但非 cmd 命令则不受影响：\n1 LC_ALL=C cmd 使用 unset 内置命令可以注销变量：\n1 2 3 4 var=\u0026#34;hello world\u0026#34; echo $var unset var echo $var 使用 readonly 内置命令可以定义只读变量，只读变量不可修改、不可注销。\n1 2 3 readonly xyz=\u0026#34;helloworld\u0026#34; abc=\u0026#34;hello world\u0026#34; readonley abc 变量引用 使用 $VAR 或 ${VAR}，前者是简写，后者是规范引用。\n例如：\n1 2 var=\u0026#39;hello world\u0026#39; echo $var 一定注意：变量的名称是 var，而不是 $var，$var 是在引用、访问变量在内存中保存的值。\n使用 ${#VAR} 获取变量 VAR 保存的字符长度。\n1 2 a=\u0026#34;hello world\u0026#34; echo ${#a} 当 $VAR 引用方式会产生歧义时，就用 ${VAR}，例如：\n1 2 3 VAR=\u0026#34;hello\u0026#34; echo $VARa # 访问变量VARa，但它不存在 echo ${VAR}a # 访问变量VAR，并将结果和a串联起来 环境变量 在 Shell 脚本中偶尔会考虑用环境变量，但是环境的概念在 Shell 中很重要。\n环境变量可以看作是一个全局变量，但这说法并不正确。后面我会详细解释何为 Shell 环境，这是 Shell 中非常重要的概念，到时候大家就会对环境变量有一个非常清晰的认识。\n使用 bash 内置命令 export 可以定义一个环境变量：\n1 2 3 4 5 6 # 直接定义一个新的环境变量 $ export ENV_VAR=\u0026#34;hello world\u0026#34; # 将一个已存在的普通变量导出为环境变量 $ ENV_VAR1=\u0026#34;HELLOWORLD\u0026#34; $ export ENV_VAR1 环境变量一般以大写字母命名。\n子 Shell 进程可以继承父 Shell 中的环境变量：\n1 2 3 4 x=1000 y=10000 export y bash -c \u0026#39;echo $x;echo $y\u0026#39; 使用 env 命令可以查看所有环境变量。\n1 env 可以在某个命令行前设置变量，便表示设置该命令的专属环境变量，只有该命令进程中可访问该环境变量，其它任何地方都无法访问，且命令退出后专属环境变量消失。\n1 2 3 4 5 6 7 8 9 10 # 下面等价 xyz=10 bash -c \u0026#39;echo $xyz\u0026#39; env xyz=100 bash -c \u0026#39;echo $xyz\u0026#39; # 环境变量只对cmd1有效 xyz=10 cmd1 | cmd2 # 环境变量对cmd1和cmd2都有效 xyz=10 cmd1 | xyz=10 cmd2 xyz=55 bash -c \u0026#39;cmd1 | cmd2\u0026#39; 常见的环境变量：\n1 2 3 4 5 6 7 8 9 10 HOSTNAME=control_node USER=root HOME=/root SHELL=/bin/bash HISTSIZE=1000 SSH_TTY=/dev/pts/2 PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin MAIL=/var/spool/mail/root PWD=/root LANG=en_US.UTF-8 特别要注意的是 PATH 环境变量，它决定了 Shell 调用命令时的搜索路径。经常会设置 PATH 环境变量，特别是应用在定时任务的 Shell 脚本。\n1 PATH=/usr/local/mysql/bin:$PATH 比如，编译安装或直接解压安装程序时，通常会将 PATH 写入到 /etc/profile.d/*.sh 下：\n1 2 echo \u0026#39;PATH=/usr/local/mysql/bin:$PATH\u0026#39; \u0026gt;/etc/profile.d/mysql.sh source /etc/profile.d/mysql.sh 位置参数和特殊变量 位置参数 Shell 脚本运行时可能需要一些选项或参数。\n比如，某脚本 test.sh 内容:\n1 2 3 #!/bin/bash cat $1 touch $2 这表示先读取并输出第一个参数表示文件内容，然后 touch 第二个参数表示的文件。执行时：\n1 2 chmod +x test.sh ./test.sh /etc/fstab /tmp/touchme.log 脚本执行时的选项 (本例没有选项) 和参数都是脚本的位置参数，位置参数使用 $1,$2,$3,\u0026hellip; 引用。\n$0 比较特殊，表示脚本名或当前 Shell 名称。\n位置参数是相对于每个 Shell 进程而言的。对于 Shell 脚本来说，位置参数就是执行脚本时的参数部分。当处于 Shell 环境内时，也可以使用 set -- 设置当前 Shell 环境位置参数：\n1 2 3 4 5 6 set -- a b c echo $1 echo $@ echo $# set -- # 清空当前Shell的位置参数 echo $# 特殊变量 Shell 有一些特殊变量，这些变量由 Shell 自身动态维护，不允许用户手动修改。\n为了让这些特殊变量更直观，我使用变量引用而不直接使用特殊变量名。\n1 2 3 4 5 6 7 8 9 10 $1,$2,...,$N：脚本的位置参数 $0：shell或shell脚本的名称 $*：扩展为位置参数，\u0026#34;$*\u0026#34;会将所有位置参数一次性包围引起来，\u0026#34;$*\u0026#34;等价于\u0026#34;$1_$2_$3...\u0026#34; $@：扩展为位置参数，\u0026#34;$@\u0026#34;会将每个位置参数单独引起来，\u0026#34;$@\u0026#34;等价于\u0026#34;$1\u0026#34; \u0026#34;$2\u0026#34; \u0026#34;$3\u0026#34;... $#：位置参数的个数 $$：当前Shell的进程PID，在某些子Shell(如小括号()开启的子Shell)下，会被继承。如果可以，建议使用$BASHPID替代$$ $?：最近一个前台命令的退出状态码 $!：最近一个后台命令的进程PID $-：当前Shell环境的一些特殊设置，比如是否交互式 $_：最近一个前台命令的最后一个参数（还有其它情况，该变量用的不多，所以不追究了） 关于 $* \u0026quot;$*\u0026quot; $@ \u0026quot;$@\u0026quot; 的区别，参见如下 shell 脚本测试：\n1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash echo \u0026#39;$*----------\u0026#39;: for i in $*;do echo \u0026#34;\u0026lt;$i\u0026gt;\u0026#34;;done echo \u0026#39;\u0026#34;$*--------\u0026#34;\u0026#39;: for i in \u0026#34;$*\u0026#34;;do echo \u0026#34;\u0026lt;$i\u0026gt;\u0026#34;;done echo \u0026#39;$@----------\u0026#39;: for i in $@;do echo \u0026#34;\u0026lt;$i\u0026gt;\u0026#34;;done echo \u0026#39;\u0026#34;$@--------\u0026#34;\u0026#39;: for i in \u0026#34;$@\u0026#34;;do echo \u0026#34;\u0026lt;$i\u0026gt;\u0026#34;;done 执行：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 $ chmod +x position_parameters.sh $ ./position_parameters.sh a b \u0026#39;c d\u0026#39; $*---------: \u0026lt;a\u0026gt; \u0026lt;b\u0026gt; \u0026lt;c\u0026gt; \u0026lt;d\u0026gt; \u0026#34;$*--------\u0026#34;: \u0026lt;a b c d\u0026gt; $@----------: \u0026lt;a\u0026gt; \u0026lt;b\u0026gt; \u0026lt;c\u0026gt; \u0026lt;d\u0026gt; \u0026#34;$@--------\u0026#34;: \u0026lt;a\u0026gt; \u0026lt;b\u0026gt; \u0026lt;c d\u0026gt; shift踢掉位置参数 Bash 内置命令 shift 专门用来踢位置参数。在为 Shell 脚本设计选项、参数时，都会用到 shift。\n1 shift [N] 踢掉前 N 个位置参数，如果没有指定 N 参数，则默认 N=1，即一次踢掉一个位置参数。\n踢掉位置参数后，后面的位置参数会向前移动。\n1 2 3 4 5 6 7 8 9 $ set -- a b c d e f $ echo ${#@} $ echo $1 a $ shift 2 $ echo ${@} c d e f $ echo ${1} c 例如，自定义 ping 命令的选项、参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #!/bin/bash while [ ${#@} -gt 0 ];do case \u0026#34;$1\u0026#34; in -c|--count) count=$2 shift 2 ;; -t|--timeout) timeout=$2 shift 2 ;; -a|--ip) ip=$2 shift 2 ;; *) echo \u0026#34;wrong options or arguments\u0026#34; exit 1 esac done ping -c $count -W timeout $ip ","date":"2023-09-27T15:52:59+08:00","permalink":"http://localhost:1313/post/shell-bash-var/","title":"Bash 变量"},{"content":"本文转载自 Shell 脚本深入教程：快速入门\nShell 脚本基础入门 bash注释 Bash 只支持单行注释，使用#开头的都被当作注释语句：\n1 2 # 整行注释 echo hello world # 行尾注释 通过 Bash 的一些特性，可以取巧实现多行注释：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 : \u0026#39; 注释1 注释2 \u0026#39; : \u0026lt;\u0026lt;\u0026#39;EOF\u0026#39; 注释1 注释2 EOF ____=\u0026#39; 注释1 注释2 \u0026#39; 但是，别闲的蛋疼去用取巧的多行注释，安心用#来注释。\nbash基本数据类型 Bash 中基本数据类型只有字符串类型，连数值类型都没有 (declare -i 可强制声明数值类型)。\n比如：\n1 2 3 # 都会当作字符串 echo haha echo 1234 bash字符串串联 Bash 中字符串的串联操作，直接将两段数据连接在一起即可，不需要任何操作符。\n例如：\n1 2 echo \u0026#34;arturia\u0026#34;\u0026#34;mu\u0026#34; echo 1234 5678 命令基本知识 变量赋值和引用变量 等号左右不能有空格\n1 2 3 4 5 6 7 8 a=3 echo $a a=\u0026#34;www.junmajinlong.com\u0026#34; echo $a a=\u0026#39;hello world\u0026#39; echo $a Shell 中可以引用未定义的变量：\n1 echo $xyzdefabc 可以定义空变量：\n1 2 a= echo $a 变量替换 变量替换是指在命令开始执行前，Shell 会先将变量的值替换到引用变量的位置处。\n例如：\n1 2 a=\u0026#34;hello\u0026#34; echo $a world 在 echo 命令开始执行前，Shell 会取得变量 a 的值 hello，并将它替换到命令行的 $a 处。于是，在 echo 命令开始执行时，命令行已经变成：\n1 echo hello world 除了变量替换，Shell 还会做其它替换：\n命令替换 进程替换 算术运算替换 大括号扩展 波浪号扩展 路径扩展 这些扩展和替换，都是 Shell 在调用命令之前就完成的，这和其它语言解析代码的方式不一样。\n后面会详细解释 Shell 是如何做命令行解析的，如果不掌握命令行解析，当遇到命令行语法错误后很可能会花掉大量无谓的时间去调试命令。而掌握命令行解析后， 就会对命令生命周期了如执掌，不敢说一次就能写对所有命令行，但能节省大量调试时间，对写命令行和写脚本的能力也会上升一个层次。\n命令替换 使用反引号或 $() 可以执行命令替换。\n1 2 `cmd` $(cmd) 命令替换是指先执行 cmd，将 cmd 的输出结果替换到 $() 或反引号位置处。\n例如：\n1 2 echo `id root` echo $(id root) 在 echo 命令执行前，会先执行 id 命令，id 命令的执行结果：\n1 2 $ id root uid=0(root) gid=0(root) groups=0(root) 所以会将结果 uid=0(root) gid=0(root) groups=0(root) 替换 $(id root)。于是，echo 命令开始执行时，命令行已经变成了：\n1 echo uid=0(root) gid=0(root) groups=0(root) 算术运算 $[] 或 $(()) 或 let 命令可以做算术运算。\nlet 是单独的命令，不能写在其它命令行中。\n1 2 3 a=3 let a=a+1 echo $a $[] 和 $(()) 可以写在命令行内部，Shell 在解析命令行的时候，会对它们做算术运算，然后将运算结果替换到命令行中。\n1 2 3 a=33 echo $[a+3] echo $((a+3)) 因为变量替换先于算术替换，所以，使用变量名或引用变量的方式都可以：\n1 2 3 a=333 echo $[$a+3] echo $(($a+3)) 退出状态码 每个命令执行后都会有对应的进程退出状态码，用来表示该进程是否是正常退出。\n所以，在命令行中，在 Shell 脚本中，经常会使用特殊变量 $? 判断最近一个前台命令是否正常退出。\n通常情况下，如果 $? 的值：\n为 0，表示进程成功执行，即正常退出 非 0，表示进程未成功执行，即非正常退出 但非 0 退出状态码并不一定表示错误，也可能是正常逻辑的退出 另外，在 Shell 脚本中，所有条件判断 (比如 if 语句、while 语句) 都以 0 退出状态码表示 True，以非 0 退出状态码为 False。\nexit命令 exit 命令可用于退出当前 Shell 进程，比如退出当前 Shell 终端、退出 Shell 脚本，等等。\n1 exit [N] exit 可指定退出状态码 N，如果省略 N，则默认退出状态码为 0，即表示正确退出。\n后台执行命令 \u0026amp; 在命令的结尾使用 \u0026amp; 符号，可以将这个命令放入后台执行。\n命令放入后台后，会立即回到 Shell 进程，Shell 进程会立即执行下一条命令 (如果有) 或退出。\n使用 $! 可以获取最近一个后台进程的 PID。\n1 2 sleep 20 \u0026amp; echo $! 使用 wait 命令可以等待后台进程 (当前 Shell 进程的子进程) 完成：\n1 wait [n1 n2 n3 ...] 不给定任何参数时，会等待所有子进程 (即所有后台进程) 完成。\n1 2 3 sleep 5 \u0026amp; wait echo haha 多命令组合 Shell 中有多种组合多个命令的方式。\n1.cmd1 退出后，执行 cmd2\n1 cmd1;cmd2 2.cmd1 正确退出 (退出状态码为 0) 后，执行 cmd2\n1 cmd1 \u0026amp;\u0026amp; cmd2 3.cmd1 不正确退出后，执行 cmd2\n1 cmd1 || cmd2 4.逻辑结合：\u0026amp;\u0026amp; 和 || 可以随意结合\n1 2 3 4 5 6 7 8 9 10 # cmd1正确退出后执行cmd2，cmd2正确退出后执行cmd3 cmd1 \u0026amp;\u0026amp; cmd2 \u0026amp;\u0026amp; cmd3... # cmd1正确退出则执行cmd2，cmd1不正确退出会执行cmd3 # cmd1正确退出，但cmd2不正确退出，也会执行cmd3 cmd1 \u0026amp;\u0026amp; cmd2 || cmd3 # cmd1正确退出会执行cmd3 # cmd1不正确退出会执行cmd2，cmd2正确退出会执行cmd3 cmd1 || cmd2 \u0026amp;\u0026amp; cmd3 5.将多个命令分组：小括号或大括号可以组合多个命令\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 小括号组合的多个命令是在子Shell中执行 # 即会先创建一个新的Shell进程，在执行里面的命令 (cmd1;cmd2;cmd3) # 大括号组合的多个命令是在当前Shell中执行 # 大括号语法特殊，要求： # 1.开闭括号旁边都有空白，否则语法解析错误(解析成大括号扩展) # 2.写在同一行时，每个cmd后都要加分号结尾 # 3.多个命令可分行书写，不要求分号结尾 { cmd1;cmd2;cmd3; } { cmd1 cmd2 cmd3 } 基本重定向 软件设计认为，程序应该有一个数据来源、数据出口和报告错误的地方。在 Linux 系统中，每个程序默认都会打开三个文件描述符 (file descriptor,fd)：\nfd=0：标准输入，表示程序默认从哪里读取数据 fd=1：标准输出，表示程序默认将数据输出到哪里 fd=2：标准错误，表示程序默认将错误信息输出到哪里 文件描述符，说白了就是系统为了跟踪打开的文件而分配给它的一个数字，这个数字和文件有对应关系：从文件描述符读取数据，即表示从对应的文件中读取数据， 向文件描述符写数据，即表示向对应文件中写入数据。\nLinux 中万物皆文件，文件描述符也是文件。默认：\nfd=0 的标准输入是 /dev/stdin 文件 fd=1 的标准输出是 /dev/stdout 文件 fd=2 的标准错误是 /dev/stderr 文件 这些文件默认又是各个终端的软链接文件：\n1 2 3 4 5 6 7 8 9 10 $ ls -l /dev/std* lrwxrwxrwx 1 root root 15 Jan 8 20:26 /dev/stderr -\u0026gt; /proc/self/fd/2 lrwxrwxrwx 1 root root 15 Jan 8 20:26 /dev/stdin -\u0026gt; /proc/self/fd/0 lrwxrwxrwx 1 root root 15 Jan 8 20:26 /dev/stdout -\u0026gt; /proc/self/fd/1 $ ls -l /proc/self/fd/ lrwx------ 1 root root 64 Jan 16 10:40 0 -\u0026gt; /dev/pts/0 lrwx------ 1 root root 64 Jan 16 10:40 1 -\u0026gt; /dev/pts/0 lrwx------ 1 root root 64 Jan 16 10:40 2 -\u0026gt; /dev/pts/0 lr-x------ 1 root root 64 Jan 16 10:40 3 -\u0026gt; /proc/75220/fd 所以，默认情况下读写数据都是终端，例如：\n1 2 3 4 5 6 7 8 9 10 11 # 数据输出到终端 $ echo haha $ cat /etc/fstab # 从终端读取数据 $ cat hello # 在终端输入 hello # 在终端输出 world # 在终端输入 world # 在终端输出 ^C 改变文件描述符对应的目标，可以改变数据的流向。比如标准输出 fd=1 默认流向是终端设备，若将其改为 /tmp/a.log，便能让数据写入 /tmp/a.log 文件中而不再是终端设备中。\n在 Shell 中，这种改变文件描述符目标的行为称为重定向，即重新确定数据的流向。\n其实，文件描述符有很多类操作，包括 fd 的重定向、fd 的分配 (open，即打开文件)、fd 复制 (duplicate)、fd 的移动 (move)、fd 的关闭 (close)。现在只介绍基础重定向操作。\nShell 中，基础重定向操作有以下几种方式：\n[n]\u0026gt;file：覆盖式输出重定向，输出到 fd=n 的数据改变流向输出到 file 文件中，file 不存在则创建，file 存在则先清空再写入数据 省略 n 时 \u0026gt;file，等价于 1\u0026gt;file，即标准输出覆盖重定向到 file 文件中 [n]\u0026gt;\u0026gt;file：追加式输出重定向，输出到 fd=n 的数据改变流向输出到 file 文件的尾部，file 不存在则创建，file 存在则直接追加在文件尾部 省略 n 时 \u0026raquo;file，等价于 1\u0026raquo;file，即标准输出追加重定向到 file 文件中 [n]\u0026lt;file：输入重定向，以读取模式打开 file 文件并分配 fd=n，file 不存在则报错 省略 n 时 \u0026lt;file，等价于 0\u0026lt;file，即直接从 file 中读数据 通常程序都只从 fd=0 中读数据，所以当 n 不等于 0 时，需要多做一步操作 3\u0026lt;file \u0026lt;\u0026amp;3，看不懂先跳过 \u0026amp;\u0026gt;file：这是特殊的重定向方式，表示将标准错误和标准输出都重定向到 file 文件中，等价于 \u0026gt;file 2\u0026gt;\u0026amp;1 \u0026amp;\u0026gt;\u0026gt;file：这是特殊的重定向方式，表示将标准错误和标准输出都追加到 file 文件中，等价于 \u0026raquo;file 2\u0026gt;\u0026amp;1 另外，经常用于输出的一个特殊目标文件是 /dev/null，它是空设备，可以直接丢掉所有写入它的数据。\n1 2 3 4 echo blog.mulinbiao.com \u0026gt;/dev/null curl -I blog.mulinbiao.com 2\u0026gt;/dev/null \u0026gt;/tmp/a.log cat \u0026lt;/etc/fstab 一个经常用的技巧是清空文件的方式：\n1 2 $ cat /dev/null \u0026gt;file $ \u0026gt;file 区分 cat \u0026lt;file 和 cat file cat 是一个命令，这个命令的源代码中写了一些代码用来处理选项和参数。\n1 cat -n /etc/fstab cat 命令开始执行后，会识别 -n 选项，该选项会让 cat 输出时同时输出行号，cat 同时还会识别 /etc/fstab 参数，cat 会读取参数指定的文件然后输出。\n如果没有指定 cat 的文件参数，则 cat 默认会从标准输入中读取数据。默认的标准输入是终端，所以在没有改变标准输入的流向时，会从终端读取数据， 也就是用户输入什么字符，就读取什么字符，然后输出什么字符：\n1 2 3 4 5 6 $ cat arturia # 在终端输入 arturia # 在终端输出 mu # 在终端输入 mu # 在终端输出 ^C 但用户可以改变标准输入的来源。比如：\n1 $ cat \u0026lt;/etc/fstab 表示将标准输入来源改为 /etc/fstab 文件，于是 cat 会从 /etc/fstab 中读取数据。\n另外，约定俗成的，会使用一个 - 来表示标准输入或标准输出。\n注：这并非是一贯正确的，只是约定俗成的大多数程序的代码中都定义了 - 相关的代码处理。可参考相关命令的 man 手册。如 man cat 中有一行：\n1 With no FILE, or when FILE is -, read standard input. here doc 输入重定向是 \u0026lt;，除此之外还有 \u0026lt;\u0026lt;、\u0026lt;\u0026lt;\u0026lt;。\n\u0026lt;\u0026lt; 符号表示 here doc。也就是说，它后面跟的是一篇文档，就像一个文件一样，只不过这个文件的内容是临时定义在 \u0026lt;\u0026lt; 符号后的。here doc 常用于指定多行数据输入。\n既然是文档，就有文档起始符号表示文档从此开始和文档终止符号表示文档到此结束。起始符和终止符中间的内容全部是文档内容。文档内容会作为标准输入的数据被读取。\n文档的起始符和终止符可以随意定义，但两者前后必须一样。常见的符号是：\nEOF：end of file EOL：end of line EOB：end of block 例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # here doc作为标准输入被读取，然后被cat输出 cat \u0026lt;\u0026lt;EOF hello world EOF # here doc的内容还会被cat覆盖式输出到指定文件 cat \u0026lt;\u0026lt;eof \u0026gt;/tmp/file hello world eof # here doc的内容还会被cat追加式输出到指定文件 cat \u0026lt;\u0026lt;eof \u0026gt;\u0026gt;/tmp/file hello world eof # here doc和重定向符号的前后位置随意 cat \u0026gt;\u0026gt;/tmp/file\u0026lt;\u0026lt;eof ... eof 另外，如果将起始符用引号包围，则不会进行变量替换、命令替换、算术替换等。如果不用引号包围起始符，则会进行替换。\n1 2 3 4 5 6 7 8 a=333 cat \u0026lt;\u0026lt;eof $a eof cat \u0026lt;\u0026lt;\u0026#34;eof\u0026#34; $a eof 输出结果：\n1 2 333 $a here string \u0026lt;\u0026lt;\u0026lt; 表示 here string。也就是说该符号后面是一个字符串，这个字符串会作为标准输入的内容。\n1 cat \u0026lt;\u0026lt;\u0026lt;\u0026#34;blog.mulinbiao.com\u0026#34; 使用单引号包围 here string 时，不会进行变量替换、命令替换等，使用双引号包围时会进行替换。\n1 2 3 4 5 6 7 $ a=3333 $ cat \u0026lt;\u0026lt;\u0026lt;$a 3333 $ cat \u0026lt;\u0026lt;\u0026lt;\u0026#34;hello world$a\u0026#34; hello world3333 $ cat \u0026lt;\u0026lt;\u0026lt;\u0026#39;hello world$a\u0026#39; hello world$a here string 常可以替代管道前的 echo 命令 echo xxx|。例如：\n1 2 3 # 下面是等价的 echo hello world | grep \u0026#34;llo\u0026#34; grep \u0026#34;llo\u0026#34; \u0026lt;\u0026lt;\u0026lt;\u0026#34;hello world\u0026#34; 管道 管道的用法：\n1 cmd1 | cmd2 | cmd3... 每个竖线代表一个管道。上面命令行表示 cmd1 的标准输出会放进管道，cmd2 会从管道中读取进行处理，cmd2 的标准输出会放入另一个管道，cmd3 会从这个管道中读取数据进行处理。后面还可以接任意数量的管道。\nShell 管道是 Shell 中最值得称赞的功能之一，它以非常简洁的形式实现了管道的进程间通信方式，我个人认为 Shell 处理文本数据的半壁江山都来自于竖线形式的管道。像其它编程语言，打开管道后还要区分哪个进程写管道、哪个进程读管道，为了安全，每个进程还要关闭不用的读端或写端，总之就是麻烦，而 Shell 的管道非常简洁，竖线左边的就是写管道的，竖线右边的就是读管道的。\n例如：\n1 ps aux | grep \u0026#39;sshd\u0026#39; ps 命令产生的数据 (标准输出) 会写进管道，只要管道内一有数据，grep 命令就从中读取数据进行处理。\n那下面的命令中，grep 从哪读数据呢？\n1 ps aux | grep \u0026#39;#\u0026#39; /etc/fstab 那想要让 grep 既从 /etc/fstab 读取数据，也从管道中读取数据呢？\n1 2 ps aux | grep \u0026#39;#\u0026#39; /etc/fstab /dev/stdin ps aux | grep \u0026#39;#\u0026#39; /etc/fstab - tee命令 tee 命令可将一份标准输入原样拷贝到标准输出和 0 或多个文件中。换句话说，tee 的作用是数据多重定向。\n1 2 3 4 5 6 7 8 9 10 11 NAME tee - read from standard input and write to standard output and files SYNOPSIS tee [OPTION]... [FILE]... DESCRIPTION Copy standard input to each FILE, and also to standard output. -a, --append ppend to the given FILEs, do not overwrite 如图：\n例如：\n1 2 $ echo hello world | tee /tmp/file1 /tmp/file2 | cat $ echo hello world | tee -a /tmp/file3 \u0026gt;/dev/null 进程替换 Bash 还支持进程替换 (注：有些 Shell 不支持进程替换)。\n进程替换的语法：\n1 2 \u0026lt;(cmd) \u0026gt;(cmd) 进程替换和命令替换类似，都是让 cmd 命令先执行，因为它们都是在 Shell 解析命令行的阶段执行的。\n进程替换先让 cmd 放入后台异步执行，并且不会等待 cmd 执行完。\n其实，每个进程替换都是一个虚拟文件，只不过这个文件的内容是由 cmd 命令产生的 (\u0026lt;(cmd)) 或被 cmd 命令读取的 (\u0026gt;(cmd))。\n1 2 $ echo \u0026lt;(echo blog.mulinbiao.com) /dev/fd/63 既然进程替换是文件，那么它就可以像文件一样被操作。比如被读取、被当作标准输入重定向的数据源等等：\n1 2 3 4 5 6 7 # cmd做数据产生者 $ cat \u0026lt;(echo blog.mulinbiao.com) # 等价于cat /dev/fd/63 $ cat \u0026lt; \u0026lt;(echo blog.mulinbiao.com) # 等价于cat \u0026lt;/dev/fd/63 # cmd做数据接收者 $ echo hello world \u0026gt; \u0026gt;(grep \u0026#39;llo\u0026#39;) $ echo hello world | tee \u0026gt;(grep \u0026#39;llo\u0026#39;) \u0026gt;(grep \u0026#39;rld\u0026#39;) \u0026gt;/dev/null 条件测试语句 test 命令或功能等价的 Bash 内置命令 [ ] 可以做条件测试，如果测试的结果为 True，则退出状态码为 0。\n此外，还可以使用 [[]] 来做条件测试，甚至 let、$[]、$(()) 也可以做条件测试，但这里暂不介绍。\n这些条件测试常用在 if、while 语句中，也常用在 cmd1 \u0026amp;\u0026amp; cmd2 || cmd3 格式的命令行中。\n用法示例：\n1 2 3 sh_file=test.sh [ -x \u0026#34;$sh_file\u0026#34; ] \u0026amp;\u0026amp; ./$sh_file || { echo \u0026#34;can\u0026#39;t execute,exit...\u0026#34;;exit 1; } test -x \u0026#34;$sh_file\u0026#34; \u0026amp;\u0026amp; ./$sh_file || { echo \u0026#34;can\u0026#39;t execute,exit...\u0026#34;;exit 1; } [] 中的条件测试表达式需要和开闭中括号使用空格隔开，否则语法解析错误。\n无测试内容 1 2 [ ] test 没有任何测试内容时，直接返回 false。\ntrue和false命令 true 命令直接返回 true，即退出状态码为 0。\nfalse 命令直接返回 false，即退出状态码非 0。\n1 2 3 4 $ true $ echo $? # 0 $ false $ echo $? # 1 文件类测试 条件表达式 含义 -e file 文件是否存在 (exist) -f file 文件是否存在且为普通文件 (file) -d file 文件是否存在且为目录 (directory) -b file 文件是否存在且为块设备 block device -c file 文件是否存在且为字符设备 character device -S file 文件是否存在且为套接字文件 Socket -p file 文件是否存在且为命名管道文件 FIFO (pipe) -L file 文件是否存在且是一个链接文件 (Link) 文件属性类测试 条件表达式 含义 -r file 文件是否存在且当前用户可读 -w file 文件是否存在且当前用户可写 -x file 文件是否存在且当前用户可执行 -s file 文件是否存在且大小大于 0 字节，即检测文件是否非空文件 -N file 文件是否存在，且自上次 read 后是否被 modify 两文件之间的比较 条件表达式 含义 file1 -nt file2 (newer than) 判断 file1 是否比 file2 新 file1 -ot file2 (older than) 判断 file1 是否比 file2 旧 file1 -ef file2 (equal file) 判断 file1 与 file2 是否为同一文件 数值大小比较 条件表达式 含义 int1 -eq int2 两数值相等 (equal) int1 -ne int2 两数值不相等 (not equal) int1 -gt int2 n1 大于 n2 (greater than) int1 -lt int2 n1 小于 n2 (less than) int1 -ge int2 n1 大于等于 n2 (greater than or equal) int1 -le int2 n1 小于等于 n2 (less than or equal) 字符串比较 条件表达式 含义 -z str (zero) 判定字符串是否为空？str 为空串，则 true str -n str 判定字符串是否非空？str 为串，则 false。注：-n 可省略 str1 = str2/str1 == str2 str1 和 str2 是否相同，相同则返回 true。”==” 和”=” 等价 str1 != str2 str1 是否不等于 str2，若不等，则返回 true str1 \u0026gt; str2 str1 字母顺序是否大于 str2，若大于则返回 true str1 \u0026lt; str2 str1 字母顺序是否小于 str2，若小于则返回 true 逻辑运算符 条件表达式 含义 -a 或 \u0026amp;\u0026amp; (and) 两表达式同时为 true 时才为 true。“-a” 只能在 test 或 [] 中使用，\u0026amp;\u0026amp; 只能在 [[]] 中使用 -o 或 || (or) 两表达式任何一个 true 则为 true。“-o” 只能在 test 或 [] 中使用，||只能在 [[]] 中使用 ! 对表达式取反 () 改变表达式的优先级，为了防止被 shell 解析，应加上反斜线转义 ( ) if语句 1 2 3 4 5 6 if test-commands; then consequent-commands; [elif more-test-commands; then more-consequents;] [else alternate-consequents;] fi test-commands 既可以是 test 测试或 []、[[]] 测试，也可以是任何其它命令，test-commands 用于条件测试，它只判断命令的退出状态码是否为 0，为 0 则为 true。\n例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 if [ \u0026#34;$a\u0026#34; ];then echo \u0026#39;$a\u0026#39; is not none;else echo \u0026#39;$a\u0026#39; undefined or empty;fi if [ ! -d ~/.ssh ];then mkdir ~/.ssh chown -R $USER.$USER ~/.ssh chmod 700 ~/.ssh fi if grep \u0026#39;arturiamu\u0026#39; /etc/passwd \u0026amp;\u0026gt;/dev/null;then echo \u0026#39;User \u0026#34;arturiamu\u0026#34; already exists...\u0026#39; elif grep \u0026#39;mulinbiao\u0026#39; /etc/passwd \u0026amp;\u0026gt;/dev/null;then echo \u0026#39;User \u0026#34;mulinbiao\u0026#34; already exists...\u0026#39; else echo \u0026#39;you should create user,exit...\u0026#39; exit 1 fi case语句 case 常用于确定的分支判断。比如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 while [ ${#@} -gt 0 ];do case \u0026#34;$1\u0026#34; in start) echo start;; stop) echo stop ;; restart) echo restart ;; reload | force-reload) echo reload;; status) echo status;; *) echo $\u0026#34;Usage: $0 {start|stop|status|restart|reload|force-reload}\u0026#34; exit 2 esac done case 用法基本要求：\n除最后一个分支外，每个分支都以 ;; 结尾，否则出现分支穿透 (所以 ;; 不是必须的) 分支条件可以使用通配符号 分支条件中可使用竖线隔开多个条件，表示只要匹配其中之一就执行该分支 最后一般会定义一个能匹配其它任意条件的默认分支，即 *) 下面是为 ping 命令自定义设计选项的脚本：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #!/bin/bash while [ $1 ];do case \u0026#34;$1\u0026#34; in -c|--count) count=$2 shift 2 ;; -t|--timeout) timeout=$2 shift 2 ;; -h|--host) host=$2 shift 2 ;; *) echo \u0026#34;wrong options or arguments\u0026#34; exit 1 esac done ping -c $count -W timeout $host 执行：\n1 2 $ chmod +x ping.sh $ ./ping.sh -c 5 -t 2 -h blog.mulinbiao.com for循环 有两种 for 循环结构：\n1 2 3 4 5 # 成员测试类语法 for i in word1 word2 ...;do cmd_list;done # C语言for语法 for (( expr1;expr2;expr3 ));do cmd_list;done 成员测试类的 for 循环中，in 关键字后是使用空格分隔的一个或多个元素，for 循环时，每次从 in 关键字后面取一个元素并赋值给 i 变量。\n例如：\n1 2 3 4 5 6 7 8 9 $ for i in 1 2 3 4;do echo $i;done 1 2 3 4 $ for i in 1 2 \u0026#34;3 4\u0026#34;;do echo $i;done 1 2 3 4 C 语言型的 for 语法中，expr1 是初始化语句，expr2 是循环终点条件判断语句，expr3 是每轮循环后执行的语句，一般用来更改条件判断相关的变量。\n1 2 3 4 for ((i=1;i\u0026lt;=3;++i));do echo $i;done 1 2 3 while循环 1 while test_cmd_list;do cmd_list;done while 循环，开始时会测试 test_cmd_list，如果测试的退出状态码为 0，则执行一次循环体语句 cmd_list，然后再测试 test_cmd_list，一直循环，直到测试退出状态码非 0，循环退出。\n例如：\n1 2 3 4 5 let i=1,sum=0; while [ $i -le 10 ];do let sum=sum+i let ++i done 还有 until 循环语句，但在 Shell 中用的很少。\nwhile 循环经常会和 read 命令一起使用，read 是 Bash 的内置命令，可用来读取文件，通常会按行读取：每次读一行。\n例如：\n1 2 3 4 cat /etc/fstab | while read line;do let num+=1 echo $num: $line done 上面的命令行中，首先 cat 进程和 while 结构开始运行，while 结构中的 read 命令从标准输入中读取，也就是从管道中读取数据，每次读取一行，因为管道中最初没有数据，所以 read 命令被阻塞处于数据等待状态。当 cat 命令读完文件所有数据后，将数据放入到管道中，于是 read 命令从管道中每次读取一行并将所读行赋值给变量 line，然后执行循环体，然后继续循环，直到 read 读完所有数据，循环退出。\n但注意，管道两边的命令默认是在子 Shell 中执行的，所以其设置的变量在命令执行完成后就消失。换句话说，在父 Shell 中无法访问这些变量。比如上面的 num 变量是在管道的 while 结构中设置的，除了在 while 中能访问该变量，其它任何地方都无法访问它。\n如果想要访问 while 中赋值的变量，就不能使用管道。如果是直接从文件读取，可使用输入重定向，如果是读取命令产生的数据，可使用进程替换。\n1 2 3 4 5 6 7 8 9 10 while read line;do let num1+=1 echo $num1: $line done \u0026lt;/etc/fstab echo $num1 while read line;do let num2+=1 echo $num2: $line done \u0026lt; \u0026lt;(grep \u0026#39;UUID\u0026#39; /etc/fstab) shell函数 Shell 函数可以当作命令一样执行，它是一个或多个命令的组合结构体。通常，可以为每个功能定义一个函数，该函数中包含实现这个功能相关的所有命令和逻辑。\n因为可以组合多个命令，并且定义之后就可以直接在当前 Shell 中调用，所以函数具有一次定义多次调用且代码复用的功能。\nShell 函数的定义风格有下面几种：\n1 2 3 function func_name {CMD_LIST} func_name() {CMD_LIST} function func_name() {CMD_LIST} 函数定义后，可以直接使用函数名来调用函数，同时还可以向函数传递零个或多个参数。\n1 2 3 4 # 不传递参数 func_name # 传递多个参数 func_name arg1 arg2 arg3 在函数中，那些位置变量将有特殊的意义：\n$1、$2、$3\u0026hellip;：传递给函数的第一个参数保存在 $1 中，第二个参数保存在 $2 中… $@和 $*：保存了所有参数，各参数使用空格分隔 不用双引号包围时，两者没区别 双引号包围时，$@的各个元素都被双引号包围，$* 的所有元素一次性被双引号包围 例如，定义一个函数专门用来设置和代理相关的变量：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 proxy_addr=127.0.0.1:8118 function proxy_set { local p_addr=$1 export http_proxy=$p_addr export https_proxy=$p_addr export ftp_proxy=$p_addr } # 调用函数 proxy_set $proxy_addr # 各代理变量已设置 echo $http_proxy echo $https_proxy echo $ftp_proxy 上面在函数定义的代码中使用了 local，它可以用在函数内部表示定义一个局部变量，局部变量在函数执行完毕后就消失，不会影响函数外部的环境。\n另外，函数中可以使用 return 语句来定义函数的返回值，每当执行到函数内的 return 时，函数就会终止执行，直接退出函数。在 Shell 中，函数的返回值其实就是退出状态码。\n1 return [N] 如果不指定 N，则默认退出状态码为 0。\n例如：\n1 2 3 4 5 6 7 8 function sayhello { [ \u0026#34;$1\u0026#34; ] || { echo \u0026#34;give me a name please!\u0026#34;; return 1; } echo hello $1 } sayhello \u0026#34;arturia\u0026#34; ; echo $? sayhello \u0026#34;mu\u0026#34; ; echo $? sayhello ; echo $? ","date":"2023-09-27T14:10:12+08:00","permalink":"http://localhost:1313/post/shell-basic-knowledge/","title":"shell脚本基础入门"},{"content":"遍历修改 这是初学者最容易犯的问题，当我们试图修改切片中的数据时，直接使用for range遍历数据并修改\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main import \u0026#34;fmt\u0026#34; type Test struct { ID int Name string } func TestForLoop() { var tests = []Test{ {ID: 0, Name: \u0026#34;0\u0026#34;}, {ID: 1, Name: \u0026#34;0\u0026#34;}, {ID: 2, Name: \u0026#34;0\u0026#34;}, } for i, test := range tests { test.Name = fmt.Sprintf(\u0026#34;%d\u0026#34;, i) } for _, test := range tests { fmt.Println(test) } } 以上代码输出结果为：\n1 2 3 {0 0} {1 0} {2 0} 原因 for i, test := range tests语句中的test是一个新定义的变量，对他的修改并不会影响到切片中原变量的值\n解决方案 使用for i遍历切片：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main import \u0026#34;fmt\u0026#34; type Test struct { ID int Name string } func TestForLoop() { var tests = []Test{ {ID: 0, Name: \u0026#34;0\u0026#34;}, {ID: 1, Name: \u0026#34;0\u0026#34;}, {ID: 2, Name: \u0026#34;0\u0026#34;}, } for i := 0; i \u0026lt; len(tests); i++ { tests[i].Name = fmt.Sprintf(\u0026#34;%d\u0026#34;, i) } for _, test := range tests { fmt.Println(test) } } 地址问题 先看代码，该代码定义了一个src切片和一个dist切片，遍历src切片并将遍历到的值地址添加到dist切片内，遍历dist切片并输出\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main import \u0026#34;fmt\u0026#34; func TestForLoop() { src := []int{1, 2, 3, 4} var dist []*int for _, v := range src { dist = append(dist, \u0026amp;v) } for _, v := range dist { fmt.Println(*v) } } 输出\n1 2 3 4 5 /Users/mulinbiao/Library/Caches/JetBrains/IntelliJIdea2023.1/tmp/GoLand/___go_build_code 4 4 4 4 原因 在golang的for循环中，循环内部创建的函数变量都是共享同一块内存地址，for循环总是使用同一块内存去接收循环中的的value变量的值。不管循环多少次，value的内存地址都是相同的。\n解决方法 定义临时变量tmp，将v的值赋给tmp，问题就解决了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main import \u0026#34;fmt\u0026#34; func TestForLoop() { src := []int{1, 2, 3, 4} var dist []*int for _, v := range src { tmp:=v dist = append(dist, \u0026amp;tmp) } for _, v := range dist { fmt.Println(*v) } } 变量快照 先看代码，该代码期望使用协程输出ints切片的值，但实际情况并不是。这个例子里，3个goroutine共享同一个变量i，最后输出的结果大概率是输出3 3 3。\n要解决这个问题，主要有2个解决方案。\n1 2 3 4 5 6 7 8 9 10 11 12 package main import \u0026#34;fmt\u0026#34; func TestForLoop() { ints := []int{1, 2, 3} for _, i := range ints { go func() { fmt.Printf(\u0026#34;%v\\n\u0026#34;, i) }() } } 方案一 把循环变量i作为goroutine函数的一个参数，编译器在执行go func(i int)时，就会解析到i的值，确保每个goroutine可以拿到自己想要的值。\n1 2 3 4 5 6 7 8 9 10 11 12 package main import \u0026#34;fmt\u0026#34; func TestForLoop() { ints := []int{1, 2, 3} for _, i := range ints { go func(i int) { fmt.Printf(\u0026#34;%v\\n\u0026#34;, i) }(i) } } 方案二 创建一个新的变量，用于goroutine。\n1 2 3 4 5 6 7 8 9 10 11 12 13 package main import \u0026#34;fmt\u0026#34; func TestForLoop() { ints := []int{1, 2, 3} for _, i := range ints { i := i go func() { fmt.Printf(\u0026#34;%v\\n\u0026#34;, i) }() } } ","date":"2023-09-26T19:45:10+08:00","permalink":"http://localhost:1313/post/go-for-loop/","title":"golang for循环的坑"},{"content":"修改字体 这里使用了Shimoko的鸿蒙字体CDN\n在博客根目录/layouts/partials/head/custom.html文件内写入如下内容\n没有该文件夹的话直接将主题目录下的layouts文件夹复制过来即可（为了方便后期维护，不建议直接在主题目录下修改）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;style\u0026gt; :root { /* 在style中优先调用HarmonyOS_Sans_SC_Medium */ --sys-font-family: \u0026#34;HarmonyOS_Sans_SC_Medium\u0026#34;, Georgia, -apple-system, \u0026#39;Nimbus Roman No9 L\u0026#39;, \u0026#39;PingFang SC\u0026#39;, \u0026#39;Hiragino Sans GB\u0026#39;, \u0026#39;Noto Serif SC\u0026#39;, \u0026#39;Microsoft Yahei\u0026#39;, \u0026#39;WenQuanYi Micro Hei\u0026#39;, \u0026#39;ST Heiti\u0026#39;, sans-serif; --code-font-family: \u0026#34;JetBrainsMono Regular\u0026#34;, Menlo, Monaco, Consolas, \u0026#34;Courier New\u0026#34;; --article-font-family: \u0026#34;HarmonyOS_Sans_SC_Medium\u0026#34;, var(--base-font-family); } \u0026lt;/style\u0026gt; \u0026lt;script\u0026gt; (function () { const customFont = document.createElement(\u0026#39;link\u0026#39;); customFont.href = \u0026#34;https://img.shimoko.com/fonts/font.css\u0026#34;; customFont.type = \u0026#34;text/css\u0026#34;; customFont.rel = \u0026#34;stylesheet\u0026#34;; document.head.appendChild(customFont); }()); \u0026lt;/script\u0026gt; 效果对比\n双排友链 在博客根目录/assets/scss下创建custom.scss文件，写入如下内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 //友情链接双栏 @media (min-width: 1024px) { .article-list--compact.links { display: grid; grid-template-columns: 1fr 1fr; background: none; box-shadow: none; article { background: var(--card-background); border: none; box-shadow: var(--shadow-l2); margin-bottom: 8px; border-radius: 10px; \u0026amp;:nth-child(odd) { margin-right: 8px; } } } } 效果对比\n添加站点统计信息与i18n 期望展示格式：\n中文：\n本博客已稳定运行 x 天 y 小时 z 分钟 共发表 x 篇文章 · 总计 y k 字 本站总访问量x次 英文：\nThis blog has been running stably for x day, y hours and z minutes Published x articles in total · totaling y k words The total number of visits to this site is x times 其中访问量使用不蒜子实现\n在根目录/layouts/partials/footer/footer.html文件内添加如下代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 \u0026lt;section class=\u0026#34;count_info\u0026#34;\u0026gt; \u0026lt;div\u0026gt; {{ T \u0026#34;footer.runtime1\u0026#34; }} \u0026lt;span id=\u0026#34;ds\u0026#34; class=\u0026#34;running-days\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; {{ T \u0026#34;footer.runtime2\u0026#34; }} \u0026lt;span id=\u0026#34;hs\u0026#34; class=\u0026#34;running-days\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; {{ T \u0026#34;footer.runtime3\u0026#34; }} \u0026lt;span id=\u0026#34;ms\u0026#34; class=\u0026#34;running-days\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; {{ T \u0026#34;footer.runtime4\u0026#34; }} \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; {{$scratch := newScratch}} {{ range (where .Site.Pages \u0026#34;Kind\u0026#34; \u0026#34;page\u0026#34; )}} {{$scratch.Add \u0026#34;total\u0026#34; .WordCount}} {{ end }} {{ T \u0026#34;footer.count1\u0026#34; }} {{ len (where .Site.RegularPages \u0026#34;Section\u0026#34; \u0026#34;post\u0026#34;) }} {{ T \u0026#34;footer.count2\u0026#34; }} {{ div ($scratch.Get \u0026#34;total\u0026#34;) 1000.0 | lang.FormatNumber 2 }} k {{ T \u0026#34;footer.count3\u0026#34; }} \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;span id=\u0026#34;busuanzi_container_site_pv\u0026#34;\u0026gt;{{ T \u0026#34;footer.pv1\u0026#34; }}\u0026lt;span id=\u0026#34;busuanzi_value_site_pv\u0026#34;\u0026gt;\u0026lt;/span\u0026gt;{{ T \u0026#34;footer.pv2\u0026#34; }}\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;!-- Add blog running time --\u0026gt; \u0026lt;script\u0026gt; let s1 = \u0026#39;2023-6-18\u0026#39;; //website start date s1 = new Date(s1.replace(/-/g, \u0026#34;/\u0026#34;)); let s2 = new Date(); let timeDifference = s2.getTime() - s1.getTime(); let days = Math.floor(timeDifference / (1000 * 60 * 60 * 24)); let hours = Math.floor((timeDifference % (1000 * 60 * 60 * 24)) / (1000 * 60 * 60)); let minutes = Math.floor((timeDifference % (1000 * 60 * 60)) / (1000 * 60)); document.getElementById(\u0026#39;ds\u0026#39;).innerHTML = days; document.getElementById(\u0026#39;hs\u0026#39;).innerHTML = hours; document.getElementById(\u0026#39;ms\u0026#39;).innerHTML = minutes; \u0026lt;/script\u0026gt; 在主题目录/i18n下找到对应语言的文件，在属性footer下添加相应字段,结果如下\nzh-cn.yaml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 footer: # 本博客已稳定运行1天2小时3分钟 runtime1: other: 本博客已稳定运行 runtime2: other: 天 runtime3: other: 小时 runtime4: other: 分钟 # 共发表x篇文章，总计y k字 count1: other: 共发表 count2: other: 篇文章 · 总计 count3: other: 字 # 本站总访问量X次 pv1: other: 本站总访问量 pv2: other: 次 en.yaml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 footer: # This blog has been running stably for 1 day, 2 hours and 3 minutes runtime1: other: This blog has been running stably for runtime2: other: day, runtime3: other: hours and runtime4: other: minutes # Published x articles in total, totaling y words count1: other: Published count2: other: articles in total · totaling count3: other: words # The total number of visits to this site is X times pv1: other: The total number of visits to this site is pv2: other: times 其他语言同理\n效果展示\n添加访客地图 使用clustrmaps实现\n在根目录/layouts/partials/sidebar/right.html内添加script即可，添加后完整代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 {{- $scope := default \u0026#34;homepage\u0026#34; .Scope -}} {{- $context := .Context -}} {{- with (index .Context.Site.Params.widgets $scope) -}} \u0026lt;aside class=\u0026#34;sidebar right-sidebar sticky\u0026#34;\u0026gt; {{ range $widget := . }} {{ if templates.Exists (printf \u0026#34;partials/widget/%s.html\u0026#34; .type) }} {{ partial (printf \u0026#34;widget/%s\u0026#34; .type) (dict \u0026#34;Context\u0026#34; $context \u0026#34;Params\u0026#34; .params) }} {{ else }} {{ warnf \u0026#34;Widget %s not found\u0026#34; .type }} {{ end }} {{ end }} \u0026lt;div style=\u0026#34;height: 30%;width: 30%\u0026#34;\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; id=\u0026#34;clstr_globe\u0026#34; src=\u0026#34;//clustrmaps.com/globe.js?d=xxxxx\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/aside\u0026gt; {{ end }} 效果展示\n","date":"2023-09-19T15:51:30+08:00","permalink":"http://localhost:1313/post/stack-beautify/","title":"hugo stack 主题美化"},{"content":"本文转载自 深入MySQL复制(二)\n相比传统的MySQL复制，gtid复制无论是配置还是维护都要轻松的多。本文对gtid复制稍作介绍。\nMySQL基于GTID复制官方手册：https://dev.mysql.com/doc/refman/5.7/en/replication-gtids.html\ngtid基本概念 传统的基于binlog position复制的方式有个严重的缺点：如果slave连接master时指定的binlog文件错误或者position错误，会造成遗漏或者重复，很多时候前后数据是有依赖性的，这样就会出错而导致数据不一致。\n从MYSQL5.6开始，mysql开始支持GTID复制。GTID的全称是global transaction id，表示的是全局事务ID。GTID的分配方式为uuid:trans_id，其中：\nuuid是每个mysql服务器都唯一的，记录在$datadir/auto.cnf中。如果复制结构中，任意两台服务器uuid重复的话(比如直接冷备份时，auto.conf中的内容是一致的)，在启动复制功能的时候会报错。这时可以删除auto.conf文件再重启mysqld。 1 2 3 4 5 6 7 8 9 10 11 mysql\u0026gt; show variables like \u0026#34;%uuid%\u0026#34;; +---------------+--------------------------------------+ | Variable_name | Value | +---------------+--------------------------------------+ | server_uuid | a126fcb6-3706-11e8-b1d5-000c294ebf0d | +---------------+--------------------------------------+ 1 row in set (0.00 sec) mysql\u0026gt; \\! cat /data/auto.cnf [auto] server-uuid=a126fcb6-3706-11e8-b1d5-000c294ebf0d trans_id是事务ID，可以唯一标记某MySQL服务器上执行的某个事务。事务号从1开始，每提交一个事务，事务号加1。 例如\u0026quot;gtid_executed 5ad9cb8e-2092-11e7-ac95-000c29bf823d:1-6\u0026quot;，表示该server_uuid上执行了从1到6的事务。\ngtid的生命周期 gtid的生命周期对于配置和维护基于gtid的复制至关重要。 所以，请尽可能理解以下几个过程。\ngtid在master和slave上是一直持久化保存(即使删除了日志，也会记录到Previous_GTID中)的。它在master和slave上的生命周期如下：\n1、客户端发送DDL/DML给master上，master首先对此事务生成一个唯一的gtid，假如为uuid_xxx:1，然后立即执行该事务中的操作。\n注意，主从复制的情况下，sync-binlog基本上都会设置为1，这表示在每次提交事务时将缓存中的binlog刷盘。所以，在事务提交前，gtid以及事务相关操作的信息都在缓存中，提交后它们才写入到binlog file中，然后才会被dump线程dump出去。\n换句话说，只有提交了的事务，gtid和对应的事务操作才会记录到binlog文件中。记录的格式是先记录gtid，紧跟着再记录事务相关的操作。\n2、当binlog传送到relay log中后，slave上的SQL线程首先读取该gtid，并设置变量 gtid_next 的值为该gtid，表示下一个要操作的事务是该gtid。 gtid_next 是基于会话的，不同会话的gtid_next不同。\n3、随后slave检测该gtid在自己的binlog中是否存在。如果存在，则放弃此gtid事务；如果不存在，则将此gtid写入到自己的binlog中，然后立刻执行该事务，并在自己的binlog中记录该事务相关的操作。\n注意，slave上replay的时候，gtid不是提交后才写到自己的binlog file的，而是判断gtid不存在后立即写入binlog file。\n通过这种在执行事务前先检查并写gtid到binlog的机制，不仅可以保证当前会话在此之前没有执行过该事务，还能保证没有其他会话读取了该gtid却没有提交。因为如果其他会话读取了该gtid会立即写入到binlog(不管是否已经开始执行事务)，所以当前会话总能读取到binlog中的该gtid，于是当前会话就会放弃该事务。总之，一个gtid事务是决不允许多次执行、多个会话并行执行的。\n4、slave在重放relay log中的事务时，不会自己生成gtid，所以所有的slave(无论是何种方式的一主一从或一主多从复制架构)通过重放relay log中事务获取的gtid都来源于master，并永久保存在slave上。\n基于gtid复制的好处 从上面可以看出，gtid复制的优点大致有：\n保证同一个事务在某slave上绝对只执行一次，没有执行过的gtid事务总是会被执行。 不用像传统复制那样保证binlog的坐标准确，因为根本不需要binlog以及坐标。 故障转移到新的master的时候很方便，简化了很多任务。 很容易判断master和slave的数据是否一致。只要master上提交的事务在slave上也提交了，那么一定是一致的。 当然，MySQL提供了选项可以控制跳过某些gtid事务，防止slave第一次启动复制时执行master上的所有事务而导致耗时过久。\n虽然对于row-based和statement-based的格式都能进行gtid复制，但建议采用row-based格式。\n配置一主一从的gtid复制 环境：\n主机IP OS版本 MySQL版本 角色（master/slave) 数据状态 192.168.100.21 centos 7 MySQL 5.7.22 master_gtid 全新实例 192.168.100.22 centos 7 MySQL 5.7.22 slave1_gtid 全新实例 因为是用作master和slave的mysql实例都是全新环境，所以这里简单配置一下即可。\nmaster的配置文件：\n1 2 3 4 5 6 7 8 9 10 11 12 [mysqld] datadir=/data socket=/data/mysql.sock log-bin=/data/master-bin # 必须项 sync-binlog=1 # 建议项 binlog_format=row # 建议项 server-id=100 # 必须项 log-error=/data/error.log pid-file=/data/mysqld.pid enforce_gtid_consistency=on # gtid复制需要加上的必须项 gtid_mode=on # gtid复制需要加上的必须项 关于后面的两项，是gtid复制所必须开启的项，这里指定它开启就行了，它们的意义以及更多gtid相关的选项见后文解释。\nslave的配置文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 [mysqld] datadir=/data socket=/data/mysql.sock log-bin=/data/master-slave-bin # mysql 5.6必须项，mysql 5.7非必须项 sync-binlog=1 # 建议项 binlog_format=row # 建议项 relay-log=/data/slave-bin # 必须项 server-id=110 # 必须项 log-error=/data/error.log pid-file=/data/mysqld.pid enforce_gtid_consistency=on # 必须项 gtid_mode=on # 必须项 我的环境是mysql 5.7，如果是mysql 5.6，那么在上面两个配置文件中需要加上log-slave-updates选项。\n重启master和slave后，在master上创建一个用于复制的用户repl。\n1 2 # master上执行 mysql\u0026gt; grant replication slave on *.* to repl@\u0026#39;192.168.100.%\u0026#39; identified by \u0026#39;P@ssword1!\u0026#39;; 因为master上的binlog没有删除过，所以在slave上直接change master to配置连接参数。\n1 2 3 4 5 # slave上执行 mysql\u0026gt; change master to master_host=\u0026#39;192.168.100.21\u0026#39;, master_port=3306, master_auto_position=1; # gtid复制必须设置此项 因为是MySQL 5.7，没有在change master to语句中加入user和password项，而是在start slave语句中使用，否则会警告。\n现在启动slave上的两个复制线程。\n1 2 # slave上执行 mysql\u0026gt; start slave user=\u0026#39;repl\u0026#39; password=\u0026#39;P@ssword1!\u0026#39;; 查看io线程和sql线程是否正常。\n1 2 3 4 5 6 7 8 9 # slave上执行，为了排版，缩减了一些无关紧要的字段 mysql\u0026gt; show processlist; +----+-------------+---------+--------------------------------------------------------+ | Id | User | Command | State | +----+-------------+---------+--------------------------------------------------------+ | 9 | root | Query | starting | | 10 | system user | Connect | Waiting for master to send event | | 11 | system user | Connect | Slave has read all relay log; waiting for more updates | +----+-------------+---------+--------------------------------------------------------+ 最后验证gtid复制是否生效。\n在master上插入一些数据。这里使用上一篇文章中使用的存储过程proc_num1和proc_num2分别向数值辅助表backup.num_isam和backup.num_innodb中插入一些数据，该存储过程的代码见：https://www.cnblogs.com/f-ck-need-u/p/9155003.html#blognum。\n1 2 3 4 5 # 向MyISAM数值辅助表backup.num_isam插入100W行数据 call proc_num1(1000000); # 向InnoDB数值辅助表backup.num_innodb插入100W行数据 call proc_num2(1000000); 在slave上查看slave的状态，以下是同步结束后的状态信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 # slave上执行： mysql\u0026gt; show slave status\\G *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.100.21 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-bin.000004 Read_Master_Log_Pos: 10057867 Relay_Log_File: slave-bin.000003 Relay_Log_Pos: 457 Relay_Master_Log_File: master-bin.000004 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: Replicate_Ignore_DB: Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 10057867 Relay_Log_Space: 10058586 Until_Condition: None Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: 0 Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 100 Master_UUID: a659234f-6aea-11e8-a361-000c29ed4cf4 Master_Info_File: /data/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: a659234f-6aea-11e8-a361-000c29ed4cf4:1-54 Executed_Gtid_Set: a659234f-6aea-11e8-a361-000c29ed4cf4:1-54 Auto_Position: 1 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 添加新的slave到gtid复制结构中 GTID复制是基于事务ID的，确切地说是binlog中的GTID，所以事务ID对GTID复制来说是命脉。\n当master没有删除过任何binlog时，可以随意地向复制结构中添加新的slave，因为slave会复制所有的binlog到自己relay log中并replay。这样的操作尽管可能速度不佳，但胜在操作极其简便。\n当master删除过一部分binlog后，在向复制结构中添加新的slave时，必须先获取到master binlog中当前已记录的第一个gtid之前的所有数据，然后恢复到slave上。只有slave上具有了这部分基准数据，才能保证和master的数据一致性。\n而在实际环境中，往往会定期删除一部分binlog。所以，为了配置更通用的gtid复制环境，这里把前文的master的binlog给purge掉一部分。\n目前master上的binlog使用情况如下，不难发现绝大多数操作都集中在master-bin.000004这个binlog中。\n1 2 3 4 5 6 [root@xuexi ~]# ls -l /data/*bin* -rw-r----- 1 mysql mysql 177 Jun 8 15:07 /data/master-bin.000001 -rw-r----- 1 mysql mysql 727 Jun 8 15:42 /data/master-bin.000002 -rw-r----- 1 mysql mysql 177 Jun 9 09:50 /data/master-bin.000003 -rw-r----- 1 mysql mysql 10057867 Jun 9 10:17 /data/master-bin.000004 -rw-r----- 1 mysql mysql 96 Jun 9 09:50 /data/master-bin.index purge已有的binlog。\n1 2 mysql\u0026gt; flush logs; mysql\u0026gt; purge master logs to \u0026#39;master-bin.000005\u0026#39;; 1 2 [root@xuexi ~]# cat /data/master-bin.index /data/master-bin.000005 但无论master是否purge过binlog，配置基于gtid的复制都极其方便，而且方法众多(只要理解了GTID的生命周期，可以随意折腾，基本上都能很轻松地维护好)，这是它\u0026quot;迷人\u0026quot;的优点。\n现在的测试环境是这样的：\n主机IP OS版本 MySQL版本 角色（master/slave) 数据状态 192.168.100.21 centos 7 MySQL 5.7.22 master_gtid 已purge过binlog 192.168.100.22 centos 7 MySQL 5.7.22 slave1_gtid 已同步 192.168.100.23 centos 7 MySQL 5.7.22 slave2_gtid 全新实例 其中slave2的配置文件和slave1的配置文件完全相同：\n1 2 3 4 5 6 7 8 9 10 11 12 13 [mysqld] datadir=/data socket=/data/mysql.sock log-bin=/data/master-slave-bin # 必须项 sync-binlog=1 # 建议项 binlog_format=row # 建议项 relay-log=/data/slave-bin # 必须项 server-id=110 # 必须项 log-error=/data/error.log pid-file=/data/mysqld.pid enforce_gtid_consistency=on # 必须项 gtid_mode=on # 必须项 1、备份master。\n我选择的是xtrabackup的innobackupex工具，因为它速度快，操作简单，而且在线备份也比较安全。如果不知道xtrabackup备份的使用方法，见另一篇文章：xtrabackup用法和原理详述。当然，你也可以采用mysqldump和冷备份的方式，因为gtid复制的特性，这些备份方式也都很安全。\n1 2 3 4 5 # master上执行，备份所有数据： [root@xuexi ~]# mkdir /backdir # 备份目录 [root@xuexi ~]# innobackupex -uroot -pP@ssword1! -S /data/mysql.sock /backdir/ # 准备数据 [root@xuexi ~]# innobackupex --apply-log /backdir/2018-06-09_20-02-24/ # 应用数据 [root@xuexi ~]# scp -pr /backdir/2018-06-09_20-02-24/ 192.168.100.23:/tmp 2.将备份恢复到slave2。\n在slave2上执行：\n1 2 3 4 5 [root@xuexi ~]# systemctl stop mysqld [root@xuexi ~]# rm -rf /data/* # 恢复前必须先清空数据目录 [root@xuexi ~]# innobackupex --copy-back /tmp/2018-06-09_20-02-24/ # 恢复备份数据 [root@xuexi ~]# chown -R mysql.mysql /data [root@xuexi ~]# systemctl start mysqld 3、设置gtid_purged，连接master，开启复制功能。\n由于xtrabackup备份数据集却不备份binlog，所以必须先获取此次备份结束时的最后一个事务ID，并在slave上明确指定跳过这些事务，否则slave会再次从master上复制这些binlog并执行，导致数据重复执行。\n可以从slave2数据目录中的xtrabackup_info文件中获取。如果不是xtrabackup备份的，那么可以直接从master的show global variables like \u0026quot;gtid_executed\u0026quot;;中获取，它表示master中已执行过的事务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [root@xuexi ~]# cat /data/xtrabackup_info uuid = fc3de8c1-6bdc-11e8-832d-000c29ed4cf4 name = tool_name = innobackupex tool_command = -uroot -pP@ssword1! -S /data/mysql.sock /backdir/ tool_version = 2.4.11 ibbackup_version = 2.4.11 server_version = 5.7.22-log start_time = 2018-06-09 20:02:28 end_time = 2018-06-09 20:02:30 lock_time = 0 binlog_pos = filename \u0026#39;master-bin.000005\u0026#39;, position \u0026#39;194\u0026#39;, GTID of the last change \u0026#39;a659234f-6aea-11e8-a361-000c29ed4cf4:1-54\u0026#39; innodb_from_lsn = 0 innodb_to_lsn = 51235233 partial = N incremental = N format = file compact = N compressed = N encrypted = N 其中binlog_pos中的GTID对应的就是已备份的数据对应的事务。换句话说，这里的gtid集合1-54表示这54个事务不需要进行复制。\n或者在master上直接查看executed的值，注意不是gtid_purged的值，master上的gtid_purged表示的是曾经删除掉的binlog。\n1 2 3 4 5 6 7 8 9 10 11 12 13 mysql\u0026gt; show global variables like \u0026#39;%gtid%\u0026#39;; +----------------------------------+-------------------------------------------+ | Variable_name | Value | +----------------------------------+-------------------------------------------+ | binlog_gtid_simple_recovery | ON | | enforce_gtid_consistency | ON | | gtid_executed | a659234f-6aea-11e8-a361-000c29ed4cf4:1-54 | | gtid_executed_compression_period | 1000 | | gtid_mode | ON | | gtid_owned | | | gtid_purged | a659234f-6aea-11e8-a361-000c29ed4cf4:1-54 | | session_track_gtids | OFF | +----------------------------------+-------------------------------------------+ 可以在启动slave线程 之前使用gtid_purged变量来指定需要跳过的gtid集合。但因为要设置gtid_purged必须保证全局变量gtid_executed为空，所以先在slave上执行reset master(注意，不是reset slave)，再设置gtid_purged。\n1 2 3 # slave2上执行： mysql\u0026gt; reset master; mysql\u0026gt; set @@global.gtid_purged=\u0026#39;a659234f-6aea-11e8-a361-000c29ed4cf4:1-54\u0026#39;; 设置好gtid_purged之后，就可以开启复制线程了。\n1 2 3 4 5 mysql\u0026gt; change master to master_host=\u0026#39;192.168.100.21\u0026#39;, master_port=3306, master_auto_position=1; mysql\u0026gt; start slave user=\u0026#39;repl\u0026#39; password=\u0026#39;P@ssword1!\u0026#39;; 查看slave的状态，看是否正确启动了复制功能。如果没错，再在master上修改一部分数据，检查是否同步到slave1和slave2。\n4、回到master，purge掉已同步的binlog。\n当slave指定gtid_purged并实现了同步之后，为了下次重启mysqld实例不用再次设置gtid_purged(甚至可能会在启动的时候自动开启复制线程)，所以应该去master上将已经同步的binlog给purged掉。\n1 2 3 4 5 # master上执行： mysql\u0026gt; flush logs; # flush之后滚动到新的日志master-bin.000006 # 在确保所有slave都复制完000006之前的所有事务后，purge掉旧日志 mysql\u0026gt; purge master logs to \u0026#34;master-bin.000006\u0026#34;; GTID复制相关的状态信息和变量 show slave status中和gtid复制相关的状态行 1 2 3 Retrieved_Gtid_Set: a659234f-6aea-11e8-a361-000c29ed4cf4:1-54 Executed_Gtid_Set: a659234f-6aea-11e8-a361-000c29ed4cf4:1-54 Auto_Position: 1 其中：\nRetrieved_Gtid_Set：在开启了gtid复制(即gtid_mode=on)时，slave在启动io线程的时候会检查自己的relay log，并从中检索出gtid集合。也就是说，这代表的是slave已经从master中复制了哪些事务过来。检索出来的gtid不会再请求master发送过来。 Executed_Gtid_Set：在开启了gtid复制(即gtid_mode=on)时，它表示已经向自己的binlog中写入了哪些gtid集合。注意，这个值是根据一些状态信息计算出来的，并非binlog中能看到的那些。举个特殊一点的例子，可能slave的binlog还是空的，但这里已经显示一些已执行gtid集合了。 Auto_Position：开启gtid时是否自动获取binlog坐标。1表示开启，这是gtid复制的默认值。 binlog中关于gtid的信息 例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 [root@xuexi ~]# mysqlbinlog /data/master-bin.000007 /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/; /*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/; DELIMITER /*!*/; # at 4 #180610 1:34:08 server id 100 end_log_pos 123 CRC32 0x4a6e9510 Start: binlog v 4, server v 5.7.22-log created 180610 1:34:08 # Warning: this binlog is either in use or was not closed properly. BINLOG \u0026#39; kA8cWw9kAAAAdwAAAHsAAAABAAQANS43LjIyLWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAEzgNAAgAEgAEBAQEEgAAXwAEGggAAAAICAgCAAAACgoKKioAEjQA ARCVbko= \u0026#39;/*!*/; # at 123 #180610 1:34:08 server id 100 end_log_pos 194 CRC32 0x0f6ba409 Previous-GTIDs # a659234f-6aea-11e8-a361-000c29ed4cf4:1-57 #### 注意行1 # at 194 #180610 2:06:31 server id 100 end_log_pos 259 CRC32 0xfef9194e GTID last_committed=0 sequence_number=1 rbr_only=no #### 注意行2 SET @@SESSION.GTID_NEXT= \u0026#39;a659234f-6aea-11e8-a361-000c29ed4cf4:58\u0026#39;/*!*/; #### 注意行3 # at 259 #180610 2:06:31 server id 100 end_log_pos 359 CRC32 0x5a561d94 Query thread_id=2 exec_time=0 error_code=0 use `backup`/*!*/; SET TIMESTAMP=1528567591/*!*/; SET @@session.pseudo_thread_id=2/*!*/; SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/; SET @@session.sql_mode=1436549152/*!*/; SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/; /*!\\C utf8 *//*!*/; SET @@session.character_set_client=33,@@session.collation_connection=33,@@session.collation_server=8/*!*/; SET @@session.lc_time_names=0/*!*/; SET @@session.collation_database=DEFAULT/*!*/; create table t1(n int) /*!*/; # at 359 #180610 2:09:36 server id 100 end_log_pos 424 CRC32 0x82564e69 GTID last_committed=1 sequence_number=2 rbr_only=no #### 注意行4 SET @@SESSION.GTID_NEXT= \u0026#39;a659234f-6aea-11e8-a361-000c29ed4cf4:59\u0026#39;/*!*/; #### 注意行5 # at 424 #180610 2:09:36 server id 100 end_log_pos 524 CRC32 0xbc21683a Query thread_id=2 exec_time=0 error_code=0 SET TIMESTAMP=1528567776/*!*/; create table t2(n int) /*!*/; SET @@SESSION.GTID_NEXT= \u0026#39;AUTOMATIC\u0026#39; /* added by mysqlbinlog */ /*!*/; #### 注意行6 DELIMITER ; # End of log file /*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/; /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 其中：\n\u0026ldquo;注意行1\u0026quot;中Previous-GTIDs代表的gtid集合是曾经的gtid，换句话说是被purge掉的事务。 \u0026ldquo;注意行2\u0026quot;和\u0026quot;注意行4\u0026quot;是两个事务的gtid信息。它们写在每个事务的前面。 \u0026ldquo;注意行3\u0026quot;和\u0026quot;注意行5\u0026quot;设置了GTID_NEXT的值，表示读取到了该事务后，那么必须要执行的是稍后列出的这个事务。 \u0026ldquo;注意行6\u0026quot;是在所有事务执行结束时设置的，表示自动获取gtid的值。它对复制是隐身的(也就是说不会dump线程不会将它dump出去)，该行的结尾也说了，这一行是mysqlbinlog添加的。 一些重要的变量 gtid_mode：是否开启gtid复制模式。只允许on/off类的布尔值，不允许其他类型(如1/0)的布尔值，实际上这个变量是枚举类型的。要设置 gtid_mode=on ，必须同时设置 enforce_gtid_consistency 开。在MySQL 5.6中，还必须开启 log_slave_updates ，即使是master也要开启。 enforce_gtid_consistency：强制要求只允许复制事务安全的事务。 gtid_mode=on 时必须显式设置该项，如果不给定值，则默认为on。应该尽量将该选项放在 gtid_mode 的前面，减少启动mysqld时的检查。 不能在事务内部创建和删除临时表。只能在事务外部进行，且autocommit需要设置为1。 不能执行 create table \u0026hellip; select 语句。该语句除了创建一张新表并填充一些数据，其他什么事也没干。 不能在事务内既更新事务表又更新非事务表。 gtid_executed：已经执行过的GTID。 reset master 会清空该项的全局变量值。 gtid_purged：已经purge掉的gtid。要设置该项，必须先保证 gtid_executed 已经为空，这意味着也一定会同时设置该项为空。在slave上设置该项时，表示稍后启动io线程和SQL线程都跳过这些gtid，slave上设置时应该让此项的gtid集合等于master上 gtid_executed 的值。 gtid_next：表示下一个要执行的gtid事务。 需要注意，master和slave上都有gtid_executed和gtid_purged，它们代表的意义有时候是不同的。\n还有一些变量，可能用到的不会多。如有需要，可翻官方手册。\nmysql.gtid_executed表 MySQL 5.7中添加了一张记录已执行gtid的表mysql.gtid_executed，所以slave上的binlog不是必须开启的。\n1 2 3 4 5 6 7 8 mysql\u0026gt; select * from mysql.gtid_executed; +--------------------------------------+----------------+--------------+ | source_uuid | interval_start | interval_end | +--------------------------------------+----------------+--------------+ | a659234f-6aea-11e8-a361-000c29ed4cf4 | 1 | 57 | | a659234f-6aea-11e8-a361-000c29ed4cf4 | 58 | 58 | | a659234f-6aea-11e8-a361-000c29ed4cf4 | 59 | 59 | +--------------------------------------+----------------+--------------+ 一张图说明GTID复制 在前面第6节中，使用了xtrabackup备份的方式提供gtid复制的基准数据。其中涉及到一些gtid检查、设置的操作。通过这些操作，大概可以感受的到gtid复制的几个概念。\n用一张图来说明：\n假如当前master的gtid为A3，已经purge掉的gtid为\u0026quot;1\u0026ndash;\u0026gt;A1\u0026rdquo;，备份到slave上的数据为1-A2部分。\n如果A1 = 0，表示master的binlog没有被Purge过。slave可以直接开启gtid复制，但这样可能速度较慢，因为slave要复制所有binlog。也可以将master数据备份到slave上，然后设置 gtid_purged 跳过备份结束时的gtid，这样速度较快。\n如果A1 != 0，表示master上的binlog中删除了一部分gtid。此时slave上必须先从master处恢复purge掉的那部分日志对应的数据。上图中备份结束时的GTID为A2。然后slave开启复制，唯一需要考虑的是\u0026quot;是否需要设置 gtid_purged 跳过一部分gtid以避免重复执行\u0026rdquo;。\n备份数据到slave上，方式可以是mysqldump、冷备份、xtrabackup备份都行。由于gtid复制的特性，所需要的操作都很少，也很简单，前提是理解了\u0026quot;gtid的生命周期\u0026rdquo;。\n","date":"2023-09-19T11:35:24+08:00","permalink":"http://localhost:1313/post/mysql-replication-2/","title":"深入MySQL复制(二)：基于GTID复制 "},{"content":"本文转载自 深入MySQL复制(一)\n本文非常详细地介绍MySQL复制相关的内容，包括基本概念、复制原理、如何配置不同类型的复制(传统复制)等等\n本文是MySQL Replication的基础，但却非常重要。对于MySQL复制，如何搭建它不是重点(因为简单，网上资源非常多)，如何维护它才是重点(网上资源不集中)。 以下几个知识点是掌握MySQL复制所必备的：\n复制的原理\n将master上已存在的数据恢复到slave上作为基准数据\n获取正确的binlog坐标\n深入理解show slave status中的一些状态信息\n本文对以上内容都做了非常详细的说明。希望对各位初学、深入MySQL复制有所帮助。\nmysql replication官方手册：https://dev.mysql.com/doc/refman/5.7/en/replication.html。\n复制的基本概念和原理 mysql复制是指从一个mysql服务器(MASTER)将数据通过日志的方式经过网络传送到另一台或多台mysql服务器(SLAVE)，然后在slave上重放(replay或redo)传送过来的日志，以达到和master数据同步的目的。\n它的工作原理很简单。首先确保master数据库上开启了二进制日志，这是复制的前提。\n在slave准备开始复制时，首先要执行change master to语句设置连接到master服务器的连接参数, 在执行该语句的时候要提供一些信息，包括如何连接和要从哪复制binlog，这些信息在连接的时候会记录到slave的datadir下的master.info文件中，以后再连接master的时候将不用再提供这新信息而是直接读取该文件进行连接。 在slave上有两种线程，分别是IO线程和SQL线程。 IO线程用于连接master，监控和接受master的binlog。当启动IO线程成功连接master时，master会同时启动一个dump线程，该线程将slave请求要复制的binlog给dump出来，之后IO线程负责监控并接收master上dump出来的二进制日志，当master上binlog有变化的时候，IO线程就将其复制过来并写入到自己的中继日志(relay log)文件中。 slave上的另一个线程SQL线程用于监控、读取并重放relay log中的日志，将数据写入到自己的数据库中。如下图所示。 站在slave的角度上看，过程如下：\n站在master的角度上看，过程如下(默认的异步复制模式，前提是设置了sync_binlog=1，否则binlog刷盘时间由操作系统决定)：\n所以，可以认为复制大致有三个步骤：\n数据修改写入master数据库的binlog中。 slave的IO线程复制这些变动的binlog到自己的relay log中。 slave的SQL线程读取并重新应用relay log到自己的数据库上，让其和master数据库保持一致。 从复制的机制上可以知道，在复制进行前，slave上必须具有master上部分完整内容作为复制基准数据。例如，master上有数据库A，二进制日志已经写到了pos1位置，那么在复制进行前，slave上必须要有数据库A，且如果要从pos1位置开始复制的话，还必须有和master上pos1之前完全一致的数据。如果不满足这样的一致性条件，那么在replay中继日志的时候将不知道如何进行应用而导致数据混乱。也就是说，复制是基于binlog的position进行的，复制之前必须保证position一致。(注：这是传统的复制方式所要求的)\n可以选择对哪些数据库甚至数据库中的哪些表进行复制。默认情况下，MySQL的复制是异步的。slave可以不用一直连着master，即使中间断开了也能从断开的position处继续进行复制。\nMySQL 5.6对比MySQL 5.5在复制上进行了很大的改进，主要包括支持GTID(Global Transaction ID,全局事务ID)复制和多SQL线程并行重放。GTID的复制方式和传统的复制方式不一样，通过全局事务ID，它不要求复制前slave有基准数据，也不要求binlog的position一致。\nMySQL 5.7.17则提出了组复制(MySQL Group Replication,MGR)的概念。像数据库这样的产品，必须要尽可能完美地设计一致性问题，特别是在集群、分布式环境下。Galera就是一个MySQL集群产品，它支持多主模型(多个master)，但是当MySQL 5.7.17引入了MGR功能后，Galera的优势不再明显，甚至MGR可以取而代之。MGR为MySQL集群中多主复制的很多问题提供了很好的方案，可谓是一项革命性的功能。\n复制和二进制日志息息相关，所以学习本章必须先有二进制日志的相关知识。\n复制的好处 围绕下面的拓扑图来分析：\n主要有以下几点好处：\n1.提供了读写分离的能力。\nreplication让所有的slave都和master保持数据一致，因此外界客户端可以从各个slave中读取数据，而写数据则从master上操作。也就是实现了读写分离。\n需要注意的是，为了保证数据一致性，写操作必须在master上进行。\n通常说到读写分离这个词，立刻就能意识到它会分散压力、提高性能。\n2.为MySQL服务器提供了良好的伸缩(scale-out)能力。\n由于各个slave服务器上只提供数据检索而没有写操作，因此\u0026quot;随意地\u0026quot;增加slave服务器数量来提升整个MySQL群的性能，而不会对当前业务产生任何影响。\n之所以\u0026quot;随意地\u0026quot;要加上双引号，是因为每个slave都要和master建立连接，传输数据。如果slave数量巨多，master的压力就会增大，网络带宽的压力也会增大。\n3.数据库备份时，对业务影响降到最低。\n由于MySQL服务器群中所有数据都是一致的(至少几乎是一致的)，所以在需要备份数据库的时候可以任意停止某一台slave的复制功能(甚至停止整个mysql服务)，然后从这台主机上进行备份，这样几乎不会影响整个业务(除非只有一台slave，但既然只有一台slave，说明业务压力并不大，短期内将这个压力分配给master也不会有什么影响)。\n4.能提升数据的安全性。\n这是显然的，任意一台mysql服务器断开，都不会丢失数据。即使是master宕机，也只是丢失了那部分还没有传送的数据(异步复制时才会丢失这部分数据)。\n5.数据分析不再影响业务。\n需要进行数据分析的时候，直接划分一台或多台slave出来专门用于数据分析。这样OLTP和OLAP可以共存，且几乎不会影响业务处理性能。\n复制分类和它们的特性 MySQL支持两种不同的复制方法：传统的复制方式和GTID复制。MySQL 5.7.17之后还支持组复制(MGR)。\n传统的复制方法要求复制之前，slave上必须有基准数据，且binlog的position一致。 GTID复制方法不要求基准数据和binlog的position一致性。GTID复制时，master上只要一提交，就会立即应用到slave上。这极大地简化了复制的复杂性，且更好地保证master上和各slave上的数据一致性。 从数据同步方式的角度考虑，MySQL支持4种不同的同步方式：同步(synchronous)、半同步(semisynchronous)、异步(asynchronous)、延迟(delayed)。所以对于复制来说，就分为同步复制、半同步复制、异步复制和延迟复制。\n同步复制 客户端发送DDL/DML语句给master，master执行完毕后还需要等待所有的slave都写完了relay log才认为此次DDL/DML成功，然后才会返回成功信息给客户端。 同步复制的问题是master必须等待，所以延迟较大，在MySQL中不使用这种复制方式。\n例如上图中描述的，只有3个slave全都写完relay log并返回ACK给master后，master才会判断此次DDL/DML成功。\n半同步复制 客户端发送DDL/DML语句给master，master执行完毕后还要等待一个slave写完relay log并返回确认信息给master，master才认为此次DDL/DML语句是成功的，然后才会发送成功信息给客户端。 半同步复制只需等待一个slave的回应，且等待的超时时间可以设置，超时后会自动降级为异步复制，所以在局域网内(网络延迟很小)使用半同步复制是可行的。\n例如上图中，只有第一个slave返回成功，master就判断此次DDL/DML成功，其他的slave无论复制进行到哪一个阶段都无关紧要。\n异步复制 客户端发送DDL/DML语句给master，master执行完毕立即返回成功信息给客户端，而不管slave是否已经开始复制。 这样的复制方式导致的问题是，当master写完了binlog，而slave还没有开始复制或者复制还没完成时，slave上和master上的数据暂时不一致，且此时master突然宕机，slave将会丢失一部分数据。如果此时把slave提升为新的master，那么整个数据库就永久丢失这部分数据。\n延迟复制 顾名思义，延迟复制就是故意让slave延迟一段时间再从master上进行复制。\n配置一主一从 此处先配置默认的异步复制模式。由于复制和binlog息息相关，如果对binlog还不熟悉，请先了解binlog。\nmysql支持一主一从和一主多从。但是每个slave必须只能是一个master的从，否则从多个master接受二进制日志后重放将会导致数据混乱的问题。\n以下是一主一从的结构图：\n在开始传统的复制(非GTID复制)前，需要完成以下几个关键点，这几个关键点指导后续复制的所有步骤。\n为master和slave设定不同的server-id，这是主从复制结构中非常关键的标识号。到了MySQL 5.7，似乎不设置server id就无法开启binlog。设置server id需要重启MySQL实例。 开启master的binlog。刚安装并初始化的MySQL默认未开启binlog，建议手动设置binlog且为其设定文件名，否则默认以主机名为基名时修改主机名后会找不到日志文件。 最好设置master上的变量sync_binlog=1(MySQL 5.7.7之后默认为1，之前的版本默认为0)，这样每写一次二进制日志都将其刷新到磁盘，让slave服务器可以尽快地复制。防止万一master的二进制日志还在缓存中就宕机时，slave无法复制这部分丢失的数据。 最好设置master上的redo log的刷盘变量innodb_flush_log_at_trx_commit=1(默认值为1)，这样每次提交事务都会立即将事务刷盘保证持久性和一致性。 在slave上开启中继日志relay log。这个是默认开启的，同样建议手动设置其文件名。 建议在master上专门创建一个用于复制的用户，它只需要有复制权限replication slave用来读取binlog。 确保slave上的数据和master上的数据在\u0026quot;复制的起始position之前\u0026quot;是完全一致的。如果master和slave上数据不一致，复制会失败。 记下master开始复制前binlog的position，因为在slave连接master时需要指定从master的哪个position开始复制。 考虑是否将slave设置为只读，也就是开启read_only选项。这种情况下，除了具有super权限(mysql 5.7.16还提供了super_read_only禁止super的写操作)和SQL线程能写数据库，其他用户都不能进行写操作。这种禁写对于slave来说，绝大多数场景都非常适合。 一主一从 一主一从是最简单的主从复制结构。本节实验环境如下：\n1、配置master和slave的配置文件。\n1 2 3 4 5 6 [mysqld] # master datadir=/data socket=/data/mysql.sock log-bin=master-bin sync-binlog=1 server-id=100 1 2 3 4 5 [mysqld] # slave datadir=/data socket=/data/mysql.sock relay-log=slave-bin server-id=111 2、重启master和slave上的MySQL实例。\n1 service mysqld restart 3、在master上创建复制专用的用户。\n1 2 create user \u0026#39;repl\u0026#39;@\u0026#39;192.168.100.%\u0026#39; identified by \u0026#39;P@ssword1!\u0026#39;; grant REPLICATION SLAVE on *.* to \u0026#39;repl\u0026#39;@\u0026#39;192.168.100.%\u0026#39;; 4、将slave恢复到master上指定的坐标。\n这是备份恢复的内容，此处用一个小节来简述操作过程。\n将slave恢复到master指定的坐标 对于复制而言，有几种情况：\n待复制的master没有新增数据，例如新安装的mysql实例。这种情况下，可以跳过恢复这个过程。 待复制的master上已有数据。这时需要将这些已有数据也应用到slave上，并获取master上binlog当前的坐标。只有slave和master的数据能匹配上，slave重放relay log时才不会出错。 第一种情况此处不赘述。第二种情况有几种方法，例如使用mysqldump、冷备份、xtrabackup等工具，这其中又需要考虑是MyISAM表还是InnoDB表。\n在实验开始之前，首先在master上新增一些测试数据，以innodb和myisam的数值辅助表为例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 DROP DATABASE IF EXISTS backuptest; CREATE DATABASE backuptest; USE backuptest; # 创建myisam类型的数值辅助表和插入数据的存储过程 CREATE TABLE num_isam (n INT NOT NULL PRIMARY KEY) ENGINE = MYISAM ; DROP PROCEDURE IF EXISTS proc_num1; DELIMITER $$ CREATE PROCEDURE proc_num1 (num INT) BEGIN DECLARE rn INT DEFAULT 1 ; TRUNCATE TABLE backuptest.num_isam ; INSERT INTO backuptest.num_isam VALUES(1) ; dd: WHILE rn * 2 \u0026lt; num DO BEGIN INSERT INTO backuptest.num_isam SELECT rn + n FROM backuptest.num_isam; SET rn = rn * 2 ; END ; END WHILE dd; INSERT INTO backuptest.num_isam SELECT n + rn FROM backuptest.num_isam WHERE n + rn \u0026lt;= num; END ; $$ DELIMITER ; # 创建innodb类型的数值辅助表和插入数据的存储过程 CREATE TABLE num_innodb (n INT NOT NULL PRIMARY KEY) ENGINE = INNODB ; DROP PROCEDURE IF EXISTS proc_num2; DELIMITER $$ CREATE PROCEDURE proc_num2 (num INT) BEGIN DECLARE rn INT DEFAULT 1 ; TRUNCATE TABLE backuptest.num_innodb ; INSERT INTO backuptest.num_innodb VALUES(1) ; dd: WHILE rn * 2 \u0026lt; num DO BEGIN INSERT INTO backuptest.num_innodb SELECT rn + n FROM backuptest.num_innodb; SET rn = rn * 2 ; END ; END WHILE dd; INSERT INTO backuptest.num_innodb SELECT n + rn FROM backuptest.num_innodb WHERE n + rn \u0026lt;= num ; END ; $$ DELIMITER ; # 分别向两个数值辅助表中插入100W条数据 CALL proc_num1 (1000000) ; CALL proc_num2 (1000000) ; 所谓数值辅助表是只有一列的表，且这个字段的值全是数值，从1开始增长。例如上面的是从1到100W的数值辅助表。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 mysql\u0026gt; select * from backuptest.num_isam limit 10; +----+ | n | +----+ | 1 | | 2 | | 3 | | 4 | | 5 | | 6 | | 7 | | 8 | | 9 | | 10 | +----+ 获取master binlog的坐标 如果master是全新的数据库实例，或者在此之前没有开启过binlog，那么它的坐标位置是position=4。 之所以是4而非0，是因为binlog的前4个记录单元是每个binlog文件的头部信息。\n如果master已有数据，或者说master以前就开启了binlog并写过数据库，那么需要手动获取position。为了安全以及没有后续写操作，必须先锁表。\n1 mysql\u0026gt; flush tables with read lock; 注意，这次的锁表会导致写阻塞以及innodb的commit操作。\n然后查看binlog的坐标。\n1 2 3 4 5 6 mysql\u0026gt; show master status; # 为了排版，简化了输出结果 +-------------------+----------+--------------+--------+--------+ | File | Position | Binlog_Do_DB | ...... | ...... | +-------------------+----------+--------------+--------+--------+ | master-bin.000001 | 623 | | | | +-------------------+----------+--------------+--------+--------+ 记住master-bin.000001和623。\n备份master数据到slave上 下面给出3种备份方式以及对应slave的恢复方法。建议备份所有库到slave上，如果要筛选一部分数据库或表进行复制，应该在slave上筛选(筛选方式见后文筛选要复制的库和表)，而不应该在master的备份过程中指定。\n方式一：冷备份直接cp。这种情况只适用于没有新写入操作。严谨一点，只适合拷贝完成前master不能有写入操作。 如果要复制所有库，那么直接拷贝整个datadir。 如果要复制的是某个或某几个库，直接拷贝相关目录即可。但注意，这种冷备份的方式只适合MyISAM表和开启了innodb_file_per_table=ON的InnoDB表。如果没有开启该变量，innodb表使用公共表空间，无法直接冷备份。 如果要冷备份innodb表，最安全的方法是先关闭master上的mysql，而不是通过表锁。 所以，如果没有涉及到innodb表，那么在锁表之后，可以直接冷拷贝。最后释放锁。\n1 2 3 4 5 6 7 mysql\u0026gt; flush tables with read lock; mysql\u0026gt; show master status; # 为了排版，简化了输出结果 +-------------------+----------+--------------+--------+--------+ | File | Position | Binlog_Do_DB | ...... | ...... | +-------------------+----------+--------------+--------+--------+ | master-bin.000001 | 623 | | | | +-------------------+----------+--------------+--------+--------+ 1 2 shell\u0026gt; rsync -avz /data 192.168.100.150:/ mysql\u0026gt; unlock tables; 此处实验，假设要备份的是整个实例，因为涉及到了innodb表，所以建议关闭MySQL。 因为是冷备份，所以slave上也应该关闭MySQL。\n1 2 # master和slave上都执行 shell\u0026gt; mysqladmin -uroot -p shutdown 然后将整个datadir拷贝到slave上(当然，有些文件是不用拷贝的，比如master上的binlog、mysql库等)。\n1 2 # 将master的datadir(/data)拷贝到slave的datadir(/data) shell\u0026gt; rsync -avz /data 192.168.100.150:/ 需要注意，在冷备份的时候，需要将备份到目标主机上的DATADIR/auto.conf删除，这个文件中记录的是mysql server的UUID，而master和slave的UUID必须不能一致。\n然后重启master和slave。因为重启了master，所以binlog已经滚动了，不过这次不用再查看binlog坐标，因为重启造成的binlog日志移动不会影响slave。\n方式二：使用mysqldump进行备份恢复。 这种方式简单的多，而且对于innodb表很适用，但是slave上恢复时速度慢，因为恢复时数据全是通过insert插入的。因为mysqldump可以进行定时点恢复甚至记住binlog的坐标，所以无需再手动获取binlog的坐标。\n1 shell\u0026gt; mysqldump -uroot -p --all-databases --master-data=2 \u0026gt;dump.db 注意，--master-data选项将再dump.db中加入change master to相关的语句，值为2时，change master to语句是注释掉的，值为1或者没有提供值时，这些语句是直接激活的。同时，--master-data会锁定所有表(如果同时使用了--single-transaction，则不是锁所有表，详细内容请参见mysqldump)。\n因此，可以直接从dump.db中获取到binlog的坐标。记住这个坐标。\n1 2 [root@xuexi ~]# grep -i -m 1 \u0026#39;change master to\u0026#39; dump.db -- CHANGE MASTER TO MASTER_LOG_FILE=\u0026#39;master-bin.000002\u0026#39;, MASTER_LOG_POS=154; 然后将dump.db拷贝到slave上，使用mysql执行dump.db脚本即可。也可以直接在master上远程连接到slave上执行。例如：\n1 shell\u0026gt; mysql -uroot -p -h 192.168.100.150 -e \u0026#39;source dump.db\u0026#39; 方式三：使用xtrabackup进行备份恢复。 这是三种方式中最佳的方式，安全性高、速度快。因为xtrabackup备份的时候会记录master的binlog的坐标，因此也无需手动获取binlog坐标。\nxtrabackup详细的备份方法见：xtrabackup\n注意：master和slave上都安装percona-xtrabackup。\n以全备份为例：\n1 innobackupex -u root -p /backup 备份完成后，在/backup下生成一个以时间为名称的目录。其内文件如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 [root@xuexi ~]# ll /backup/2018-05-29_04-12-15 total 77872 -rw-r----- 1 root root 489 May 29 04:12 backup-my.cnf drwxr-x--- 2 root root 4096 May 29 04:12 backuptest -rw-r----- 1 root root 1560 May 29 04:12 ib_buffer_pool -rw-r----- 1 root root 79691776 May 29 04:12 ibdata1 drwxr-x--- 2 root root 4096 May 29 04:12 mysql drwxr-x--- 2 root root 4096 May 29 04:12 performance_schema drwxr-x--- 2 root root 12288 May 29 04:12 sys -rw-r----- 1 root root 22 May 29 04:12 xtrabackup_binlog_info -rw-r----- 1 root root 115 May 29 04:12 xtrabackup_checkpoints -rw-r----- 1 root root 461 May 29 04:12 xtrabackup_info -rw-r----- 1 root root 2560 May 29 04:12 xtrabackup_logfile 其中xtrabackup_binlog_info中记录了binlog的坐标。记住这个坐标。\n1 2 [root@xuexi ~]# cat /backup/2018-05-29_04-12-15/xtrabackup_binlog_info master-bin.000002 154 然后将备份的数据执行\u0026quot;准备\u0026quot;阶段。这个阶段不要求连接mysql，因此不用给连接选项。\n1 innobackupex --apply-log /backup/2018-05-29_04-12-15 最后，将/backup目录拷贝到slave上进行恢复。恢复的阶段就是向MySQL的datadir拷贝。但注意，xtrabackup恢复阶段要求datadir必须为空目录。否则报错：\n1 2 3 4 5 6 7 8 9 [root@xuexi ~]# innobackupex --copy-back /backup/2018-05-29_04-12-15/ 180529 23:54:27 innobackupex: Starting the copy-back operation IMPORTANT: Please check that the copy-back run completes successfully. At the end of a successful copy-back run innobackupex prints \u0026#34;completed OK!\u0026#34;. innobackupex version 2.4.11 based on MySQL server 5.7.19 Linux (x86_64) (revision id: b4e0db5) Original data directory /data is not empty! 所以，停止slave的mysql并清空datadir。\n1 2 service mysqld stop rm -rf /data/* 恢复时使用的模式是\u0026quot;\u0026ndash;copy-back\u0026quot;，选项后指定要恢复的源备份目录。恢复时因为不需要连接数据库，所以不用指定连接选项。\n1 2 [root@xuexi ~]# innobackupex --copy-back /backup/2018-05-29_04-12-15/ 180529 23:55:53 completed OK! 恢复完成后，MySQL的datadir的文件的所有者和属组是innobackupex的调用者，所以需要改回mysql.mysql。\n1 shell\u0026gt; chown -R mysql.mysql /data 启动slave，并查看恢复是否成功。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 shell\u0026gt; service mysqld start shell\u0026gt; mysql -uroot -p -e \u0026#39;select * from backuptest.num_isam limit 10;\u0026#39; +----+ | n | +----+ | 1 | | 2 | | 3 | | 4 | | 5 | | 6 | | 7 | | 8 | | 9 | | 10 | +----+ slave开启复制 经过前面的一番折腾，总算是把该准备的数据都准备到slave上，也获取到master上binlog的坐标(154)。现在还欠东风：连接master。\n连接master时，需要使用change master to提供连接到master的连接选项，包括user、port、password、binlog、position等。\n1 2 3 4 5 6 7 mysql\u0026gt; change master to master_host=\u0026#39;192.168.100.20\u0026#39;, master_port=3306, master_user=\u0026#39;repl\u0026#39;, master_password=\u0026#39;P@ssword1!\u0026#39;, master_log_file=\u0026#39;master-bin.000002\u0026#39;, master_log_pos=154; 完整的change master to语法如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 CHANGE MASTER TO option [, option] ... option: | MASTER_HOST = \u0026#39;host_name\u0026#39; | MASTER_USER = \u0026#39;user_name\u0026#39; | MASTER_PASSWORD = \u0026#39;password\u0026#39; | MASTER_PORT = port_num | MASTER_LOG_FILE = \u0026#39;master_log_name\u0026#39; | MASTER_LOG_POS = master_log_pos | MASTER_AUTO_POSITION = {0|1} | RELAY_LOG_FILE = \u0026#39;relay_log_name\u0026#39; | RELAY_LOG_POS = relay_log_pos | MASTER_SSL = {0|1} | MASTER_SSL_CA = \u0026#39;ca_file_name\u0026#39; | MASTER_SSL_CAPATH = \u0026#39;ca_directory_name\u0026#39; | MASTER_SSL_CERT = \u0026#39;cert_file_name\u0026#39; | MASTER_SSL_CRL = \u0026#39;crl_file_name\u0026#39; | MASTER_SSL_CRLPATH = \u0026#39;crl_directory_name\u0026#39; | MASTER_SSL_KEY = \u0026#39;key_file_name\u0026#39; | MASTER_SSL_CIPHER = \u0026#39;cipher_list\u0026#39; | MASTER_SSL_VERIFY_SERVER_CERT = {0|1} 然后，启动IO线程和SQL线程。可以一次性启动两个，也可以分开启动。\n1 2 3 4 5 6 7 # 一次性启动、关闭 start slave; stop slave; # 单独启动 start slave io_thread; start slave sql_thread; 至此，复制就已经可以开始工作了。当master写入数据，slave就会从master处进行复制。\n例如，在master上新建一个表，然后去slave上查看是否有该表。因为是DDL语句，它会写二进制日志，所以它也会复制到slave上。\n查看slave的信息 change master to后，在slave的datadir下就会生成master.info文件和relay-log.info文件，这两个文件随着复制的进行，其内数据会随之更新。\nmaster.info master.info文件记录的是IO线程相关的信息， 也就是连接master以及读取master binlog的信息。通过这个文件，下次连接master时就不需要再提供连接选项。\n以下是master.info的内容，每一行的意义见官方手册\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 [root@xuexi ~]# cat /data/master.info 25 # 本文件的行数 master-bin.000002 # IO线程正从哪个master binlog读取日志 154 # IO线程读取到master binlog的位置 192.168.100.20 # master_host repl # master_user P@ssword1! # master_password 3306 # master_port 60 # master_retry，slave重连master的超时时间(单位秒) 0 0 30.000 0 86400 0 relay-log.info relay-log.info文件中记录的是SQL线程相关的信息。 以下是relay-log.info文件的内容，每一行的意义见官方手册\n1 2 3 4 5 6 7 8 9 [root@xuexi ~]# cat /data/relay-log.info 7 # 本文件的行数 ./slave-bin.000001 # 当前SQL线程正在读取的relay-log文件 4 # SQL线程已执行到的relay log位置 master-bin.000002 # SQL线程最近执行的操作对应的是哪个master binlog 154 # SQL线程最近执行的操作对应的是master binlog的哪个位置 0 # slave上必须落后于master多长时间 0 # 正在运行的SQL线程数 1 # 一种用于内部信息交流的ID，目前值总是1 show slave status 在slave上执行show slave status可以查看slave的状态信息。信息非常多，每个字段的详细意义可参见官方手册\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 mysql\u0026gt; show slave status\\G *************************** 1. row *************************** Slave_IO_State: # slave上IO线程的状态，来源于show processlist Master_Host: 192.168.100.20 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-bin.000002 Read_Master_Log_Pos: 154 Relay_Log_File: slave-bin.000001 Relay_Log_Pos: 4 Relay_Master_Log_File: master-bin.000002 Slave_IO_Running: No # IO线程的状态，此处为未运行且未连接状态 Slave_SQL_Running: No # SQL线程的状态，此处为未运行状态 Replicate_Do_DB: # 显式指定要复制的数据库 Replicate_Ignore_DB: # 显式指定要忽略的数据库 Replicate_Do_Table: Replicate_Ignore_Table: Replicate_Wild_Do_Table: # 以通配符方式指定要复制的表 Replicate_Wild_Ignore_Table: Last_Errno: 0 Last_Error: Skip_Counter: 0 Exec_Master_Log_Pos: 154 Relay_Log_Space: 154 Until_Condition: None # start slave语句中指定的until条件， # 例如，读取到哪个binlog位置就停止 Until_Log_File: Until_Log_Pos: 0 Master_SSL_Allowed: No Master_SSL_CA_File: Master_SSL_CA_Path: Master_SSL_Cert: Master_SSL_Cipher: Master_SSL_Key: Seconds_Behind_Master: NULL # SQL线程执行过的位置比IO线程慢多少 Master_SSL_Verify_Server_Cert: No Last_IO_Errno: 0 Last_IO_Error: Last_SQL_Errno: 0 Last_SQL_Error: Replicate_Ignore_Server_Ids: Master_Server_Id: 0 # master的server id Master_UUID: Master_Info_File: /data/master.info SQL_Delay: 0 SQL_Remaining_Delay: NULL Slave_SQL_Running_State: # slave SQL线程的状态 Master_Retry_Count: 86400 Master_Bind: Last_IO_Error_Timestamp: Last_SQL_Error_Timestamp: Master_SSL_Crl: Master_SSL_Crlpath: Retrieved_Gtid_Set: Executed_Gtid_Set: Auto_Position: 0 Replicate_Rewrite_DB: Channel_Name: Master_TLS_Version: 1 row in set (0.01 sec) 因为太长，后面再列出show slave status时，将裁剪一些意义不大的行。\n再次回到上面show slave status的信息。除了那些描述IO线程、SQL线程状态的行，还有几个log_file和pos相关的行，如下所列。\n1 2 3 4 5 6 Master_Log_File: master-bin.000002 Read_Master_Log_Pos: 154 Relay_Log_File: slave-bin.000001 Relay_Log_Pos: 4 Relay_Master_Log_File: master-bin.000002 Exec_Master_Log_Pos: 154 理解这几行的意义至关重要，前面因为排版限制，描述看上去有些重复。所以这里完整地描述它们：\nMaster_Log_File：IO线程正在读取的master binlog； Read_Master_Log_Pos：IO线程已经读取到master binlog的哪个位置； Relay_Log_File：SQL线程正在读取和执行的relay log； Relay_Log_Pos：SQL线程已经读取和执行到relay log的哪个位置； Relay_Master_Log_File：SQL线程最近执行的操作对应的是哪个master binlog； Exec_Master_Log_Pos：SQL线程最近执行的操作对应的是master binlog的哪个位置。 所以，(Relay_Master_Log_File, Exec_Master_log_Pos)构成一个坐标，这个坐标表示slave上已经将master上的哪些数据重放到自己的实例中，它可以用于下一次change master to时指定的binlog坐标。\n与这个坐标相对应的是slave上SQL线程的relay log坐标(Relay_Log_File, Relay_Log_Pos)。这两个坐标位置不同，但它们对应的数据是一致的。\n最后还有一个延迟参数Seconds_Behind_Master需要说明一下，它的本质意义是SQL线程比IO线程慢多少。如果master和slave之间的网络状况优良，那么slave的IO线程读速度和master写binlog的速度基本一致，所以这个参数也用来描述\u0026quot;SQL线程比master慢多少\u0026quot;，也就是说slave比master少多少数据，只不过衡量的单位是秒。但需要注意，这个参数的描述并不标准，只有在网速很好的时候做个大概估计，很多种情况下它的值都是0，即使SQL线程比IO线程慢了很多也是如此。\nslave信息汇总 上面的master.info、relay-log.info和show slave status的状态都是刚连接上master还未启动IO thread、SQL thread时的状态。下面将显示已经进行一段正在执行复制的slave状态。\n首先查看启动io thread和sql thread后的状态。使用show processlist查看即可。\n1 2 3 4 5 6 7 8 9 10 11 mysql\u0026gt; start slave; mysql\u0026gt; show processlist; # slave上的信息，为了排版，简化了输出 +----+-------------+---------+--------------------------------------------------------+ | Id | User | Command | State | +----+-------------+---------+--------------------------------------------------------+ | 4 | root | Sleep | | | 7 | root | Query | starting | | 8 | system user | Connect | Waiting for master to send event | | 9 | system user | Connect | Slave has read all relay log; waiting for more updates | +----+-------------+---------+--------------------------------------------------------+ 可以看到：\nId=8的线程负责连接master并读取binlog，它是IO 线程，它的状态指示\u0026quot;等待master发送更多的事件\u0026quot;； Id=9的线程负责读取relay log，它是SQL线程，它的状态指示\u0026quot;已经读取了所有的relay log\u0026quot;。 再看看此时master上的信息。\n1 2 3 4 5 6 7 8 9 mysql\u0026gt; show processlist; # master上的信息，为了排版，经过了修改 +----+------+-----------------------+-------------+--------------------------------------+ | Id | User | Host | Command | State | +----+------+-----------------------+-------------+--------------------------------------+ | 4 | root | localhost | Query | starting | |----|------|-----------------------|-------------|--------------------------------------| | 16 | repl | 192.168.100.150:39556 | Binlog Dump | Master has sent all binlog to slave; | | | | | | waiting for more updates | +----+------+-----------------------+-------------+--------------------------------------+ master上有一个Id=16的binlog dump线程，该线程的用户是repl。它的状态指示\u0026quot;已经将所有的binlog发送给slave了\u0026quot;。\n现在，在master上执行一个长事件，以便查看slave上的状态信息。\n仍然使用前面插入数值辅助表的存储过程，这次分别向两张表中插入一亿条数据(尽管去抽烟、喝茶，够等几分钟的。如果机器性能不好，请大幅减少插入的行数)。\n1 2 call proc_num1(100000000); call proc_num2(100000000); 然后去slave上查看信息，如下。因为太长，已经裁剪了一部分没什么用的行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 mysql\u0026gt; show slave status\\G mysql: [Warning] Using a password on the command line interface can be insecure. *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.100.20 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: master-bin.000003 Read_Master_Log_Pos: 512685413 Relay_Log_File: slave-bin.000003 Relay_Log_Pos: 336989434 Relay_Master_Log_File: master-bin.000003 Slave_IO_Running: Yes Slave_SQL_Running: Yes Exec_Master_Log_Pos: 336989219 Slave_SQL_Running_State: Reading event from the relay log 从中获取到的信息有：\nIO线程的状态 SQL线程的状态 IO线程读取到master binlog的哪个位置：512685413 SQL线程已经执行到relay log的哪个位置：336989434 SQL线程执行的位置对应于master binlog的哪个位置：336989219 可以看出，IO线程比SQL线程超前了很多很多，所以SQL线程比IO线程的延迟较大。\nMySQL复制如何实现断开重连 很多人以为change master to语句是用来连接master的，实际上这种说法是错的。连接master是IO线程的事情，change master to只是为IO线程连接master时提供连接参数。\n如果slave从来没连接过master，那么必须使用change master to语句来生成IO线程所需要的信息，这些信息记录在master.info中。这个文件是change master to成功之后立即生成的，以后启动IO线程时，IO线程都会自动读取这个文件来连接master，不需要先执行change master to语句。\n例如，可以随时stop slave来停止复制线程，然后再随时start slave，只要master.info存在，且没有人为修改过它，IO线程就一定不会出错。这是因为master.info会随着IO线程的执行而更新，无论读取到master binlog的哪个位置，都会记录下这个位置，如此一来，IO线程下次启动的时候就知道从哪里开始监控master binlog。\n前面还提到一个文件：relay-log.info文件。这个文件中记录的是SQL线程的相关信息，包括读取、执行到relay log的哪个位置，刚重放的数据对应master binlog的哪个位置。随着复制的进行，这个文件的信息会即时改变。所以，通过relay-log.info，下次SQL线程启动的时候就能知道从relay log的哪个地方继续读取、执行。\n如果不小心把relay log文件删除了，SQL线程可能会丢失了一部分相比IO线程延迟的数据。这时候，只需将relay-log.info中第4、5行记录的\u0026quot;SQL线程刚重放的数据对应master binlog的坐标\u0026quot;手动修改到master.info中即可，这样IO线程下次连接master就会从master binlog的这个地方开始监控。当然，也可以将这个坐标作为change master to的坐标来修改master.info。\n此外，当mysql实例启动时，默认会自动start slave，也就是MySQL一启动就自动开启复制线程。如果想要禁止这种行为，在配置文件中加上：\n1 2 [mysqld] skip-slave-start 一些变量 默认情况下，slave连接到master后会在slave的datadir下生成master.info和relay-log.info文件，但是这是可以通过设置变量来改变的。\nmaster-info-repository={TABLE|FILE}：master的信息是记录到文件master.info中还是记录到表mysql.slave_master_info中。默认为file。 relay-log-info-repository={TABLE|FILE}：slave的信息是记录到文件relay-log.info中还是记录到表mysql.slave_relay_log_info中。默认为file。 IO线程每次从master复制日志要写入到relay log中，但是它是先放在内存的，等到一定时机后才会将其刷到磁盘上的relay log文件中。刷到磁盘的时机可以由变量控制。 另外，IO线程每次从master复制日志后都会更新master.info的信息，也是先更新内存中信息，在特定的时候才会刷到磁盘的master.info文件；同理SQL线程更新realy-log.info也是一样的。它们是可以通过变量来设置更新时机的。\nsync-relay-log=N：设置为大于0的数表示每从master复制N个事件就刷一次盘。设置为0表示依赖于操作系统的sync机制。 sync-master-info=N：依赖于master-info-repository的设置，如果为file，则设置为大于0的值时表示每更新多少次master.info将其写入到磁盘的master.info中，设置为0则表示由操作系统来决定何时调用fdatasync()函数刷到磁盘。如果设置为table，则设置为大于0的值表示每更新多少次master.info就更新mysql.slave_master_info表一次，如果设置为0则表示永不更新该表。 sync-relay-log-info=N：同上。 一主多从 一主多从有两种情况，结构图如下。\n以下是一主多从的结构图(和一主一从的配置方法完全一致)：\n以下是一主多从，但某slave是另一群MySQL实例的master：\n配置一主多从时，需要考虑一件事：slave上是否要开启binlog? 如果不开启slave的binlog，性能肯定要稍微好一点。但是开启了binlog后，可以通过slave来备份数据，也可以在master宕机时直接将slave切换为新的master。此外，如果是上面第二种主从结构，这台slave必须开启binlog。可以将某台或某几台slave开启binlog，并在mysql动静分离的路由算法上稍微减少一点到这些slave上的访问权重。\n上面第一种一主多从的结构没什么可解释的，它和一主一从的配置方式完全一样，但是可以考虑另一种情况：向现有主从结构中添加新的slave。所以，稍后先介绍这种添加slave，再介绍第二种一主多从的结构。\n向现有主从结构中添加slave 官方手册：https://dev.mysql.com/doc/refman/5.7/en/replication-howto-additionalslaves.html\n例如在前文一主一从的实验环境下添加一台新的slave。\n因为新的slave在开始复制前，要有master上的基准数据，还要有master binlog的坐标。按照前文一主一从的配置方式，当然很容易获取这些信息，但这样会将master锁住一段时间(因为要备份基准数据)。\n深入思考一下，其实slave上也有数据，还有relay log以及一些仓库文件标记着数据复制到哪个地方。所以，完全可以从slave上获取基准数据和坐标，也建议这样做。\n仍然有三种方法从slave上获取基准数据：冷备份、mysqldump和xtrabackup。方法见前文将slave恢复到master指定的坐标。\n其实临时关闭一个slave对业务影响很小，所以我个人建议，新添加slave时采用冷备份slave的方式，不仅备份恢复的速度最快，配置成slave也最方便，这一点和前面配置\u0026quot;一主一从\u0026quot;不一样。但冷备份slave的时候需要注意几点：\n可以考虑将slave1完全shutdown再将整个datadir拷贝到新的slave2上。 建议新的slave2配置文件中的\u0026quot;relay-log\u0026quot;的值和slave1的值完全一致，否则应该手动从slave2的relay-log.info中获取IO线程连接master时的坐标，并在slave2上使用change master to语句设置连接参数。 方法很简单，所以不做演示了。\n配置一主多从(从中有从) 此处实现的一主多从是下面这种结构：\n这种结构对MySQL复制来说，是一个很好的提升性能的方式。对于只有一个master的主从复制结构，每多一个slave，意味着master多发一部分binlog，业务稍微繁忙一点时，这种压力会加剧。而这种一个主master、一个或多个辅助master的主从结构，非常有助于MySQL集群的伸缩性，对压力的适应性也很强。\n除上面一主多从、从中有从的方式可提升复制性能，还有几种提升MySQL复制性能的方式：\n将不同数据库复制到不同slave上。 可以将master上的事务表(如InnoDB)复制为slave上的非事务表(如MyISAM)，这样slave上回放的速度加快，查询数据的速度在一定程度上也会提升。 回到这种主从结构，它有些不同，master只负责传送日志给slave1、slave2和slave3，slave 2_1和slave 2_2的日志由slave2负责传送，所以slave2上也必须要开启binlog选项。此外，还必须开启一个选项--log-slave-updates让slave2能够在重放relay log时也写自己的binlog，否则slave2的binlog仅接受人为的写操作。\n问：slave能否进行写操作？重放relay log的操作是否会记录到slave的binlog中？\n1、在slave上没有开启read-only选项(只读变量)时，任何有写权限的用户都可以进行写操作，这些操作都会记录到binlog中。注意，read-only选项对具有super权限的用户以及SQL线程执行的重放写操作无效。 默认这个选项是关闭的。\n1 2 3 4 5 6 mysql\u0026gt; show variables like \u0026#34;read_only\u0026#34;; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | read_only | OFF | +---------------+-------+ 2、在slave上没有开启log-slave-updates和binlog选项时，重放relay log不会记录binlog。\n所以如果slave2要作为某些slave的master，那么在slave2上必须要开启log-slave-updates和binlog选项。为了安全和数据一致性，在slave2上还应该启用read-only选项。\n环境如下：\n以下是master、slave1和slave2上配置文件内容。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 # master上的配置 [mysqld] datadir=/data socket=/data/mysql.sock server_id=100 sync-binlog=1 log_bin=master-bin log-error=/data/err.log pid-file=/data/mysqld.pid # slave1上的配置 [mysqld] datadir=/data socket=/data/mysql.sock server_id=111 relay-log=slave-bin log-error=/data/err.log pid-file=/data/mysqld.pid log-slave-updates # 新增配置 log-bin=master-slave-bin # 新增配置 read-only=ON # 新增配置 # slave2上的配置 [mysqld] datadir=/data socket=/data/mysql.sock server_id=123 relay-log=slave-bin log-error=/data/err.log pid-file=/data/mysqld.pid read-only=ON 因为slave2目前是全新的实例，所以先将slave1的基准数据备份到slave2。由于slave1自身就是slave，临时关闭一个slave对业务影响很小，所以直接采用冷备份slave的方式。\n1 2 3 4 5 6 7 # 在slave2上执行 shell\u0026gt; mysqladmin -uroot -p shutdown # 在slave1上执行： shell\u0026gt; mysqladmin -uroot -p shutdown shell\u0026gt; rsync -az --delete /data 192.168.100.19:/ shell\u0026gt; service mysqld start 冷备份时，以下几点千万注意：\n因为slave2是slave1的从，所以在启动MySQL前必须将备份到slave2上的和复制有关的文件都删除。包括： master.info。除非配置文件中指定了skip-slave-start，否则slave2将再次连接到master并作为master的slave。 relay-log.info。因为slave1启动后会继续执行relay log中的内容(如果有未执行的)，这时slave1会将这部分写入binlog并传送到slave2。 删除relay log文件。其实不是必须删除，但建议删除。 删除relay log index文件。 删除DATADIR/auto.conf。这个文件必须删除，因为这里面保留了mysql server的UUID，而master和slave的UUID必须不能一致。在启动mysql的时候，如果没有这个文件会自动生成自己的UUID并保存到auto.conf中。 检查slave1上从master复制过来的专门用于复制的用户repl是否允许slave2连接。如果不允许，应该去master上修改这个用户。 因为slave1是刚开启的binlog，所以slave2连接slave1时的binlog position应该指定为4。即使slave1不是刚开启的binlog，它在重启后也会滚动binlog。 所以，在slave2上继续操作：\n1 2 3 4 5 6 7 shell\u0026gt; ls /data auto.cnf ib_buffer_pool ib_logfile1 performance_schema slave-bin.000005 backuptest ibdata1 master.info relay-log.info slave-bin.index err.log ib_logfile0 mysql slave-bin.000004 sys shell\u0026gt; rm -f /data/{master.info,relay-log.info,auto.conf,slave-bin*} shell\u0026gt; service mysqld start 最后连上slave2，启动复制线程。\n1 2 3 4 5 6 7 8 9 10 shell\u0026gt; mysql -uroot -p mysql\u0026gt; change master to master_host=\u0026#39;192.168.100.150\u0026#39;, master_port=3306, master_user=\u0026#39;repl\u0026#39;, master_password=\u0026#39;P@ssword1!\u0026#39;, master_log_file=\u0026#39;master-slave-bin.000001\u0026#39;, master_log_pos=4; mysql\u0026gt; start slave; mysql\u0026gt; show slave status\\G MySQL复制中一些常用操作 筛选要复制的库和表 默认情况下，slave会复制master上所有库。可以指定以下变量显式指定要复制的库、表和要忽略的库、表，也可以将其写入配置文件。\n1 2 3 4 5 6 Replicate_Do_DB: 要复制的数据库 Replicate_Ignore_DB: 不复制的数据库 Replicate_Do_Table: 要复制的表 Replicate_Ignore_Table: 不复制的表 Replicate_Wild_Do_Table: 通配符方式指定要复制的表 Replicate_Wild_Ignore_Table: 通配符方式指定不复制的表 如果要指定列表，则多次使用这些变量进行设置。\n需要注意的是，尽管显式指定了要复制和忽略的库或者表，但是master还是会将所有的binlog传给slave并写入到slave的relay log中，真正负责筛选的slave上的SQL线程。\n另外，如果slave上开启了binlog，SQL线程读取relay log后会将所有的事件都写入到自己的binlog中，只不过对于那些被忽略的事件只记录相关的事务号等信息，不记录事务的具体内容。所以，如果之前设置了被忽略的库或表，后来取消忽略后，它们在取消忽略以前的变化是不会再重放的，特别是基于gtid的复制会严格比较binlog中的gtid。\n总之使用筛选的时候应该多多考虑是否真的要筛选，是否是永久筛选。\nreset slave和reset master reset slave会删除master.info/relay-log.info和relay log，然后新生成一个relay log。但是change master to设置的连接参数还在内存中保留着，所以此时可以直接start slave，并根据内存中的change master to连接参数复制日志。\nreset slave all除了删除reset slave删除的东西，还删除内存中的change master to设置的连接信息。\nreset master会删除master上所有的二进制日志，并新建一个日志。在正常运行的主从复制环境中，执行reset master很可能导致异常状况。所以建议使用purge来删除某个时间点之前的日志(应该保证只删除那些已经复制完成的日志)。\nshow slave hosts 如果想查看master有几个slave的信息，可以使用show slave hosts。以下为某个master上的结果：\n1 2 3 4 5 6 7 mysql\u0026gt; show slave hosts; +-----------+------+------+-----------+--------------------------------------+ | Server_id | Host | Port | Master_id | Slave_UUID | +-----------+------+------+-----------+--------------------------------------+ | 111 | | 3306 | 11 | ff7bb057-2466-11e7-8591-000c29479b32 | | 1111 | | 3306 | 11 | 9b119463-24d2-11e7-884e-000c29867ec2 | +-----------+------+------+-----------+--------------------------------------+ 可以看到，该show中会显示server-id、slave的主机地址和端口号、它们的master_id以及这些slave独一无二的uuid号。\n其中show结果中的host显示结果是由slave上的变量report_host控制的，端口是由report_port控制的。\n例如，在slave2上修改其配置文件，添加report-host项后重启MySQL服务。\n1 2 [mysqld] report_host=192.168.100.19 在slave1(前文的实验环境，slave1是slave2的master)上查看，host已经显示为新配置的项。\n1 2 3 4 5 6 7 mysql\u0026gt; show slave hosts; +-----------+----------------+------+-----------+--------------------------------------+ | Server_id | Host | Port | Master_id | Slave_UUID | +-----------+----------------+------+-----------+--------------------------------------+ | 111 | 192.168.100.19 | 3306 | 11 | ff7bb057-2466-11e7-8591-000c29479b32 | | 1111 | | 3306 | 11 | 9b119463-24d2-11e7-884e-000c29867ec2 | +-----------+----------------+------+-----------+--------------------------------------+ 多线程复制 在老版本中，只有一个SQL线程读取relay log并重放。重放的速度肯定比IO线程写relay log的速度慢非常多，导致SQL线程非常繁忙，且实现到从库上延迟较大。没错，多线程复制可以解决主从延迟问题，且使用得当的话效果非常的好(关于主从复制延迟，是生产环境下最常见的问题之一，且没有很好的办法来避免。后文稍微介绍了一点方法)。\n在MySQL 5.6中引入了多线程复制(multi-thread slave，简称MTS)，这个多线程指的是多个SQL线程，IO线程还是只有一个。 当IO线程将master binlog写入relay log中后，一个称为\u0026quot;多线程协调器(multithreaded slave coordinator)\u0026ldquo;会对多个SQL线程进行调度，让它们按照一定的规则去执行relay log中的事件。\n需要谨记于心的是，如果对多线程复制没有了解的很透彻，千万不要在生产环境中使用多线程复制。 它的确带来了一些复制性能的提升，并且能解决主从超高延迟的问题，但随之而来的是很多的\u0026quot;疑难杂症\u0026rdquo;，这些\u0026quot;疑难杂症\u0026quot;并非是bug，只是需要多多了解之后才知道为何会出现这些问题以及如何解决这些问题。稍后会简单介绍一种多线程复制问题：gaps。\n通过全局变量slave-parallel-workers控制SQL线程个数，设置为非0正整数N，表示多加N个SQL线程，加上原有的共N+1个SQL线程。默认为0，表示不加任何SQL线程，即关闭多线程功能。\n1 2 3 4 5 6 mysql\u0026gt; show variables like \u0026#34;%parallel%\u0026#34;; +------------------------+-------+ | Variable_name | Value | +------------------------+-------+ | slave_parallel_workers | 0 | +------------------------+-------+ 显然，多线程只有在slave上开启才有效，因为只有slave上才有SQL线程。另外，设置了该全局变量，需要重启SQL线程才生效，否则内存中还是只有一个SQL线程。\n例如，初始时slave上的processlist如下：\n设置slave_parallel_workers=2。\n1 2 3 4 mysql\u0026gt; set @@global.slave_parallel_workers=2; mysql\u0026gt; stop slave sql_thread; msyql\u0026gt; start slave sql_thread; mysql\u0026gt; show full processlist; 可见多出了两个线程，其状态信息是\u0026quot;Waiting for an event from Coordinator\u0026quot;。\n虽然是多个SQL线程，但是复制时每个库只能使用一个线程(默认情况下，可以通过--slave-parallel-type修改并行策略)，因为如果一个库可以使用多个线程，多个线程并行重放relay log，可能导致数据错乱。所以应该设置线程数等于或小于要复制的库的数量，设置多了无效且浪费资源。\n多线程复制带来的不一致问题 虽然多线程复制带来了一定的复制性能提升，但它也带来了很多问题，最严重的是一致性问题。完整的内容见官方手册。此处介绍其中一个最重要的问题。\n关于多线程复制，最常见也是开启多线程复制前最需要深入了解的问题是：由于多个SQL线程同时执行relay log中的事务，这使得slave上提交事务的顺序很可能和master binlog中记录的顺序不一致(除非指定变量slave_preserve_commit_order=1)。 (注意：这里说的是事务而不是事件。因为MyISAM的binlog顺序无所谓，只要执行完了就正确，而且多线程协调器能够协调好这些任务。所以只需考虑innodb基于事务的binlog)\n举个简单的例子，master上事务A先于事务B提交，到了slave上因为多SQL线程的原因，可能事务B提交了事务A却还没提交。\n是否还记得show slave status中的Exec_master_log_pos代表的意义？它表示SQL线程最近执行的事件对应的是master binlog中的哪个位置。问题由此而来。通过show slave status，我们看到已经执行事件对应的坐标，它前面可能还有事务没有执行。而在relay log中，事务B记录的位置是在事务A之后的(和master一样)，于是事务A和事务B之间可能就存在一个孔洞(gap)，这个孔洞是事务A剩余要执行的操作。\n正常情况下，多线程协调器记录了一切和多线程复制相关的内容，它能识别这种孔洞(通过打低水位标记low-watermark)，也能正确填充孔洞。即使是在存在孔洞的情况下执行stop slave也不会有任何问题，因为在停止SQL线程之前，它会等待先把孔洞填充完。 但危险因素太多，比如突然宕机、突然杀掉mysqld进程等等，这些都会导致孔洞持续下去，甚至可能因为操作不当而永久丢失这部分孔洞。\n那么如何避免这种问题，出现这种问题如何解决？\n1、如何避免gap。\n前面说了，多个SQL线程是通过协调器来调度的。默认情况下，可能会出现gap的情况，这是因为变量slave_preserve_commit_order的默认值为0。该变量指示协调器是否让每个SQL线程执行的事务按master binlog中的顺序提交。因此，将其设置为1，然后重启SQL线程即可保证SQL线程按序提交，也就不可能会有gap的出现。\n当事务B准备先于事务A提交的时候，它将一直等待。此时slave的状态将显示：\n1 2 Waiting for preceding transaction to commit # MySQL 5.7.8之后显示该状态 Waiting for its turn to commit # MySQL 5.7.8之前显示该状态 尽管不会出现gap，但show slave status的Exec_master_log_pos仍可能显示在事务A的坐标之后。\n由于开启slave_preserve_commit_order涉及到不少操作，它还要求开启slave的binlog--log-bin(因此需要重启mysqld)，且开启重放relay log也记录binlog的行为--log-slave-updates，此外，还必须设置多线程的并行策略--slave-parallel-type=LOGICAL_CLOCK。\n1 2 3 4 5 6 7 8 9 shell\u0026gt; mysqladmin -uroot -p shutdown shell\u0026gt; cat /etc/my.cnf log_bin=slave-bin log-slave-updates slave_parallel_workers=1 slave_parallel_type=LOGICAL_CLOCK shell\u0026gt;service mysqld start 2、如何处理已经存在的gap。\n方法之一，是从master上重新备份恢复到slave上，这种方法是处理不当的最后解决办法。\n正常的处理方法是，使用START SLAVE [SQL_THREAD] UNTIL SQL_AFTER_MTS_GAPS;，它表示SQL线程只有先填充gaps后才能启动。实际上，它涉及了两个操作：\n填充gaps 自动停止SQL线程(所以之后需要手动启动SQL线程) 一般来说，在填充完gaps之后，应该先reset slave移除已经执行完的relay log，然后再去启动sql_thread。\n多线程复制切换回单线程复制 多线程的带来的问题不止gaps一种，所以没有深入了解多线程的情况下，千万不能在生产环境中启用它。如果想将多线程切换回单线程，可以执行如下操作：\n1 2 3 START SLAVE UNTIL SQL_AFTER_MTS_GAPS; SET @@GLOBAL.slave_parallel_workers = 0; START SLAVE SQL_THREAD; slave升级为master的大致操作 当master突然宕机，有时候需要切换到slave，将slave提升为新的master。但对于master突然宕机可能造成的数据丢失，主从切换是无法解决的，它只是尽可能地不间断提供MySQL服务。\n假如现在有主服务器M，从服务器S1、S2，S1作为将来的新的master。\n1、在将S1提升为master之前，需要保证S1已经将relay log中的事件已经replay完成。即下面两个状态查看语句中SQL线程的状态显示为：\u0026ldquo;Slave has read all relay log; waiting for the slave I/O thread to update it\u0026rdquo;。\n1 2 show slave status; show processlist; 2、停止S1上的IO线程和SQL线程，然后将S1的binlog清空(要求已启用binlog)。\n1 2 mysql\u0026gt; stop slave; mysql\u0026gt; reset master; 3、在S2上停止IO线程和SQL线程，通过change master to修改master的指向为S1，然后再启动io线程和SQL线程。\n1 2 3 mysql\u0026gt; stop slave; mysql\u0026gt; change master to master_host=S1,... mysql\u0026gt; start slave; 4、将应用程序原本指向M的请求修改为指向S1，如修改MySQL代理的目标地址。一般会通过MySQL Router、Amoeba、cobar等数据库中间件来实现。\n5、删除S1上的master.info、relay-log.info文件，否则下次S1重启服务器会继续以slave角色运行。\n6、将来M重新上线后，可以将其配置成S1的slave，然后修改应用程序请求的目标列表，添加上新上线的M，如将M加入到MySQL代理的读目标列表。\n注意：reset master很重要，如果不是基于GTID复制且开启了log-slave-updates选项时，S1在应用relay log的时候会将其写入到自己的binlog，以后S2会复制这些日志导致重复执行的问题。\n其实上面只是提供一种slave升级为Master的解决思路，在实际应用中环境可能比较复杂。例如，上面的S1是S2的master，这时S1如果没有设置为read-only，当M宕机时，可以不用停止S1，也不需要reset master等操作，受影响的操作仅仅只是S1一直无法连接M而已，但这对业务不会有多大的影响。\n相信理解了前面的内容，分析主从切换的思路应该也没有多大问题。\n指定不复制到slave上的语句 前面说的筛选要复制的库和表可以用于指定不复制到slave上的库和表，但却没有筛选不复制到slave的语句。\n但有些特殊情况下，可能需要这种功能。例如，master上创建专门用于复制的用户repl，这种语句其实没有必要复制到slave上，甚至出于安全的考虑不应该复制到slave上。\n可以使用sql_log_bin变量对此进行设置，默认该变量的值为1，表示所有语句都写进binlog，从而被slave复制走。如果设置为0，则之后的语句不会写入binlog，从而实现\u0026quot;不复制某些语句到slave\u0026quot;上的功能。\n例如：屏蔽创建repl用户的语句。\n1 2 3 4 mysql\u0026gt; set sql_log_bin=0; mysql\u0026gt; create user repl@\u0026#39;%\u0026#39; identified by \u0026#39;P@ssword1!\u0026#39;; mysql\u0026gt; grant replication slave on *.* to repl@\u0026#39;%\u0026#39;; mysql\u0026gt; set sql_log_bin=1; 在使用该变量时，默认是会话范围内的变量，一定不能设置它的全局变量值，否则所有语句都将不写binlog。\n主从高延迟的解决思路 slave通过IO线程获取master的binlog，并通过SQL线程来应用获取到的日志。因为各个方面的原因，经常会出现slave的延迟(即Seconds_Behind_Master的值)非常高(动辄几天的延迟是常见的，几个小时的延迟已经算短的)，使得主从状态不一致。\n一个很容易理解的延迟示例是：假如master串行执行一个大事务需要30分钟，那么slave应用这个事务也大约要30分钟，从master提交的那一刻开始，slave的延迟就是30分钟，更极端一点，由于binlog的记录时间点是在事务提交时，如果这个大事务的日志量很大，比如要传输10多分钟，那么很可能延迟要达到40分钟左右。而且更严重的是，这种延迟具有滚雪球的特性，从延迟开始，很容易导致后续加剧延迟。\n所以，第一个优化方式是不要在mysql中使用大事务，这是mysql主从优化的第一口诀。\n在回归正题，要解决slave的高延迟问题，先要知道Second_Behind_Master是如何计算延迟的：SQL线程比IO线程慢多少(其本质是NOW()减去Exec_Master_Log_Pos处设置的TIMESTAMP)。在主从网络状态良好的情况下，IO线程和master的binlog大多数时候都能保持一致(也即是IO线程没有多少延迟，除非事务非常大，导致二进制日志传输时间久，但mysql优化的一个最基本口诀就是大事务切成小事务)，所以在这种理想状态下，可以认为主从延迟说的是slave上的数据状态比master要延迟多少。它的计数单位是秒。\n从产生Binlog的master上考虑，可以在master上应用group commit的功能，并设置参数binlog_group_commit_sync_delay和bin log_group_commit_sync_no_delay_count，前者表示延迟多少秒才提交事务，后者表示要堆积多少个事务之后再提交。这样一来，事务的产生速度降低，slave的SQL线程相对就得到缓解。\n再者从slave上考虑，可以在slave上开启多线程复制(MTS)功能，让多个SQL线程同时从一个IO线程中取事务进行应用，这对于多核CPU来说是非常有效的手段。 但是前面介绍多线程复制的时候说过，没有掌握多线程复制的方方面面之前，千万不要在生产环境中使用多线程复制，要是出现gap问题，很让人崩溃。\n最后从架构上考虑。主从延迟是因为slave跟不上master的速度，那么可以考虑对master进行节流控制，让master的性能下降，从而变相提高slave的能力。这种方法肯定是没人用的，但确实是一种方法，提供了一种思路，比如slave使用性能比master更好的硬件。另一种比较可取的方式是加多个中间slave层(也就是master-\u0026gt;slaves-\u0026gt;slaves)，让多个中间slave层专注于复制(也可作为非业务的他用，比如用于备份)。\n使用组复制或者Galera/PXC的多写节点，此外还可以设置相关参数，让它们对延迟自行调整。但一般都不需要调整，因为有默认设置。\n还有比较细致的方面可以降低延迟，比如设置为row格式的Binlog要比statement要好，因为不需要额外执行语句，直接修改数据即可。比如master设置保证数据一致性的日志刷盘规则(sync_binlog/innodb_flush_log_at_trx_commit设置为1)，而slave关闭binlog或者设置性能优先于数据一致性的binlog刷盘规则。再比如设置slave的隔离级别使得slave的锁粒度放大，不会轻易锁表(多线程复制时避免使用此方法)。还有很多方面，选择好的磁盘，设计好分库分表的结构等等，这些都是直接全局的，实在没什么必要在这里多做解释。\n","date":"2023-09-18T14:51:23+08:00","permalink":"http://localhost:1313/post/mysql-replication-1/","title":"深入MySQL复制(一)"},{"content":"由于公司使用自己的git服务进行代码管理，导致很长时间我的github都没有贡献记录，现在让我们来试试将gitlab的贡献记录导出并提交到github。\n这里我使用import-gitlab-commits工具来操作，import-gitlab-commits是一个用golang编写的工具，可以非常简单的将gitlab贡献记录导出\n操作步骤 安装import-gitlab-commits 使用go install github.com/alexandear/import-gitlab-commits@latest命令将该工具直接安装到gopath路径下， 如果不知道自己的gopath路径，可以使用echo $GOPATH命令查看，如果没有配置过该路径，则会自动安装到HOME/go/bin下。\n配置环境变量 1 2 3 4 export GITLAB_BASE_URL=https://xxx.com # 公司的gitlab地址 export GITLAB_TOKEN=your_secure_token # gitlab token export COMMITTER_NAME=your_github_name # github 用户名 export COMMITTER_EMAIL=your_github_email # github 邮箱地址 运行导出工具 1 ~/go/bin/import-gitlab-commits 运行成功后会在当前路径下生成repo.xxx.com.user仓库\n到github创建新仓库clarity-contributions（名字随意） 将上面工具生成的仓库提交到新简的仓库 1 2 3 cd repo.xxx.com.user git remote add origin git@github.com:xxx/clarity-contributions.git git push --set-upstream origin master 到github查看，可以看到gitlab的贡献记录已经同步到github，大功告成\n","date":"2023-09-15T13:47:01+08:00","permalink":"http://localhost:1313/post/gitlab2github/","title":"gitlab贡献记录同步到github"},{"content":"现状及问题 在golang开发中我们经常会使用gin作为web框架，gin一直以高性能和简单著称，并且有十分完善的官方文档。然而gin的错误处理却一直以来都被人吐槽， 正常情况下我们在handler层需要根据service层返回的结果给前端相应的响应内容，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 package main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { r := gin.Default() r.GET(\u0026#34;/hello\u0026#34;, helloHandler) r.GET(\u0026#34;/world\u0026#34;, worldHandler) r.Run() } func helloHandler(c *gin.Context) { resp, err := helloService.Hello() if err != nil { c.JSON(http.StatusInternalServerError, gin.H{ \u0026#34;message\u0026#34;: err.Error(), \u0026#34;data\u0026#34;: nil, }) return } c.JSON(http.StatusInternalServerError, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;data\u0026#34;: resp, }) } func worldHandler(c *gin.Context) { resp, err := worldService.World() if err != nil { c.JSON(http.StatusInternalServerError, gin.H{ \u0026#34;message\u0026#34;: err.Error(), \u0026#34;data\u0026#34;: nil, }) return } c.JSON(http.StatusInternalServerError, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;data\u0026#34;: resp, }) } 在每个handler中重复判断service是否返回异常未免太过繁琐，接下来我们通过golang的函数编程能力，使用中间件进行处理\n简单方案 使用中间件改变handler函数，在中间件中处理返回逻辑\n定义返回结构体、异常处理函数以及中间件Wrapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 package middleware import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) // 返回结构体 type resp struct { Code int `json:\u0026#34;code\u0026#34;` Message string `json:\u0026#34;message\u0026#34;` Data any `json:\u0026#34;data\u0026#34;` } func errResp(message string) resp { return resp{ Code: http.StatusInternalServerError, Message: message, Data: nil, } } func okResp(data interface{}) resp { return resp{ Code: http.StatusOK, Message: \u0026#34;ok\u0026#34;, Data: data, } } // ExceptionHandlerFunc 异常处理函数 type ExceptionHandlerFunc func(c *gin.Context) (data any, err error) // Wrapper 中间件 func Wrapper(handlerFunc ExceptionHandlerFunc) func(c *gin.Context) { return func(c *gin.Context) { data, err := handlerFunc(c) if err != nil { c.JSON(http.StatusOK,errResp(err.Error())) return } c.JSON(http.StatusOK, okResp(data)) } } 修改router方法注册以及handler函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 package main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { r := gin.Default() r.GET(\u0026#34;/hello\u0026#34;, middleware.Wrapper(helloHandler)) // 使用Wrapper中间件 r.GET(\u0026#34;/world\u0026#34;, middleware.Wrapper(worldHandler)) // 使用Wrapper中间件 r.Run() } // 将handler改写为ExceptionHandlerFunc类型 func helloHandler(c *gin.Context)(data any, err error) { // 省略参数获取、验证等流程 resp, err := helloService.Hello() // 从service获取结果并且处理返回 // 省略对resp的处理 return resp, err } // 将handler改写为ExceptionHandlerFunc类型 func worldHandler(c *gin.Context)(data any, err error) { // 省略参数获取、验证等流程 return worldService.World() // 直接返回service结果 } 从代码可以看出，使用该方法可以简化handler方法的逻辑，并且实现起来相对简单\n复杂方案 自定义错误类型、错误处理函数并在中间件中统一处理\n定义结构体，实现Error接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // api错误的结构体 type APIException struct { Code int `json:\u0026#34;-\u0026#34;` ErrorCode int `json:\u0026#34;error_code\u0026#34;` Msg string `json:\u0026#34;msg\u0026#34;` Request string `json:\u0026#34;request\u0026#34;` } // 实现接口 func (e *APIException) Error() string { return e.Msg } func newAPIException(code int, errorCode int,msg string) *APIException { return \u0026amp;APIException{ Code:code, ErrorCode:errorCode, Msg:msg, } } 定义错误处理的函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 const ( SERVER_ERROR = 1000 // 系统错误 NOT_FOUND = 1001 // 401错误 UNKNOWN_ERROR = 1002 // 未知错误 PARAMETER_ERROR = 1003 // 参数错误 AUTH_ERROR = 1004 // 错误 ) // 500 错误处理 func ServerError() *APIException { return newAPIException(http.StatusInternalServerError,SERVER_ERROR,http.StatusText(http.StatusInternalServerError)) } // 404 错误 func NotFound() *APIException { return newAPIException(http.StatusNotFound,NOT_FOUND,http.StatusText(http.StatusNotFound)) } // 未知错误 func UnknownError(message string) *APIException { return newAPIException(http.StatusForbidden,UNKNOWN_ERROR,message) } // 参数错误 func ParameterError(message string) *APIException { return newAPIException(http.StatusBadRequest,PARAMETER_ERROR,message) } 定义中间件统一处理错误 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 func wrapper(handler HandlerFunc) func(c *gin.Context) { return func(c *gin.Context) { var ( err error ) err = handler(c) if err != nil { var apiException *APIException if h,ok := err.(*APIException); ok { apiException = h }else if e, ok := err.(error); ok { if gin.Mode() == \u0026#34;debug\u0026#34; { // 错误 apiException = UnknownError(e.Error()) }else{ // 未知错误 apiException = UnknownError(e.Error()) } }else{ apiException = ServerError() } apiException.Request = c.Request.Method + \u0026#34; \u0026#34;+ c.Request.URL.String() c.JSON(apiException.Code,apiException) return } } } 定义404错误处理函数 1 2 3 4 5 6 func HandleNotFound(c *gin.Context) { handleErr := NotFound() handleErr.Request = c.Request.Method + \u0026#34; \u0026#34; + c.Request.URL.String() c.JSON(handleErr.Code,handleErr) return } 使用 1 2 3 4 5 6 7 func main() { r := gin.Default() r.NoMethod(HandleNotFound) r.NoRoute(HandleNotFound) r.GET(\u0026#34;/hello\u0026#34;, wrapper(world)) r.Run() } ","date":"2023-09-13T22:37:12+08:00","permalink":"http://localhost:1313/post/gin-global-err/","title":"gin中间件统一返回结果、处理错误"},{"content":"最近偶然刷到了B站UP主 Erik_Tse 的视频，了解到了一些代码抽象艺术，感觉很有意思， 所以特地开篇博客总结记录一下，欢迎大家补充~\n抽象小技巧 使用奇怪的变量名 滥用宏定义 简单操作复杂化 。。。。。。 抽象案例 用位运算代替加法 a + b = a ^ b + ((a \u0026amp; b) \u0026lt;\u0026lt; 1)\n1 2 3 4 5 // 计算 x + y int add(int a,int a){ if (!a) return b; return add((x\u0026amp;y)\u0026lt;\u0026lt;1, x^y); } 使用I和l组合作为变量名 1 2 3 4 5 6 int main(){ int IIIIIlllllIlIlllIIIIIlllllIlIlll; cin \u0026gt;\u0026gt; IIIIIlllllIlIlllIIIIIlllllIlIlll; cout \u0026lt;\u0026lt; IIIIIlllllIlIlll \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; return 0; } 使用奇怪宏定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #include \u0026lt;iostream\u0026gt; #define false 1 #define true 0 #define _ int #define ___ 1 using namespace std; _ main(){ _ llllIlIlllIIIIllIlIl;cin \u0026gt;\u0026gt; llllIlIlllIIIIllIlIl; _ llllIlIlllIlllIlIlllIIIII = 0; for (_ __ = ___;__ \u0026lt;= llllIlIlllIIIIllIlIl / __;__ += false){ if (llllIlIlllIIIIllIlIl % __ == 0){ llllIlIlllIlllIlIlllIIIII += false; if (__ != llllIlIlllIIIIllIlIl){ llllIlIlllIlllIlIlllIIIII += false; } } } cout \u0026lt;\u0026lt; llllIlIlllIlllIlIlllIIIII; return 0; } 让人摸不着头脑 尊嘟假嘟\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include \u0026lt;iostream\u0026gt; #define false 1 #define true 0 using namespace std; struct ZDJD{ bool O(bool x){ return x ? true : false; } }o; int mian(){ int a[] = {1, 2, 3, 4, 5}; int ans = 0; for (int i = 0; i \u0026lt; 5; i++){ if(o.O(*\u0026amp;(i - 1)[i + 1] % 2 == 0)){ ans++; } } cout \u0026lt;\u0026lt; ans \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; return 0; } 抽象实践 题目：求数组内偶数个数：\n思路：遍历数组，挨个判断元素是否为偶数\n正常代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u0026lt;iostream\u0026gt; using namespace std; int mian(){ int a[] = {1, 2, 3, 4, 5}; int ans = 0; for(int i = 0;i \u0026lt; 5;i++){ if (a[i] % 2 == 0){ ans++; } } cout \u0026lt;\u0026lt; ans \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; return 0; } 抽象代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #include \u0026lt;iostream\u0026gt; #define false 1 #define true 0 #define _ int #define ___ 0 using namespace std; struct ZDJD{ bool O(bool IIllIIlllIIIIIIllIlIll){ return IIllIIlllIIIIIIllIlIll ? true : false; } }o; _ mian(){ _ IIIIIllIIlllllIIIl[] = {1, 2, 3, 4, 5}; _ IIIIIllIIIIIIllIlIlllIIlIlI = ___; for(_ __ = ___;__ \u0026lt; 5;__-=0xffffffff){ if (o.O(*\u0026amp;(__ - 1)[__ + 1] % 2 == 0)) { IIIIIllIIIIIIllIlIlllIIlIlI-=0xffffffff; } } cout \u0026lt;\u0026lt; IIIIIllIIIIIIllIlIlllIIlIlI \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39; return 0; } ","date":"2023-08-16T11:17:42+08:00","permalink":"http://localhost:1313/post/code-abstract/","title":"代码抽象艺术（bushi"},{"content":"Google 1、添加站点资源\n打开google search-console, 需要注册账号，按网域或网址前缀添加资源，按照要求下载验证文件放到网站根目录即可\n2、添加站点地图\n网站资源验证通过后，打开google 站点地图，将Hugo自动生成的sitemap.xml 地址添加进去即可（默认生成在根目录，例如我的博客域名为https://blog.mulinbiao.com/, 则默认生成的xml位置为 https://blog.mulinbiao.com/sitemap.xml\n添加成功后 Google 搜索引擎会定期访问网站根目录下的Sitemap.xml文件，并对其进行抓取。你也可以在每次博客更新后通过api主动通知Google搜索引擎（后面会讲）。\nBing 打开Bing Webmasters Tools,同样需要注册账号，注册成功后添加网站，添加sitemap.xml文件， 整体流程和 Google 差不多。\n添加成功后 Bing 搜索引擎会定期访问网站根目录下的Sitemap.xml文件，并对其进行抓取。你也可以在每次博客更新后通过api主动通知 Bing 搜索引擎（后面会讲） 或者打开bing url提交进行手动提交。\n百度 打开百度搜索资源平台 ，点击 资源提交，然后点\u0026quot;添加站点\u0026quot;。同样可以用文件验证的方式来进行网站验证。\n注意：百度不允许提交索引型sitemap，并且百度爬虫无法访问 GitHub ，如果使用 GitHub Page 部署网站，可以使用手动提交或者百度api提交（后面会讲）。\n脚本 在添加完网站和sitemap文件之后，可以在每次更新完博客内容后使用脚本进行批量提交，来加快网页被搜索引擎收录的速度，以下是各个搜索引擎提供的方式：\nGoogle：最方便，只需要手动或自动通知Google网站有内容更新即可 Bing：不是很方便，需要手动或自动将有更新的网页url发送到 bing Baidu：不是很方便，需要手动或自动将有更新的网页url发送到 bing 下面附上我的脚本\n（没做任何优化，实现的很潦草，仅供参考）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 package main import ( \u0026#34;bytes\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;gorm.io/driver/sqlite\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;regexp\u0026#34; \u0026#34;strings\u0026#34; ) const ( googleApi = \u0026#34;http://www.google.com/ping?sitemap={{your_sitemap_url}}\u0026#34; bingApi = \u0026#34;https://ssl.bing.com/webmaster/api.svc/json/SubmitUrlbatch?apikey={{your_api_key}}\u0026#34; baiduApi = \u0026#34;http://data.zz.baidu.com/urls?site={{your_site_url}}\u0026amp;token={{your token}}\u0026#34; //其他语言，看自己是否需要 zhFile = \u0026#34;xxx/sitemap.xml\u0026#34; jaFile = \u0026#34;xxx/sitemap.xml\u0026#34; enFile = \u0026#34;xxx/sitemap.xml\u0026#34; //简单保存提交记录，避免重复提交 databases = \u0026#34;url.db\u0026#34; siteGoogle = 0 siteBing = 1 siteBaidu = 2 ) var db *gorm.DB type Url struct { Url string Site int } func main() { var err error db, err = gorm.Open(sqlite.Open(databases), \u0026amp;gorm.Config{}) if err != nil { panic(err) } if err = db.AutoMigrate(\u0026amp;Url{}); err != nil { panic(err) } googleCommit() bingCommit() baiduCommit() } // 使用 ping 的方式请求谷歌抓取站点数据 func googleCommit() { response, err := http.Get(googleApi) if err != nil { fmt.Println(\u0026#34;google commit err: \u0026#34;, err) return } if response.StatusCode == http.StatusOK { fmt.Println(\u0026#34;google commit ok\u0026#34;) } else { body, _ := ioutil.ReadAll(response.Body) fmt.Println(\u0026#34;google commit err: \u0026#34;, string(body), response.StatusCode, response.Status) } } // 每天10000个url，没有月配额 func bingCommit() { urls, err := getUrlsFromXml(\u0026#34;\u0026#34;) if err != nil { fmt.Println(\u0026#34;bing commit err: \u0026#34;, err) return } urls, err = urlDeduplication(urls, siteBing) if err != nil { fmt.Println(\u0026#34;bing commit err: \u0026#34;, err) return } if urls == nil || len(urls) == 0 { fmt.Print(\u0026#34;bing commit nothing\u0026#34;) return } mp := map[string]interface{}{ \u0026#34;siteUrl\u0026#34;: \u0026#34;https://arturiamu.github.io\u0026#34;, \u0026#34;urlList\u0026#34;: urls, } js, err := json.Marshal(mp) if err != nil { fmt.Println(\u0026#34;bing commit err: \u0026#34;, err) return } request, err := http.NewRequest(\u0026#34;post\u0026#34;, bingApi, bytes.NewReader([]byte(js))) request.Header.Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) request.Header.Set(\u0026#34;charset\u0026#34;, \u0026#34;utf-8\u0026#34;) client := http.Client{} response, err := client.Do(request) if err != nil { fmt.Println(\u0026#34;bing commit err: \u0026#34;, err) return } bd, err := ioutil.ReadAll(response.Body) if err != nil { fmt.Println(\u0026#34;bing commit err: \u0026#34;, err) return } if response.StatusCode == http.StatusOK { fmt.Println(\u0026#34;bing commit ok\u0026#34;, string(bd)) for _, url := range urls { db.Create(\u0026amp;Url{Site: siteBing, Url: url}) } fmt.Println(\u0026#34;bing save url ok\u0026#34;) } else { fmt.Println(\u0026#34;bing commit err: \u0026#34;, string(bd), response.StatusCode, response.Status) return } } func baiduCommit() { urls, err := getUrlsFromXml(\u0026#34;blog.mulinbiao.com\u0026#34;) if err != nil { fmt.Println(\u0026#34;baidu commit err: \u0026#34;, err) return } urls, err = urlDeduplication(urls, siteBaidu) if err != nil { fmt.Println(\u0026#34;baidu commit err: \u0026#34;, err) return } if urls == nil || len(urls) == 0 { fmt.Print(\u0026#34;baidu commit nothing\u0026#34;) return } str := strings.Join(urls, \u0026#34;\\n\u0026#34;) request, err := http.NewRequest(\u0026#34;POST\u0026#34;, baiduApi, bytes.NewReader([]byte(str))) if err != nil { fmt.Println(\u0026#34;baidu commit err: \u0026#34;, err) return } //request.Header.Set(\u0026#34;User-Agent\u0026#34;, \u0026#34;curl/7.12.1\u0026#34;) //request.Header.Set(\u0026#34;Host\u0026#34;, \u0026#34;data.zz.baidu.com\u0026#34;) //request.Header.Set(\u0026#34;Content-Length\u0026#34;, \u0026#34;83\u0026#34;) request.Header.Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/plain\u0026#34;) client := http.Client{} response, err := client.Do(request) if err != nil { fmt.Println(\u0026#34;baidu commit err: \u0026#34;, err) return } bd, err := ioutil.ReadAll(response.Body) if err != nil { fmt.Println(\u0026#34;baidu commit err: \u0026#34;, err) return } if response.StatusCode == http.StatusOK { fmt.Println(\u0026#34;baidu commit ok\u0026#34;, string(bd)) for _, url := range urls { db.Create(\u0026amp;Url{Site: siteBaidu, Url: url}) } fmt.Println(\u0026#34;baidu save url ok\u0026#34;) } else { fmt.Println(\u0026#34;baidu commit err: \u0026#34;, string(bd), response.StatusCode, response.Status) return } } // 去重 func urlDeduplication(us []string, site int) (urls []string, err error) { var lst []Url err = db.Where(\u0026#34;site = ?\u0026#34;, site).Find(\u0026amp;lst).Error if err != nil { return } if lst != nil \u0026amp;\u0026amp; len(lst) \u0026gt; 0 { for _, u := range us { if indexUrlArr(lst, u) == -1 { urls = append(urls, u) } } } else { for _, u := range us { urls = append(urls, u) } } return urls, nil } func indexUrlArr(arr []Url, target string) int { for i, s := range arr { if s.Url == target { return i } } return -1 } // 由于使用blog.mulinbiao.com指向arturiamu.github.io // 百度只能提交blog.mulinbiao.com，需要做转换，看自己博客需求 func getUrlsFromXml(domain string) (urls []string, err error) { fzh, err := os.ReadFile(zhFile) if err != nil { fmt.Println(\u0026#34;open file err: \u0026#34;, err) return } fja, err := os.ReadFile(jaFile) if err != nil { fmt.Println(\u0026#34;open file err: \u0026#34;, err) return } fen, err := os.ReadFile(enFile) if err != nil { fmt.Println(\u0026#34;open file err: \u0026#34;, err) return } var arr []string var mp = make(map[string]struct{}) //使用正则表达式简单从xml中提取url，可以优化 r := regexp.MustCompile(`\\bhttps?://\\S+\\b`) arr = append(arr, r.FindAllString(string(fzh), -1)...) arr = append(arr, r.FindAllString(string(fja), -1)...) arr = append(arr, r.FindAllString(string(fen), -1)...) for _, a := range arr { aa := a if !strings.Contains(aa, \u0026#34;https://arturiamu.github.io\u0026#34;) { continue } if domain != \u0026#34;\u0026#34; { aa = strings.ReplaceAll(aa, \u0026#34;arturiamu.github.io\u0026#34;, domain) } aa = strings.ReplaceAll(aa, \u0026#34;\u0026lt;/loc\u0026#34;, \u0026#34;\u0026#34;) if !strings.HasSuffix(aa, \u0026#34;/\u0026#34;) { aa = aa + \u0026#34;/\u0026#34; } if _, ok := mp[aa]; ok { continue } mp[aa] = struct{}{} urls = append(urls, aa) } return urls, nil } ","date":"2023-08-09T16:17:15+08:00","permalink":"http://localhost:1313/post/blog-seo/","title":"博客搜索引擎优化 SEO"},{"content":"为什么需要搭建集群 搭建主从同步集群可以实现MySQL数据库的高可用、可扩展和读写分离，提升系统的性能和稳定性。这在对数据库的可靠性、 并发读写能力和扩展性有较高要求的业务场景中尤为重要。\n主从同步原理 主数据库（Master）： 主数据库是数据变更的源头。它接收来自应用程序的写操作（INSERT、UPDATE、DELETE等）， 并记录这些操作在二进制日志（Binary Log）中， 这个过程叫做二进制日志事件 binary log events。\n从数据库（Slave）： 从数据库是主数据库的复制目标。它连接到主数据库，并通过读取主数据库的二进制日志来获取数据变更信息， 然后在从数据库上重现这些操作，从而保持与主数据库的数据一致性。改过程具体分为以下2个步骤：\nslave 将binary log events 拷贝到它的中继日志（relay_log）。 slave重做中继日志中的事件，将改变应用到自己的数据库中，mysql复制时异步的且串行化的 集群搭建流程 安装MySQL：在主库和从库上都安装MySQL数据库服务器。确保主库和从库的MySQL版本相同或兼容\nmaster 配置 1、打开主库的二进制日志功能。修改主机的配置文件（通常是my.cnf或my.ini），启用二进制日志，设置服务器ID。\n1 2 3 4 ...... log-bin = master-bin # 打开bin log日志文件，必须 server-id = 1 # 指定master服务id,必须 只要保证集群中唯一即可 ...... 2、启动主库MySQL服务，登陆root用户后创建主从复制用户slave并授权。\n1 2 3 4 5 6 # 登录 mysql -u root -p # 创建用户 slave，注意这里的ip是从库服务器的ip CREATE USER \u0026#39;slave\u0026#39;@\u0026#39;ip\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;123456\u0026#39;; # 给主从复制账号授权 grant replication slave on *.* to \u0026#39;slave\u0026#39;@\u0026#39;ip\u0026#39;; 3、重启主库的mysql服务，登录root查看配置是否生效\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 重启服务 service mysqld restart # 登录root mysql -u root -p # 查看配置 show master status; # 出现如下内容说明配置成功 +---------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +---------------+----------+--------------+------------------+-------------------+ | binlog.000001 | 2463 | | | | +---------------+----------+--------------+------------------+-------------------+ 1 row in set (0.01 sec) slave配置 1、修改从库的配置文件，设置服务器ID，启用从库功能.\n1 2 3 ...... server-id = 2 #只要保证集群中唯一即可 ...... 2、重启服务并配置主从同步\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 重启服务 service mysqld restart # 登录 mysql -u root -p # 关闭从库 stop slave; # 设置同步，注意这里是主库ip，master_log_file和master_log_pos是配置master第3步中 show master status 命令查出的值 change master to master_host=\u0026#39;ip\u0026#39;,master_user=\u0026#39;slave\u0026#39;,master_password=\u0026#39;123456\u0026#39;,master_log_file=\u0026#39;mysql-bin.000001\u0026#39;,master_log_pos=2463; # 开启从库 start slave; # 检查服务器状态 show slave status \\G; # 看到Replica has read all relay log; waiting for more updates基本说明配置成功了，已经开始了主从复制。 ","date":"2023-07-21T16:48:07+08:00","permalink":"http://localhost:1313/post/mysql-cluster/","title":"MySQL主从同步集群搭建"},{"content":"本文从作者CSDN 解决 vue+axios+sprigboot 前后端分离项目 跨域请求资源和获取session不一致问题 同步\n直接上解决方法 跨域请求资源问题 后端添加过滤器，实现HandlerInterceptor接口，重写preHandle方法，添加如下内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 @Component public class FilterConfig implements HandlerInterceptor { public void afterCompletion(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2, Exception arg3) throws Exception { } public void postHandle(HttpServletRequest arg0, HttpServletResponse arg1, Object arg2) throws Exception { } @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object arg2) throws Exception { response.setHeader(\u0026#34;Access-Control-Allow-Origin\u0026#34;, request.getHeader(\u0026#34;Origin\u0026#34;)); // 允许请求跨域 response.setHeader(\u0026#34;Access-Control-Allow-Methods\u0026#34;, \u0026#34;GET, HEAD, POST, PUT, DELETE, TRACE, OPTIONS, PATCH\u0026#34;); response.setHeader(\u0026#34;Access-Control-Allow-Credentials\u0026#34;, \u0026#34;true\u0026#34;); // 允许请求携带session response.setHeader(\u0026#34;Access-Control-Allow-Headers\u0026#34;, \u0026#34;Authorization,Origin, X-Requested-With, Content-Type, Accept,Access-Token\u0026#34;); return true; } } 新建SpringMVCConfig类，继承WebMvcConfigurerAdapter类，自动注入FilterConfig 并设置过滤器拦截规则：\n1 2 3 4 5 6 7 8 9 @SpringBootConfiguration public class SpringMVCConfig extends WebMvcConfigurerAdapter { @Autowired private FilterConfig filterConfig; public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(filterConfig).addPathPatterns(\u0026#34;/**\u0026#34;); } } 以上配置能解决跨域请求，但是仍然存在每次请求session不一致问题，需要添加以下配置：\nsession不一致问题 vue2中，在main.js中引入axios并设置允许携带cookie：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 import Vue from \u0026#39;vue\u0026#39; import App from \u0026#39;./App.vue\u0026#39; import axios from \u0026#39;axios\u0026#39;; // 引入axios axios.defaults.withCredentials=true; // 设置请求默认携带cookie Vue.prototype.$axios = axios; // 可选，设置后可使用“this.$axios”发起请求 // ...正常配置 new Vue({ render: h =\u0026gt; h(App), store, router, // ... }).$mount(\u0026#39;#app\u0026#39;) // ...正常配置 在vue.config.js中添加代理设置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 const {defineConfig} = require(\u0026#39;@vue/cli-service\u0026#39;) module.exports = defineConfig({ transpileDependencies: true, lintOnSave: false, devServer: { proxy: { // 添加代理设置 \u0026#39;/app\u0026#39;: { target: \u0026#39;http://xxx.xxx.xxx.xxx:xxxx/\u0026#39;, // 跨域目标地址 ws: true, changeOrigin: true, pathRewrite: { \u0026#39;^/app\u0026#39;: \u0026#34;\u0026#34; } } } } }) 发起跨域请求：\n1 this.$axios.post(\u0026#34;/app/xxx/xxx\u0026#34;) // 必须是\u0026#39;/app\u0026#39;开头。对应上面的\u0026#39;/app\u0026#39; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;2022年6月9日更新\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\n网站上线问题 测试发现使用以上设置上线后请求报404，将前端请求改为正常请求即可结局\n1 this.$axios.post(\u0026#34;/app/xxx/xxx\u0026#34;) // 改为\n1 this.$axios.post(\u0026#34;http://xxx.xxx.xxx.xxx:xxx/...\u0026#34;) 至此，vue+axios+springboot前后端分离项目中的跨域和session不一致问题完美解决！！！\n","date":"2023-06-23T16:37:15+08:00","permalink":"http://localhost:1313/post/vue-axios-cors/","title":"vue axios 跨域问题"},{"content":"本文从作者CSDN springboot 普通类自动注入mapper 同步\n解决方法 普通类使用@Component注解修饰，添加本类型静态属性、所需mapper属性，添加init方法，用@PostConstruct注解修饰，方法内初始化以上2个属性：\n1 2 3 4 5 6 7 8 9 10 11 12 @Component public class VideoPool { private static VideoPool that; // 本类型静态属性 @Resource public VideoMapper videoMapper; // 所需要mapper @PostConstruct public void init() { that = this; that.videoMapper = this.videoMapper; } } 在类中需要使用mapper时，用that(本类型静态属性）.mapper：\n1 2 3 public static void run() { List\u0026lt;Item\u0026gt; itemList = that.itemMapper.getAll(); } ","date":"2023-06-23T16:28:51+08:00","permalink":"http://localhost:1313/post/spring-boot-reject-mapper/","title":"springboot 普通类自动注入mapper"},{"content":"本文从作者CSDN专栏 蓝桥杯 Python B组 同步\n本专栏主要分享介绍蓝桥杯pythonB组备赛经验，希望可以帮到有需要的同学。\npython创建数组 直接定义法 1 matrix=[0,1,2,3] 间接定义法 1 2 a = 255 li = [0] * a 列表生成式 1 2 matrix=[0 for i in range(4)] matrix=[[0 for i in range(4)]for j in range(4)] ASCII码与字符相互转换 1 2 3 4 5 6 7 8 9 10 11 12 13 14 #以下代码用于实现ASCII码与字符相互转换： ## 用户输入字符 c = input(\u0026#34;请输入一个字符: \u0026#34;) ## 用户输入ASCII码，并将输入的数字转为整型 a = int(input(\u0026#34;请输入一个ASCII码: \u0026#34;)) print( c + \u0026#34; 的ASCII 码为\u0026#34;, ord(c)) print( a , \u0026#34; 对应的字符为\u0026#34;, chr(a)) #以上代码输出结果 #python3 test.py #请输入一个字符: a #请输入一个ASCII码: 101 #a 的ASCII 码为 97 #101 对应的字符为 e 列表转化为字符串 1 2 ls = [\u0026#34;1\u0026#34;,\u0026#34;2\u0026#34;,\u0026#34;3\u0026#34;] \u0026#34;\u0026#34;.join(ls) 修改字符串某一个字符 字符串是不可变的，不能直接修改\n转化法 1 2 3 4 5 s = \u0026#34;abc\u0026#34; temp = list(s) temp[2] = \u0026#34;d\u0026#34; s = \u0026#34;\u0026#34;.join(temp) print(s) replace函数 1 2 3 s = \u0026#34;abc\u0026#34; s = s.replace(\u0026#34;c\u0026#34;,\u0026#34;d\u0026#34;) print(s) 接收由空格分开的多个数据 1 ls = input().split() 同时改变列表中所有元素的类型 1 2 ls1 = input().split() ls2 = list(map(int,ls)) Python索引 python里面的索引的特征是包含起点，但是不包含结束的索引值，-1表示最后一个元素，但是-1是结尾的index，所以含义就是取原始数据的除最后一个元素之外的值\n逆序 1 li = li[::-1] 获取末尾元素 1 a = li[-1] 读取多行 使用python的标准输入函数，strip()是取出输入收尾的多余的空格、回车、缩进等等字符，在很多测试用例是必须的 map函数可以直接使用列表生成来替代 可以看到，此时可以一直读取输入，直到输入为空。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import sys try: while True: line1 = sys.stdin.readline().strip() if line1 == \u0026#39;\u0026#39;: break line2 = sys.stdin.readline().strip() a = int(line1) l = list(map(int, line2.split())) b = [int(n) for n in line2.split()] print(a) print(l) print(b) except: pass ","date":"2023-06-23T14:21:55+08:00","permalink":"http://localhost:1313/post/lq-py-grammar/","title":"蓝桥杯 Python 语法"},{"content":"本文从作者CSDN专栏 蓝桥杯 Python B组 同步\n本专栏主要分享介绍蓝桥杯pythonB组备赛经验，希望可以帮到有需要的同学。\ngcd 1 2 def gcd(a,b): return a if b == 0 else gcd(b, a % b) lcm 1 2 def lcm(a,b): return a * b / gcd(a,b) leapyear 1 year % 4 == 0 and year % 100 != 0 or year % 400 == 0 floyed 1 2 3 4 5 6 7 8 9 10 11 12 n = 5 g = [[0,2,4,7,0], [2,0,1,0,2], [4,1,0,1,6], [7,0,1,0,0], [0,2,6,0,0]] for k in range(n): ## 无向图 节点个数 = 数组长度 for i in range(n): for j in range(n): if g[i][j] \u0026gt; g [i][k] + g[k][j]: g[i][j] = min(g[i][j], g[i][k] + g[k][j]); print(g[0][-1]) ## 4 简单dp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ## 最小路径和 def minPathSum(li,i,j): m = len(li) n = len(li[0]) return dp(li,m - 1, n - 1) memo = [[-1 for i in range(m)]for j in range(n)] def dp(li,i,j): if i == 0 and j == 0: return li[i][j] if(i \u0026lt; 0 or j \u0026lt; 0): return float(\u0026#39;inf\u0026#39;) if memo[i][j] != -1: return memo[i][j] memo[i][j] = math.min(dp(li,i - 1,j),dp(li,j - 1,i)) + li[i][j] return memo[i][j] ## 01背包 for i in range(1,m + 1): for j in range(1,n + 1): dp[i][j] = dp[i - 1][j] if j \u0026gt;= vs[i]: dp[i][j] = max(dp[i - 1][j], dp[i - 1][j - vs[i]] + ws[i]) 回溯求全排列 1 2 3 4 5 6 7 8 9 10 11 12 13 li = [1,2,3] ans = [] def backtrack(st,ed): if st == ed: ans.append(li[:]) return for i in range(st,ed): li[i],li[st] = li[st],li[i] backtrack(st + 1,ed) li[i],li[st] = li[st],li[i] backtrack(0,len(li)) print(ans) 素数一 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import math def check(n): if(n \u0026lt;= 3): return n \u0026gt; 1 if(n % 6 != 1 and n % 6 != 5): return False for i in range(5,int(math.sqrt(n)) + 1,6): if n % i == 0 or n % (i + 2) == 0: return False return True for i in range(100): if check(i): print(i) 素数二 1 2 3 4 5 6 7 8 9 10 n = 100 ns = [False] * (n + 1) for i in range(2, n + 1): if ns[i]: continue print(i) for j in range(i,n//i + 1): ns[i * j] = True 二叉树遍历 1 2 3 4 5 6 7 8 def traverse(root): if not root: return ## 前序遍历 traverse(root.left) ## 中序遍历 traverse(root.right) ## 后序遍历 并查集 1 2 3 4 5 6 7 8 9 parent=[i for i in range(n)] def union(p,q): parent[find[p]] = find[q] def find(x): if parent[x] != x: parent[x] = find(parent[x]) return parent[x]; def isConn(p,q): return find(p) == find(q) 位运算技巧 1 2 3 4 5 6 7 8 (\u0026#39;a\u0026#39; | \u0026#39; \u0026#39;) = \u0026#39;a\u0026#39; (\u0026#39;A\u0026#39; | \u0026#39; \u0026#39;) = \u0026#39;a\u0026#39; (\u0026#39;b\u0026#39; \u0026amp; \u0026#39;_\u0026#39;) = \u0026#39;B\u0026#39; (\u0026#39;B\u0026#39; \u0026amp; \u0026#39;_\u0026#39;) = \u0026#39;B\u0026#39; (\u0026#39;d\u0026#39; ^ \u0026#39; \u0026#39;) = \u0026#39;D\u0026#39; (\u0026#39;D\u0026#39; ^ \u0026#39; \u0026#39;) = \u0026#39;d\u0026#39; 数论 等比数列求和 $a1(1-q^n)/(1-q)$\n等差数列求和 $n(a1+an)/2$\n","date":"2023-06-23T14:08:55+08:00","permalink":"http://localhost:1313/post/lq-py-code-tp/","title":"蓝桥杯 Python B组-代码模板"},{"content":"本文从作者CSDN专栏 蓝桥杯 Python B组 同步\n本专栏主要分享介绍蓝桥杯pythonB组备赛经验，希望可以帮到有需要的同学。\n输入输出 输入 input()接收str,需要进行类型转换\n单个数字输入：n = int(input())\n多个数字输入：a, b = map(int, input().spilt(\u0026rsquo;\u0026rsquo;))\n多个数字输入接收为列表：nums = list(map(int, input().spilt(\u0026rsquo;\u0026rsquo;)))\n输出 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ## 隔空输出 a = [1,2,3,4] print(\u0026#39; \u0026#39;.join(map(str,a))) #1 2 3 4 ## 四舍五入 a = 3.1415926 print(int(a + 0.5)) ## 保留两位 a = 3.1415926 print(\u0026#34;%.2f\u0026#34;%a) 常用函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 abs() ## 取绝对值 divmod() ## 同时取商和余 divmod(7,2)-\u0026gt;(3, 1) sum() ## 求和 min() ## 求最小值 max() ## 求最大值 round() ## 四舍五入 ‘%.3f’%x \u0026#34;{:.3f}\u0026#34;.format(x) round(x,3) ## 保留3位小数 math.ceil() ## 向上取整 math.floor ## 向下取整 pow() ## 求幂 等价于** pow(25,1/2)开方 hex() ## 十进制转十六进制 oct() ## 十进制转八进制 bin() ## 十进制转二进制 bool() ## 将指定参数转为bool类型 float() ## 转换为浮点数 int() ## 转换为整数,其他进制转为十进制 int(\u0026#39;11\u0026#39;,2)-\u0026gt;3 ord() ## 获取单个字符的ASCII数值 chr() ## 将整数转换为其值对应的ASCII/Unicode字符 range() ## 创建一个可迭代对象 all() ## 指定序列中所有元素都为True返回True否则返回False any() ## 指定序列中只要有一个元素为True返回True否则返回False sorted() ## 对可迭代对象进行排序 sorted(iters, key = lambda x: x + 1) list() ## 将可迭代对象转换为列表 set() ## 创建一个无序不重复的元素集合 map() ## 通过自定义函数实现对序列的元素映射操作并返回操作后的结果 open() ## 打开文件并返回文件对象 fp.readlines() ## 读取文件所有行（包括换行符，可以使用line.strip(\u0026#39;\\n\u0026#39;)删除） format() ## 格式化数据 \u0026#34;{} {}\u0026#34;.format(\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;)、\u0026#34;{:.2f}\u0026#34;.format(3.1415926) input() ## 接收用户输入并返回所输入的string类型数据 len() ## 返回一个对象的元素或项目个数 字符串操作 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 from collections import Counter st = \u0026#39;hello world\u0026#39; Counter(st) ### Counter({\u0026#39;l\u0026#39;: 3, \u0026#39;o\u0026#39;: 2, \u0026#39;h\u0026#39;: 1, \u0026#39;e\u0026#39;: 1, \u0026#39; \u0026#39;: 1, \u0026#39;w\u0026#39;: 1, \u0026#39;r\u0026#39;: 1, \u0026#39;d\u0026#39;: 1}) string.split(str=\u0026#34;\u0026#34;, num=string.count(str)) ## 通过指定分隔符对字符串进行切片，如果参数 num 有指定值，则分隔 num+1 个子字符串，不填则默认为空格。 string.decode(encoding=\u0026#39;UTF-8\u0026#39;,errors=\u0026#39;strict\u0026#39;) ## 指定的编码格式解码字符串 string.encode(encoding=\u0026#39;UTF-8\u0026#39;,errors=\u0026#39;strict\u0026#39;) ## 指定的编码格式编码字符串 string.encode(encoding=\u0026#39;UTF-8\u0026#39;,errors=\u0026#39;strict\u0026#39;) ## 指定的编码格式编码字符串 string.count(str, beg=0, end=len(string)) ## 统计str出现次数，可指定开始/结束位置 string.endswith(str, beg=0, end=len(string)) ## 判断是否以str结束，可指定开始/结束位置 string.find(str, beg=0, end=len(string)) ## 查找str,未找到返回-1 string.index(str, beg=0, end=len(string)) ## 查找str,未找到抛出异常 string.join(seq) ## 将seq中的各项以string为连接符拼接 string.strip([obj]) ## 去除首位指定字符 等价于string.lstrip() -\u0026gt; string.rstrip() string.upper() ## 转为大写 string.lower() ## 转为小写 string.swapcase() ## 转换大小写 时间日期操作 1 2 3 4 5 6 7 8 9 datetime.datetime.now() ## 2019-08-14 12:52:55.817273 datetime. datetime(year, month, day[, hour[, minute[, second[, microsecond[,tzinfo]]]]]) datetime.date（year，month，day) datetime.time([hour[, minute[, second[, microsecond[, tzinfo]]]]]) datetime.strftime(\u0026#34;%H\u0026#34;) 列表操作 1 2 3 4 5 6 7 8 9 10 11 list.append() ## 增加 list.insert() ## 插入 list.pop() ## 删除 list[m:n] ## 切片，从m开始到n-1 list1=list[::-1] ## 表示list1是list的逆序 \u0026#39;\u0026#39;.join(list) ## 把list中的元素合成一个字符串 正则表达式 1 2 3 4 5 import re s = \u0026#39;Regular 123 Expression 456\u0026#39; re.findall(r\u0026#39;\\d+\u0026#39;,s) 匹配规则 ^：匹配字符串开头\n\u0026ldquo;*\u0026rdquo; 匹配前面的子表达式零次或多次\n\u0026ldquo;+\u0026rdquo; 匹配前面的子表达式一次或多次\n\u0026ldquo;?\u0026rdquo; 匹配前面的子表达式零次或一次\n\u0026ldquo;[abc]\u0026rdquo; ：方括号表示字符集合，例子表示一个字符串有一个 \u0026ldquo;a\u0026rdquo; 或 \u0026ldquo;b\u0026rdquo; 或 \u0026ldquo;c\u0026rdquo; 等价于 [z|b|c]\n\u0026ldquo;[a-z]\u0026quot;： 表示一个字符串中存在一个 a 和 z 之间的所有字母\n\u0026ldquo;[^a-z]\u0026rdquo; ：表示一个字符串中不应该出现 a 到 z 之间的任意一个字母\n\u0026ldquo;[0-9]\u0026quot;： 表示一个字符串中存在一个 0 和 9 之间的所有数字\n\u0026ldquo;\\d \u0026quot; 匹配一个数字字符，等价[0-9]\n\u0026ldquo;\\D \u0026quot; 匹配一个非数字字符，等价[^0-9]\n\u0026ldquo;\\w\u0026rdquo; 匹配包括下划线的任何单词字符。等价于\u0026rdquo;[A-Za-z0-9_]\u0026rdquo;\n\u0026ldquo;\\W\u0026rdquo; 匹配任何非单词字符。等价于\u0026rdquo;[^A-Za-z0-9_]\u0026rdquo;\n注意：正则语法中^匹配行开头、\\A匹配字符串开头，单行模式下它两效果一致，多行模式下\\A不能识别\n","date":"2023-06-23T14:05:35+08:00","permalink":"http://localhost:1313/post/lq-py-base/","title":"蓝桥杯 Python B组-Python基础"},{"content":"本文从作者CSDN专栏 蓝桥杯 Python B组 同步\n本专栏主要分享介绍蓝桥杯pythonB组备赛经验，希望可以帮到有需要的同学。\n我参加的是2022年的pythonB组，本来是只打算混混省赛的，可能是今年省赛比较简单，加上运气比较好，混到了国二，排名在1/3左右，说实话挺意外的。\n比赛基本上是零基础开始准备的，省赛之后因为项目比较忙，自己也是一心摆烂，直接没有准备国赛，到国赛时候写个dfs都要推半天了。其实还是有点遗憾的，当初要是好好准备一个月说不定国一就有了。\n写这个文集主要是因为当初本人备赛时候基本没什么Python组的经验贴，有一些题解还需要收费，确实很不容易。（因为时间关系，这里的题解就随缘更了）\n所以想把自己的经验给大家分享，希望小白可以少走一些弯路！！！\n难度 蓝桥杯在程序设计竞赛中来说算是难度比较低的了（当然近年来难度也在逐渐提高），很多人称蓝桥杯为暴力杯，尤其是省赛，只要会基本的dfs就能混点分，当然这种情况也在逐年减少，但是客观来说蓝桥杯确实不难，只要备赛方法得当，拿个奖完全没问题，大家没必要太担心。\n赛制 蓝桥杯为个人赛，一共有十道题目，往年是5填空+5代码，今年改成了2填空+8代码，之后不知道还会不会调整。\n填空题都是给出题面，并且保证只有一个正确答案，选手只需要计算出答案提交结果就行，不限制计算方法，你可以使用电脑上的任何软件，比如计算器、Excel\u0026hellip;\n代码题需要提交代码，跑通给定的测试用例，也就是OJ的形式。题目完全为客观题型，选手所提交作答的运行结果为主要评分依据。\n比赛不能携带资料，但是可以查看python自带的文档，会提供草稿纸\n注意事项 只能使用Python标准库\n只能使用Python自带的IDE\n","date":"2023-06-23T13:17:35+08:00","permalink":"http://localhost:1313/post/lq-py-b/","title":"蓝桥杯 Python B组-说明"},{"content":"bug日志 2023-06-20-16:30:34 bug描述 博客评论功能不可用，具体表现为：\n博客末评论处尾显示\u0026quot;未找到相关的 Issues 进行评论，请联系xxx初始化创建\u0026quot;字样 点击\u0026quot;使用GitHub登录\u0026quot;后跳转回该博客，无其他反应 bug溯源 Google查到可能是博客uri过长，经排查后发现并不是该问题导致\n观察后发现页面跳转时候地址栏网址后带了错误参数\u0026quot;error=redirect_urixxx\u0026quot;等字样，推测是GitHub回调错误。\n排查后发现是由于之前绑定了 blog.mulinbiao.com 域名，未更新GitHub OAuth 配置的 callback 导致\nbug修复 打开GitHub settings -\u0026gt; developer settings -\u0026gt; OAuth Apps，将APP配置的 Homepage URL 和 Authorization callback URL 改为 https://blog.mulinbiao.com/ 即可\n","date":"2023-06-18T13:14:35+08:00","permalink":"http://localhost:1313/post/blog-bug-log/","title":"博客bug日志"},{"content":"前序 很早之前就很想要开个自己的博客， 但是一直都比较忙（lǎn），趁着临近毕业的空隙，才终于决定抽出时间开始实现。开这个博客的主要目的有如下两个：\n记录生活和思考\n写博客可以将自己的经验、感悟、思考和见解以文字的形式记录下来，不仅可以帮助自己更好地理清思路和总结经验，也能够与他人分享自己的心路历程。\n交流和学习\n博客也是一个交流和学习的平台，可以与其他博主、读者和同行交流和分享自己的经验和见解，从而获得更多的启发和学习机会。\n关于本博客 本博客使用 Hugo+Github Pages搭建，详细过程请自行参考 如何用 GitHub Pages + Hugo 搭建个人博客 以及 个人博客记 —— Github pages 绑定个人域名 。 另外，出于学习外语的目的，我会尽量同时发布中英日版本博客，若发现语言或内容上的错误，欢迎批评指正。\n本博客使用二级域名 blog.mulinbiao.com 解析到 arturiamu.github.io，由于 blog.mulinbiao.com 域名涉及到续费、备案等问题，连通性无法得到保障，建议使用 arturiamu.github.io 进行访问。\n许可协议 除特别声明外，本站点所有文章均使用 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 知识共享许可协议\n您可以自由地： 共享 — 在任何媒介以任何形式复制、发行本作品\n演绎 — 修改、转换或以本作品为基础进行创作\n只要你遵守许可协议条款，许可人就无法收回你的这些权利。\n惟须遵守下列条件： 署名 — 您必须给出适当地署名，提供指向本许可协议的链接，同时标明是否（对原始作品）作了修改。您可以用任何合理的方式来署名，但是不得以任何方式暗示许可人为您或您的使用背书。\n非商业性使用 — 您不得将本作品用于商业目的。\n相同方式共享 — 如果您再混合、转换或者基于本作品进行创作，您必须基于与原先许可协议相同的许可协议 分发您贡献的作品。\n没有附加限制 — 您不得适用法律术语或者 技术措施 从而限制其他人做许可协议允许的事情。\n声明 您不必因为公共领域的作品要素而遵守许可协议，或者您的使用被可适用的 例外或限制所允许。\n不提供担保。许可协议可能不会给与您意图使用的所必须的所有许可。例如，其他权利比如形象权、隐私权或人格权可能限制您如何使用作品。\n","date":"2023-06-18T12:25:48+08:00","permalink":"http://localhost:1313/post/blog-description/","title":"博客说明"}]